<?xml version="1.0" encoding="utf-8"?>
  <feed xmlns="http://www.w3.org/2005/Atom" xml:base="https://conwy.co">
  <title>conwy</title>
  <subtitle>Blog articles by Jonathan Conway</subtitle>
  <link href="https://conwy.co/feed.xml" rel="self"/>
  <link href="https://conwy.co/"/>
  <updated>2025-02-12T00:00:00.000Z</updated>
  <id>https://conwy.co</id>
  <author>
    <name>Jonathan Conway</name>
    <email>jon@conwy.co</email>
  </author>
  
  <entry>
    <title>Simulating application states</title>
    <link href="https://conwy.co/articles/simulating-states" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>simulating-states</id>
    <content xml:lang="en" type="html">## Motivation

Engineers are increasingly called upon to provide on-call support for complex software running in production.

To ease the diagnosis and resolution of issues in these systems, it can be beneficial to be able to ***simulate*** – at will – any of the important states the system can be in.

This article covers what I&#39;ve learned thus-far about simulation for the purposes of easing production support.

## Benefits of arbitrary state simulation

There are a number of benefits to being able to simulate states of interest, even before incidents occur.

- Testing in advance
- Faster diagnosis
- Fewer team interdependencies

### Testing in advance

*A bug is better discovered and resolved at 1 PM than at 3 AM!*

Engineers and testers can try out various states of the application in production, in advance, to uncover any unexpected bugs, unknown-unknowns, etc. As much as we try to keep all our environments consistent and predictable, there&#39;s always a chance some issue catches us by surprise only when it reaches production. It could be anything, from a quirk in the CPU architecture of the cloud instance to a difference in the time-zone where the instance is running.


### Faster diagnosis

*The faster an issue can be resolved at 3 AM the better!*

When an issue occurs, rather than going through a lengthy procedure to try and &quot;reproduce&quot; the bug, it&#39;s better if engineers can follow a quick, systematic and repeatable procedure to directly trigger the bug.

### Fewer team interdependencies

*The fewer people who have to be woken up at 3 AM the better!*

If an engineer can directly reproduce an issue themselves, this saves them from having to rely on subject-matter-experts, system administrators, product owners or others.

## Types of state

Here I will attempt to categorise system state into broadly the following types:

- **🌎 System state.** Example: A new feature is activated for all users.
- **🖥️ Instance state.** Example: Each instance performs a background job during off-peak hours. Instances are located in multiple time-zones.
- **🧑‍💻 User state.** Example: A user account can have a subscription or not.
- **⏰ Session state.** Example: A user account can be signed in or not.
- **⏳ Activity state.** Example: A user sees a loading screen if a certain data source takes &gt;2 seconds to load.

Depending on the type of state we want to simulate, different tools and techniques can be applied.

## Tools and techniques

### Feature flags

Feature flags are settings that can turn on or off application states.

For example, if game developers implement a new kind of magic potion, say &quot;Ginger potion&quot;, then its availability to game users could be controlled by a feature flag named: `GINGER_POTION_ENABLED`.

- **Looked up at runtime.** Example: A product owner logs into a feature flag management system such as [LaunchDarkly](https://launchdarkly.com/) and changes a flag setting, causing the feature flag to be switched on or off in production.
- **Built into the deployment.** Example: An engineer modifies a flag in a configuration file and deploys that change to production, causing the feature flag to be switched on or off in production.
- **Combination approach.** Example: An engineer specifies a default value for a flag in a configuration file and deploys that change to production, but that flag setting can be overridden by a product owner via LaunchDarkly.

### Test entities

Test entities are entities set up specifically to trigger certain application states.

Entities would typically be test user accounts, but might also be models of other entities in reality, such as bank accounts, credit cards or online products.

For example, if certain users of a banking account have an individual account, whereas others have a joint account with another user, we could create two test account entities: a &quot;Test Individual Account&quot; and a &quot;Test Joint Account&quot;. By logging in to an appropriate test account, with credentials shared privately within the organisation, engineers could simulate states specific to either individual or joint accounts.

#### Fake and real

Entities could be faked, but might alternately be real if needed. For example, if an airline needs to be able to simulate an actual passport check, a real individual&#39;s passport details could be used (obviously agreed with the person in advance, and likely a high-ranking employee in the company).

### Special values

Particular values can be inputted into the application&#39;s user interface, to trigger particular states.

#### Fake and real

As with entities, these could be faked or real.

For example, to test an error state that is only revealed when a payment over $5,000 is attempted, we can simply enter a value of $5,100. But to test an error state that is only revealed when there is an unknown downstream system error, we might use a very specific value for the &quot;Payment reference&quot; field, such as &quot;downstream-system-error&quot;. This should be a value which the customer is unlikely to ever use or guess, but which is simple for an engineer or tester to enter.

### Procedures

If we can use a reliable, repeatable and reversible procedure to generate a desired system state, then this might work out as a useful means of simulating that state.

For example, suppose a banking application has a state in which the customer has consumed all of their daily payment limit. We could simulate this state by creating a scheduled payment for tomorrow, which consumes the full limit. To reverse it, we can remove the payment on the same day. This should qualify as a simple, repeatable procedure.

In combination with fake values, we could add a &quot;testing back door&quot; into our application to make normally irreversible procedures reversible. For example, suppose we need to simulate a daily payment limit being reached on a same-day payment. We could make the payment as in the example above, but as an instant payment. Then we could reverse it by attempting to make a payment with a &quot;Payment reference&quot; field value of &quot;reverse-payment&quot;. The application would have some code to implement an &quot;undo&quot; of the payment whenever that specific payment reference is used.

### Client controls

Browser clients for web applications allow the user to enter cookies, local storage values or other methods of storage.

These can be used to simulate application states.

* Client-side. Settings can be applied directly to the user interface.
* Server-side. Settings can be sent to the server to be applied there, such as cookies.

Other rich clients could have similar facilities, either built-in / off-the-shelf or custom built by the developers who maintain the client.

### In-app controls

Applications themselves could including in-app controls for simulating states, only available to internal staff, and activated by a special shortcut key or a menu item.

I implemented an experimental form of this on the Exchange project at the DTA.

## Comparing approaches

| Approach         | Deployment required    | Non-technical staff    | Implementation effort | Types of state most suited for
| :-               | :-                     | :-                     | :-                    | :-
| Feature flags    | 🔸 Depends             | 🔸 Depends             | 🟠 Medium             | 🌎 System🖥️ Instance
| Special values   | 🚫 No                  | ✅ Yes                 | 🟡 Low-medium         | 🧑‍💻 User🖥️ Instance⏳ Activity
| Procedures       | 🚫 No                  | ✅ Yes                 | 🟢 Low                | 🧑‍💻 User⏰ Session⏳ Activity
| Client controls  | 🚫 No                  | 🚫 No                  | 🔴 High               | 🧑‍💻 User⏰ Session⏳ Activity
| In-app controls  | 🚫 No                  | ✅ Yes                 | 🔴 High               | 🧑‍💻 User⏰ Session⏳ Activity

## Documenting state simulations

State simulations can be documented to put them in easy reach of all team members, from engineers to analysts and designers to product owners.

Some documentation patterns I&#39;ve observed:

- Test accounts register
- Feature pages
- Pull requests
- README files

### Test accounts register

A table of test accounts, with columns providing login details such as username and password, as well as details on what the account can be used to test.

Usually a document in the team wiki (Confluence, Notion etc.) or a shared spreadsheet (Google Sheets, Excel, etc.).

| Username                  | Password    | Usage                        |
| :-                        | :-          | :-                           |
| individual1@test.com      | P@ssw0rd    | Individual bank account      |
| joint1@test.com           | P@ssw0rd    | Joint bank account           |
| admin1@test.com           | P@ssw0rd    | Customer service             |

External resources can be linked to, such as:

- Account credentials in a secret store

### Feature pages

A document describing a feature, including descriptions of simulated states as part of that description.

Usually a document in the team wiki (Confluence, Notion etc.).

Simulated states can be:
- Listed out in their own section or
- Included as part of a test plan with test cases

Details can be provided inline, such as:
- Account credentials
- Feature flags
- Test entities
- Procedures
- Client controls
- In-app controls

External resources can also or alternately be linked to, such as:
- Account credentials in a secret store
- Feature flag pages in feature flag management system (such as [LaunchDarkly](https://launchdarkly.com))
- Feature flag settings in code files in a source code repository (such as [Github](http://github.com))
- Test entities in separate documentation pages or in a source code repository
- Procedures in separate documentation page
- Deep-links to in-app controls for setting up state simulations

![Example with simulated states listed separately](/images/articles/simulating-states/docs-simulated-states-separate.svg)

![Example with simulated states included in test cases](/images/articles/simulating-states/docs-simulated-states-test.svg)

## Conclusion

Being able to simulate all significant states is a super-power for development teams on medium to large sized projects.

Testing can be performed more thoroughly in advance, avoiding many bugs reaching production. In the case some bugs do make it to production, they can be more directly reproduced and resolved. With appropriately applied and documented techniques, such as feature flags, special values and in-app controls, the whole team can participate, reducing problematic dependencies. 

Enabling state simulation will likely be a consideration on many more projects going into the future.</content>
  </entry>
  

  <entry>
    <title>Keyboard shortcuts</title>
    <link href="https://conwy.co/articles/keyboard-shortcuts" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>keyboard-shortcuts</id>
    <content xml:lang="en" type="html">In this article I want share the keyboard shortcuts that I use on a daily basis, in various environments.

Advantages of using shortcuts:
- Shave off a few seconds or milliseconds, hundreds of times over. The time savings really add up.
- Make you look smarter in screen sharing sessions, live demos and pairing.
- They&#39;re just fun to use!

## Visual Studio Code

![](/images/tools/vs-code.png?size=icon-small)

| Shortcut                                                                                                       | Action                               | 
| :-                                                                                                             | :-                                   |
| ⌘ + ⇧ + ⌥ + ( ↑ / ↓ )     | Rectangular selection                |
| ⇧ + ⌥ + 🖱️ Drag                                                              | Rectangular selection (mouse)        |
| ⌘ + A                                                                        | Select all                           |
| ⌘ + L                                                                        | Select line                          |
| ⌃ + ( A / E )                                               | Skip to line start / end             |
| ⌥ + ( ← / → )                                               | Skip by word left / right            |
| ⌥ + ⇧ + ( ← / → )                          | Select by word left / right          |
| ⌥ + ( ↑ / ↓ )                                               | Move line up / down                  |
| ⌥ + ⇧ + ( ↑ / ↓ )                          | Duplicate line up / down             |
| ⌘ + ⇧ + ( [ / ] )                          | Switch tab left / right              |
| ( ⌃ + ⇤ ) / ( ⌃ + ⇧ + ⇤ ) | Switch tab most / least recent       |
| ⌘ + ( [ / ] )                                               | Indent / outdent                     |
| ⌘ + /                                                                        | Toggle comment                       |
| ⌘ + W                                                                        | Close current tab                    |
| ⌘ + K, W                                                    | Close all tabs. Keep window open.    |
| ⌘ + ⇧ + W                                                   | Close current window                 |
| ⌘ + P                                                                        | Quick find file                      |
| ⌘ + ⇧ + P                                                   | Quick find action                    |
| ⌘ + T                                                                        | Quick find symbol                    |
| ⌘ + N                                                                        | Open new tab                         |
| ⌘ + ⇧ + N                                                   | Open new window                      |
| ⌘ + ⇧ + E                                                   | Focus on file browser                |
| ⌘ + F2                                                                       | Select all instances of current word |

## Sublime Text

![](/images/tools/sublime-text.png?size=icon-small)

| Shortcut                                                                                  | Action                               | 
| :-                                                                                        | :-                                   |
| ⌃ + ⌘ + ( ↑ / ↓ )     | Rectangular selection                |
| ⌥ + 🖱️ Drag                                                              | Rectangular selection (mouse)        |
| ⌘ + A                                                   | Select all                           |
| ⌘ + L                                                   | Select line                          |
| ⌃ + ( A / E )                          | Skip to line start / end             |
| ⌥ + ( ← / → )                          | Skip by word left / right            |
| ⌥ + ⇧ + ( ← / → )     | Select by word left / right          |
| ⌥ + ( ↑ / ↓ )                          | Move line up / down                  |
| ⌘ + ⇧ + D                              | Duplicate line down                  |
| ⌘ + ⇧ + ( [ / ] )     | Switch tab left / right              |
| ( ⌃ + ⇤ ) / ( ⇧ + ⇤ ) | Switch tab most / least recent       |
| ⌘ + ( [ / ] )                          | Indent / outdent                     |
| ⌘ + /                                                   | Toggle comment                       |
| ⌘ + W                                                   | Close current tab                    |
| ⌘ + P                                                   | Quick find file                      |
| ⌘ + ⇧ + P                              | Quick find action                    |
| ⌘ + ⇧ + W                              | Close current window                 |
| ⌘ + N                                                   | Open new tab                         |
| ⌘ + ⇧ + N                              | Open new window                      |
| ⌃ + ⇧ + G                              | Select all instances of current word |

## iTerm2

![](/images/tools/iterm2.png?size=icon-small)

| Shortcut                                                         | Action                   | 
| :-                                                               | :-                       |
| ( ↑ / ↓ )                      | Previous / Next history  |
| ⌃ + R                                           | Search history           |
| ⌃ + C                                           | Stop current process     |
| ⌃ + ( A / E ) | Skip to line start / end |
| ⌃ + W                          | Delete previous word     |
| ⌃ + D                                           | Delete next character    |
| ⌘ + T                                           | Open new tab             |
| ⌘ + N                          | Open new window          |

Some additional convenience shortcuts can be added by [configuring iTerm2 key mappings](https://mariusschulz.com/blog/keyboard-shortcuts-for-jumping-and-deleting-in-iterm2), as described in Marius Schulz&#39;s excellent article.

| Shortcut                                                         | Action                    | 
| :-                                                               | :-                        |
| ⌥ + ( ← / → ) | Skip by word left / right |
| ⌘ + ( ← / → ) | Skip to line start / end  |
| ⌥ + ⌫                          | Delete previous word      |
| ⌘ + ⌫                          | Delete line               |


## Slack

![](/images/tools/slack.svg?size=icon-small)

| Shortcut                                                           | Action                                                   | 
| :-                                                                 | :-                                                       |
| ⌘ + B                            | Bold                                                     |
| ⌘ + I                            | Italic                                                   |
| ⌘ + ⇧ + X       | Strikethrough                                            |
| ⌘ + V                            | Make the selection a link with pasted URL from clipboard |
| ⌘ + U                            | Upload file with file picker                             |
| &gt;, Space                      | Start a blockquote                                       |
| ⌘ + ⇧ + C       | Toggle inline code block                                 |
| &gt;, Space                      | Start a blockquote                                       |
| ``` | Start full line code block                               |

## Fork

![](/images/tools/fork.png?size=icon-small)

| Shortcut                                                                              | Action                                                          | 
| :-                                                                                    | :-                                                              |
| ⌘ + C                                               | Copy full file name of the selected file. Including path.       |
| ⌘ + ⇧ + O                          | Open the selected file. Uses the default editor.                |
| ⌘ + ⇧ + C                          | Focus on the commit message input.                              |
| ↓                                                                    | On message input, show recent commit messages. Click to re-use. |
| ⌘ + ⇧ + ( [ / ] ) | Switch tab left / right                                         |
| ⌘ + T                                               | Open new tab                                                    |
| ⌘ + N                                               | Open new window                                                 |
</content>
  </entry>
  

  <entry>
    <title>User flows</title>
    <link href="https://conwy.co/articles/user-flows" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>user-flows</id>
    <content xml:lang="en" type="html">&gt; Summary: User flows help digital teams get on the same page and view the user interface and interactions holistically. User flows are typically made up of screens and components, nodes and connectors and notes and links. Collaboration can take the form of comments and annotation sessions.

When building a digital product on a team of almost any size and composition, I&#39;ve found it helpful to get a ***complete birds-eye view*** of the user&#39;s journey through the product. This kind of view is especially helpful during discussions between engineers, designers and product owners.

Everyone should be on the same page about ***how the how the user will interact*** with the product and ***how the product should behave***.

In this case, just having a collection of screen mockups doesn&#39;t quite do the job. We want to see the ***connections between screens*** and how they interact with the user.

In a previous article I discussed [interaction wireframes](/articles/interaction-wireframes) – wireframes that include additional details about parts of the interface (via markers) and connections between screens or parts of screens (via connecting arrow lines with labels).

Recently ***user flows***, a more advanced form of this, have come into vogue. In this article I&#39;d like to describe what user flows are and their benefits.

## Ingredients of a user flow

Here&#39;s an outline of a user flow:

![Outline of a user flow](/images/articles/user-flows/outline.png)

And an example – an emoji picker application:

![Example user flow for an emoji picker](/images/articles/user-flows/example.png)

Notice the following ingredients:

1. Screens and components
2. Nodes and connectors
3. Notes and links

Let&#39;s dive into each.

## Screens and Components

![](/images/articles/user-flows/screen.png)

User flows are screen-centric. Everything revolves around whole screens that users see. We are really trying to see the product as it appears to the end-user.

Desktop and mobile screens might sit adjacent, if the experience is very similar. But in cases where the mobile experience differs significantly from desktop, it&#39;s probably better to use entirely separate flows for each.

Screens are high-fidelity mockups – they really look like the real thing. In the &quot;bad old days&quot;, it might have been advisable to use lower-fidelity tools such as wireframes and even hand drawings. In some cases these are still useful.

![Example screen containing components](/images/articles/user-flows/example-screen.png)

User flows, in contrast, take advantage of more modern tools.
1. ***Design tools*** (such as [Figma](http://figma.com)), which make it easy to create high-fidelity components and quickly assemble them into full screens and
2. ***Collaborative whiteboard tools*** (such as [FigJam](https://www.figma.com/figjam/) and [Miro](https://miro.com)), which allow screens to be quickly assembled into flows, in a real-time collaborative visual space.

Designers can consume ***design systems*** or ***component libraries***, assembling pre-built components (either internal to the organisation or off-the-shelf) into full screens. For example Figma has [Figma components](https://help.figma.com/hc/en-us/articles/360038662654-Guide-to-components-in-Figma).

With component re-use, full fidelity mockups become more effective than wireframes. They look realistic and make it easy for engineers to implement the screens using the natural reusability of frameworks such as React, React Native or Angular.

Using a collaborative whiteboard, designers can more easily communicate designs to engineers, who can also participate in the design, by asking questions, attaching comments to specific parts of the flow and/or participating in annotation sessions.

## Nodes and connectors

![](/images/articles/user-flows/nodes-connectors.png)

Screens can be connected together using ***connectors*** – lines with directional arrows, indicating visually how the user &quot;flows&quot; through the application. Various kinds of ***nodes*** can be inserted between connected screens, to indicate user actions, system events and processes, conditionals and terminators.

### User actions

![](/images/articles/user-flows/user-action.png)

In the example, I use green circles or ovals for user actions.

The text should be very short, 1-3 words maximum. It should describe a specific user activity, such as &quot;click&quot;, &quot;hover&quot;, &quot;submit form&quot;, etc.

![Example user action](/images/articles/user-flows/example-user-action.png)

### System events and processes

![](/images/articles/user-flows/system-process-event.png)

In the example, I use blue rectangles for system events and processes.

System events triggered by user interaction should be described in brief words or phrases and directly connected to the screen or another node.

Processes are second-order events that are triggered by events, not directly by interactions. I use blue rectangles for these also and connect them to the relevant event. If a process is long-running or a background process, relevant to the screen but not tied to a particular node, I just place it nearby.

![Example system event and process](/images/articles/user-flows/example-system-event.png)

### Conditionals and terminators

![](/images/articles/user-flows/conditional.png)

In the example, I use purple rhombuses for conditionals, such as &quot;if foo then bar else baz&quot;.

Conditionals are especially helpful for engineers, who need to understand the pre-conditions for a screen or component to be shown to the end-user.

![](/images/articles/user-flows/terminators.png)

Terminators indicate the start or end of a flow. I like to use a &quot;person&quot; or &quot;stick figure&quot; symbol for the start, to orient the viewers to the fact that a real person will be going through this flow. I like to use a simple gray circle to mark the end of a flow, with perhaps a link to a subsequent flow or to the main screen.

![Example conditional and terminator](/images/articles/user-flows/example-conditional-terminator.png)

## Optional: Notes and links

Small ***notes*** can be added underneath screens and components to provide additional information such as intended user experience, edge cases and justifications. These might be simply pieces of text underneath a screen or they might be numbered or bulleted lists.

Helpful ***links*** can be added, pointing to resources such as documentation, tasks in the task tracker, other user flows, chat discussions or anything else that&#39;s relevant to the screen.

&gt; Aside: I marked Notes and links as &quot;Optional&quot; because it adds some clutter to the whiteboard, which you might prefer to avoid.

![Example notes and links](/images/articles/user-flows/example-notes-links.png)

## Collaboration with comments and annotations

Team members can add ***comments*** to specific elements in the flow using, say, the [Comment tool in FigJam](https://help.figma.com/hc/en-us/articles/1500004290941-Comments-in-FigJam).

![Example comment](/images/articles/user-flows/example-comment.png)

Also the team might run ***annotation sessions***. These are online meetings in which team members take some time to add online sticky notes to parts of the flow, communicating questions, accessibility issues, engineering issues or anything other relevant communication.

![Example comment](/images/articles/user-flows/example-annotation-session.png)

## Further reading

- [User flows - Interaction Design Foundation](https://www.interaction-design.org/literature/topics/user-flows)

</content>
  </entry>
  

  <entry>
    <title>Object const enum pattern for Typescript</title>
    <link href="https://conwy.co/articles/typescript-object-const-enum-pattern" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>typescript-object-const-enum-pattern</id>
    <content xml:lang="en" type="html">&gt; Summary: Typescript&#39;s built-in enum structure can be replaced with a better object const pattern. The advantages of this pattern include flexibility over values and ability to exploit IDE features such as auto-suggest and &quot;go to source&quot;.

Typescript&#39;s built-in `enum` structure is woefully inadequate, to the point that even the Typescript team saw fit to [list pitfalls and alternatives](https://www.typescriptlang.org/docs/handbook/enums.html#const-enum-pitfalls) of `enum` in their documentation.

One [recommended alternative](https://www.typescriptlang.org/docs/handbook/enums.html#objects-vs-enums) is to declare an `object const` object with `as const`.

In this article I will describe how I implement this pattern as both an object and a derived type.

## Pattern

Here&#39;s how I implement object const:

```typescript
const Enums =  as const;

type Enum = TypeOfConst;
```

The implementation of `TypeOfConst` is a very simple one-liner:

```typescript
type TypeOfConst = Const[keyof Const];
```

I typically put it in a shared utils file and export it.

## Example

Here&#39;s an example for enumerating a few colors:

```typescript
const Colors =  as const;

type Color = TypeOfConst;
```

We can use the `Color` to access a type that can be one of the values and `Colors.` to access the values themselves.

For example, we can use `Color` as the type of a `backgroundColor` field on an interface definition:

```typescript
interface ButtonProps 
```

And then set its value using `Colors`:

```typescript
const buttonProps: ButtonProps = ;
```

## Advantages

The advantages I&#39;ve found in this approach are:

- Flexible values
- Auto-suggest on container and values
- Easy &quot;go to source&quot; on container

### Flexible values

Unlike a simple union of values, with an object const, we can separate the name of each entry from its value. This allows us more flexibility with the values, which can be strings, numbers, objects or any other type that can be assigned.

### Auto-suggest on container and values

With an object const, we get nice auto-suggest when we enter dot (&quot;.&quot;) after the const name.

![Visual Studio Code intelli-sense on object const values](/images/articles/typescript-object-const-enum-pattern/auto-suggest.png)

Even better, because the object const itself is named, we can use auto-suggest to find it and import it anywhere.

![Visual Studio Code intelli-sense on object const container name](/images/articles/typescript-object-const-enum-pattern/auto-suggest-container.png)

This wouldn&#39;t be possible with a simple union of values.

### Easy &quot;go to source&quot; on container

With an object const, we can use our IDE to quickly preview and/or navigate to the const source.

For example, in Visual Studio Code, we can Cmd+MouseOver the const name to see its source in a pop-up, and Cmd+Click to be taken to the source code.

![Visual Studio Code popup on Cmd+MouseOver on the object const name](/images/articles/typescript-object-const-enum-pattern/cmd-mouseover-popup.png)

## Conclusion

I think the object const pattern above provides a viable enumeration pattern for most use-cases in Typescript.</content>
  </entry>
  

  <entry>
    <title>Generic HOC creator pattern for React</title>
    <link href="https://conwy.co/articles/react-generic-hoc-pattern" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>react-generic-hoc-pattern</id>
    <content xml:lang="en" type="html">&gt; Summary: Using a generic HOC creator pattern, I can compose two React components together in a highly decoupled way. The pattern is to create a HOC (Higher-Order Component) creator function, which can be applied to a general component by a combined components and exported for re-use by consumer components. Examples of applications include Tooltips and Form controls.

I&#39;ve recently developed a pattern that allows me to compose two React components together in a highly decoupled way, using a generic HOC creator.

In this article I&#39;ll motivate and outline the pattern, provide an example, and discuss my own implementation, `createWithHOC`.

## Motivation

Suppose we have an extremely ***general*** component, which we want to widely re-use by connecting it to other components in our component library.

![Diagram depicting generic and connected components](/images/articles/react-generic-hoc-pattern/generic-reused-component.png)

We are happy for the immediate consumers of the component need to know about the general component.

But we don&#39;t want their consumers – the ***end consumers*** – to know about it.

![Diagram depicting generic component re-used by, but decoupled from, end consumers](/images/articles/react-generic-hoc-pattern/generic-reused-component-decoupling.png)

For these end consumers, we just want to expose some special props, which will ultimately be passed through to the general component.

![Diagram depicting generic, connected and consumer components with props passed from consumer to generic](/images/articles/react-generic-hoc-pattern/generic-reused-component-consumer-props.png)

## Pattern

The pattern here is to create a HOC (Higher-Order Component) creator function, which can be applied to the ***general*** component by the ***combined*** components and exported for re-use by the ***consumer*** components.

1. The HOC creator function is called and passed the general component as a parameter, along with a string descriptor (more on that later).
2. Its result is a HOC, which is exported. This exported HOC allows the general component to be combined with another component.
3. One or more other components call this HOC, to combine themselves with the general component.
4. Its result is a component which has almost identical props as the combined component, except that it includes one additional prop. This additional prop, named by the string descriptor from step 1, contains the props to be passed to the general component.

![Diagram depicting the generic HOC creator pattern outlined in the steps above](/images/articles/react-generic-hoc-pattern/with-hoc-pattern.png)

## Example

Let&#39;s look at a realistic example to see how this pattern can be applied.

Suppose we have a `Tooltip` component, which takes a `children` prop and a `contents` prop. The `children` prop will have the component that triggers the tooltip. The `contents` prop will have the component that should be shown inside the tooltip.

```typescript
interface TooltipProps 

export function Tooltip(props: TooltipProps) 
```

Now in our component library, there are several different components that might all need to have a tooltip.

For example:
- Button
- Checkbox
- Image

For each of the above three components, we want to allow their consumers to provide an optional tooltip. But we don&#39;t want to couple these three components too closely to the Tooltip component. And we want the re-use of the Tooltip component to be as easy and straight-forward as possible.

First, in our `tooltip.tsx` file, lets create and export an HOC that exposes `Tooltip` in a re-usable manner:

```typescript
export const withTooltip = createWithHOC(Tooltip, &quot;tooltip&quot;);
```

Notice that `createWithHOC` doesn&#39;t know much about `Tooltip`. It just receives its definition and a string descriptor - &quot;tooltip&quot;. However, what it returns - `withTooltip` - is very useful.

Here&#39;s a simple implementation of our `Button` component:

```tsx
interface ButtonProps 

export const Button_ = (props) =&gt; 
    
  );
};

export const Button = withTooltip(Button_);
```

If we were to consume `Button` directly, without the `withTooltip` wrapper, it would have the `children` and `onClick` props, as we would expect.

However, with the `withTooltip` wrapper call, `Button` is now augmented with an additional `tooltip` prop. (Named by the string &quot;tooltip&quot;, which we originally passed to the `createWithHOC` call in our `tooltip.tsx` file).

So now the props of `Button_` look like this, from a consumer&#39;s point of view:

```typescript
// Note: Fictitious interface name.
// This is just the un-named type of the props parameter of the
// `Button` component exported in the previous code sample.
interface ButtonProps 
```

So when we consume `Button`, our code can look like this:

```tsx
const Item = () =&gt; }   // &lt;--  props
    &gt;
      🗑️
    
  )
}
```

This will have the same net effect as if we had consumed `Button_` directly, wrapped in `Tooltip`, passing the appropriate props to each.

```tsx
const Item = () =&gt; 
```

## Advantages

I found three advantages of using this pattern, where applicable:

- Smaller consumer code
- Aesthetically pleasing consumer code
- Ability to constrain re-use of general components

### Smaller consumer code

Consumer code is significantly smaller and less indented, as we are relying on props rather than nesting. This benefit can add up quickly when, say, rendering multiple instances of the same component type side-by-side.

Here&#39;s an example of multiple buttons with tooltips:

```tsx
const Item = () =&gt; 
```

### Aesthetically pleasing consumer code

Consumer code is also more aesthetically pleasing, when relying on props. It presents as a cleaner, more compact and concise list of components.

Here&#39;s an example, in which we render different kinds of form controls side-by-side.

Using the generic HOC pattern, each form control is passed a prop to configure one or more of:
- A label
- A default
- Validation logic

```tsx
const Item = () =&gt; 
```

All controls appear at a consistent level of indentation and so do their props. This is easier to read and more aesthetically pleasing than if each control was nested in a different set of containers (validation, etc) and appeared at inconsistent levels of indentation.

&gt; Aside: This could be viewed as a variant of the principle of &quot;cleaning up irregularity&quot;, discussed in Dustin Boswell&#39;s book [_The Art of Readable Code_](https://www.oreilly.com/library/view/the-art-of/9781449318482/), under Aesthetics (Chapter 4, pp. 37).
&gt; The code follows a regular pattern, making it easier to visually scan and add/remove similar items (in our example, form controls).

### Ability to constrain re-use of general components

An additional advantage of this pattern is that we could, if desired, constrain the re-use of our general component.

For example, we could keep the `Tooltip` itself private to its module folder and only export the `withTooltip` HOC. Then we could only apply `withTooltip` to components that we are confident will work well with the `Tooltip`.

As a consumer, it would be easy to determine whether a given component supports the tooltip or not – we could simply examine the available pops via our IDE&#39;s ***auto-suggest*** feature.

Here&#39;s an example with Visual Studio Code IntelliSense:

![IntelliSense suggesting the `tooltip` prop on an `IconButton` component in the conwy.co code-base](/images/articles/react-generic-hoc-pattern/vs-code-intellisense-example.png)

## Implementation

Here&#39;s the `createWithHOC` function I developed in Typescript for creating the `with*` HOC creator.

```tsx

export function createWithHOC(
  HOC: ComponentType,
  hocName: THOCName,
)  else 
    };
  };
}
```

I also published it as a Github Gist: [create-with-hoc.ts](https://gist.github.com/jonathanconway/8a4144df3304505f720429e464641a4a).

Please feel free to re-use, tweak and/or share as desired. I hope someone out there finds it useful!</content>
  </entry>
  

  <entry>
    <title>How to lose weight (without getting lucky)</title>
    <link href="https://conwy.co/articles/lose-weight" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>lose-weight</id>
    <content xml:lang="en" type="html">&gt; Summary: To lose unwanted fat in a healthy, sustainable, frugal and environmentally-friendly way, follow a whole-food plant-based low-fat diet and burn excess fat by doing strength and cardio exercise on a daily basis.

Over the last few years I&#39;ve been making steady progress toward getting in better shape. It&#39;s not been a straight path, but I&#39;m pleased to report that I&#39;ve been able to get very close to my ideal body type several times (body-image issues aside) and am much closer now than I was even a few months ago!

In this article, I&#39;ll try and share what&#39;s worked for me.

BTW, the title is a riff on [*How to get rich (without getting lucky)*](https://www.goodreads.com/book/show/53662964-how-to-get-rich) by Naval Ravikant, one of my favourite modern writers.

&gt; Aside: Caveat: I don&#39;t pretend to be any kind of authority on this. This article will just be a catalog of ideas I collected from various sources (some evidence-based, some experience-based) which seem to have worked for me.

## Goal

Before launching into the tactics, I want to clarify my goal. I didn&#39;t actually start out with a clear goal, but rather I developed the goal over time and refined it quite a few times.

My basic goal now is a lean-muscular, moderately &quot;athletic&quot; body.

There are some constraints around this goal:

- **Long-term.** Not just for a few months. Ideally life-long.
- **Healthy.** Not involving toxic chemicals or unhealthy extremes.
- **Frugal.** Spending little or no more money on food than I would otherwise.
- **International.** I can move to another location while maintaining the diet/lifestyle.
- **Environmentally conscious.** At least not adding more damage to the natural world than I would otherwise.

As you can imagine, adding these constraints necessarily adds some complexity. However I still found it doable, given some ingenuity and (importantly) persistence!

## Motivation

&gt; Pull-quote: “Visualize your success and then go after it.”
&gt;
&gt; – Arnold SCHWARZENEGGER

It&#39;s important to always have a &quot;north star&quot;, &quot;dream&quot;, &quot;vision&quot; or whatever you want to call it.

Some thoughts that keep me going:
- I can achieve something difficult that even some great or famous people have struggled with.
- I&#39;ll feel &quot;light as a feather&quot; and energized throughout the day, carrying less weight around.
- Looking good, with a body that is pleasant to behold, is a plus, for myself and possibly others.
- I see myself keeping physically fit into my 70s, regardless of what happens to me, health or otherwise. This is a life-long vision.
- Avoiding serious health issues associated with obesity and unfitness, such as cardiovascular issues and cancer, is well worth the effort.

When all else fails, I just imagine having ripped abs while partying on a yacht in Fiji. That usually does it! 😄

![Stock photo of people jumping off a boat off the coast](/images/articles/lose-weight/yacht.jpg)

These all visions congeal into an image in my mind of a successful, active, fit, mature adult.

I think overall health is critical. I would never go on any regimen – diet, exercise or otherwise – that directly risked my overall health. Keeping overall health in mind is good in and of itself. But it also supports your weight loss goals. You can maintain consistent exercise and diet more easily if you are in good health most of the time.

It&#39;s important to celebrate wins – large and small. If you notice your looks or energy levels improving, take a moment to glow with self-pride and celebrate your achievement! Even if there are no visible changes, if you&#39;re able stick to your routine for some period of time, celebrate that too. Positive reinforcement of health behaviour is more sustainable than negativity and self-punishment.

## Lifestyle system

When making significant lifestyle changes, it&#39;s often helpful to step back and think of your lifestyle as a system. In a systems approach, you develop a network or web of goals. These goals are connected to eachother, and thus reinforce eachother.

For a simple example: you could move home to a location that is at least 15 minutes walk from the nearest public transport or park your car 15 at a location that is minutes walk from your home. Then you are forced to walk at least 30 minutes per day - from and to your transportation. This small change in habits automatically generates an additional 30 minutes per day of exercise.

The effect is amplified when you combine elements that are beneficial on their own and mutually reinforcing. For example, you could begin doing all your shopping at a supermarket that&#39;s 15 minutes from your home. Thus you set up a pattern of eating healthier (your supermarket is more likely to have healthy food like fruits and vegetables) **and** walking for 30 minutes daily.

For more information, you can check out books on systems thinking such as:

* [Thinking in Systems • Donella MEADOWS](https://en.wikipedia.org/wiki/Thinking_In_Systems%3A_A_Primer)
* [Early Retirement Extreme • Jacob LUND-FISKER](https://archive.org/details/earlyretiremente0000fisk)

## Mind-state

&gt; Pull-quote: “Meditation practice is also a kind of food because it nourishes us. Consider the practice offered by the Buddha to be a kind of food. Any practice must be a kind of food. Walking is like a delicious food. Eating is a delicious food, sitting is a delicious food, and working meditation is also delicious food.”
&gt;
&gt; – Thich NHAT HANH • _How to Eat_

I practice a few minutes of daily [mindfulness meditation](/articles/mindfulness), which helps to reduce anxiety and reduce mental blocks. During this I take some time to wish strength, health and wellness, both for those I know, and for myself. I try to cultivate a spirit of &quot;non-grasping&quot; generally. I try to notice when I&#39;m mentally reaching toward something, whether it&#39;s food or rest. Simply noticing this helps me to slow down and go back to a more relaxed, reflective frame of mind, putting me more in the drivers seat and in control of my actions.

There are some other mental tricks I use to manage anxiety, such as focusing on next actions and the future, while deliberately moderating expectations and reducing thoughts about the past.

Understanding and harnessing the effort-reward cycle I also find important. For example, I try to do my morning exercise before having my first shower or drinking my first coffee. This helps motivate me to do the exercise (effort) in order to get the reward (shower, coffee). I use a similar cycle for my afternoon/evening exercise. First I exercise (effort) then I enjoy dinner/supper (reward). These cycles can show up in all kinds of little parts of life, so I try to make best use of them whenever possible.

&gt; Pull-quote: “The best moments in our lives are not the passive, receptive, relaxing times...the best moments usually occur when a person&#39;s body or mind is stretched to it&#39;s limited in voluntary effort to accomplish something difficult and worthwhile.”
&gt;
&gt; – Mihaly CSIKSZENTMIHALYI • _Flow: The Psychology of Optimal Experience_

Flow activities can help you active and energized and reduce unnecessary eating.

When one feels tired, it may seem that food and rest are needed. But counter-intuitively, I&#39;ve found that&#39;s often not the case. In fact, more activity seems to generate more energy. Note that the activity need not be intense or stressful. I&#39;ve had the best experiences with moderate activities – a steady walk or hike, slow body weight exercises, a lazy afternoon swim or even chores around the house like cleaning and cooking. 

## Monitoring

Any long-term endeavour should have appropriate monitoring.

I&#39;ve given up on measuring body weight or mucking around with measuring tape.

***A quick look in the mirror on a regular basis seems the surest measure!***

And the best way to avoid making excuses.

There is one other kind of monitoring I consider crucial: blood tests. These can be obtained relatively inexpensively (at least in Australia, the UK, etc). You take the results to your GP/doctor and they tell you if you have any deficiencies. In my case, there was a minor calcium deficiency, which I remedied by adding a little yogurt to my diet and taking Vitamin D tablets (to aid absorption).

Monitoring aside, I think it&#39;s best to focus on **behaviour change** as a goal, rather than a particular body type, size, etc. Your bodily appearance can fluctuate a lot, especially over short periods like a few days or a week. Even if your goal is to look a certain way, it can be difficult to get to that goal if you cannot sustain effort over long periods such as months. So it&#39;s better to focus on changing your behaviour – eating the right foods and right portions, doing the right kinds and quantities of exercise, etc.

Observe carefully your progress in developing better habits and celebrate your wins in the area of behaviour change, regardless of what your body looks like on a given day. Over time, you will move closer to your ideal bodily appearance and feeling, as long as you&#39;re performing the right actions and doing so consistently.

## Routine

&gt; Pull-quote: “We are what we repeatedly do. ... Excellence, then, is not an act but a habit.”
&gt;
&gt; – Aristotle

&gt; Pull-quote: “Don&#39;t Make Me Think”
&gt;
&gt; – Steven KRUG

&gt; Pull-quote: “Each evening, there is a tiny moment—usually around 5:15 p.m. that shapes the rest of my night. ... the ritual is changing into my workout clothes. If I change clothes, I know the workout will happen. Everything that follows—driving to the gym, deciding which exercises to do, stepping under the bar—is easy once I’ve taken the first step.Don&#39;t Make Me Think”
&gt;
&gt; – James CLEAR • _Atomic Habits_

One thing that has helped me the most in my health and fitness pursuits is simply **maintaining a consistent daily routine**. Making a habit of daily exercise and healthy eating ensures consistent and steady progress toward my goal.

Strong habits tend to be self-reinforcing. Once you get accustomed to taking that regular morning walk or that afternoon workout, it becomes automatic and a way of life.

My routine has functioned as a kind of &quot;fall back&quot; which I can execute almost mindlessly, without stressing and lapsing. It&#39;s a **simple default** that enables me to accomplish my tasks as easily and directly as possible, without hesitation or doubt.

This has actually been good for my mental health too. I&#39;m less anxious when I don&#39;t have to constantly worry about what to do next. Of course, I do sometimes change my routine, but I try to do so in a relaxed, contemplative frame of mind, not in the heat of the moment.

I&#39;ve been able to maintain my routine pretty consistently throughout international travel, changing work hours and various ups and downs of life.

One trick is to make the routine flexible and focus primarily on *activities*, rather than timing. So if I miss a morning workout, it&#39;s Ok, not the end of the world. I just need to do that workout in the evening instead. So the *times* are flexible, while the *activities* remain solid.

I also have certain routines in the evening that help me to wind down, relax and avoid unplanned snacking. These include dimming the lights to create a cosy atmosphere, according to the famous Scandinavian [Hygge](https://en.wikipedia.org/wiki/Hygge) effect. Even on travel this can be done quite effectively with a portable USB lamp and/or tweaking my laptop display configuration. I also like to floss and brush my teeth, which gives me a fresh taste that helps to avoid any temptation to eat.

## Exercise

Exercise is a critical part of my routine. Exercise builds and maintains muscle tone, sustains health (including mental) and energy levels and reduces appetite / food cravings.

There&#39;s a fantastic cumulative effect with exercise: as you lose fat and gain muscle, the exercise gets easier and you feel less hungry, which make it easier to exercise more, etc. The challenge, of course, is to maintain consistency and not slack off.

All the exercises I&#39;m about to list are:
- Reasonably environmentally friendly do not by nature involve any damage to the environment
- Can be done in practically any major city or town, at any time of day
- Are healthy and low impact on your body, unlikely to cause serious injuries when done long term, assuming they&#39;re done with reasonable care

I try to do at least one session of HIIT, strength training and walking every day, and some swimming every week.

Keeping the exercises simple and safe increases the likelihood of doing them consistently, which I think is critical to getting most of the benefits of exercise.

### Strength training

Here&#39;s a list of the specific strength exercises I do.

I like to do body weight exercises, also known as callisthenics. These include:

- Pull-ups and muscle-ups on the bar. Forward and reverse grip. Several sets, each as much as I can while keeping form.
- Push-ups. Lateral and tilted up or down. On the bars or the floor.
- Dips. On the bar or between two chairs.
- Ab crunches. While resting on the bar or hanging off the bar, or lying on the floor with a weight.
- Step-ups onto a low bar, large stair step, rock, or even bedside.
- Military presses with weight or resistance band.
- Bicep curls with with weight or resistance band.
- Some other body-weight exercises like planking, squats and lunges.

Some other points:

- **Core strength.** Try to incorporate core / ab training into as many exercises as possible. Abs are involved in many full-body exercises, so by focusing a little on your abs, you get a kind of bonus &quot;2 in 1&quot; effect. While doing pull-ups, push-ups, band rows, etc. you can &quot;feel into&quot; your abs and make sure they&#39;re coming along for the ride.
- **Quality over quantity.** In each workout, I try to prioritise overall quality. First priority is safety – none of the movements should cause severe pain or injury. Next, I want to strain the muscles enough to feel satisfied that it was a thorough workout. This involves a kind of &quot;good pain&quot; or burning feeling, where you know that your muscle was tested. This doesn&#39;t necessarily have to involve training to complete failure.
- **Variation.** I try to make each workout a little different and unique so that each muscle group is being adequately challenged. This could mean varying the grip, intensity, number of reps, order of reps or many other possible variables.

In case you didn&#39;t notice, many of these can be done either with or without the gym! I can just use body weight, furniture or outdoor facilities. This makes the exercise routine easy to maintain while travelling and resilient to unexpected changes in the my day plan.

Strength-training builds muscle, which aids weight loss in multiple ways:
- Speeds up metabolism, aiding digestion and fat loss
- Improves general stamina for cardio
- Good for general health - heart, lungs, etc.

I aim for 3-5 strength training sets every day.

### HIIT

I&#39;ve recently been practicing [high-intensity interval training](https://en.wikipedia.org/wiki/High-intensity_interval_training). Here I do body-weight cardio exercises at a high intensity, with 20 second breaks, for a period of 5-10 minutes.

HIIT seems to generally accelerate my progress. Plus, I&#39;ve seen plenty of studies showing its benefit for overall health.

The real beauty of HIIT is its simplicity, minimalism and time efficiency. No equipment is needed, just a little floor-space and discipline! And one can almost always spare 5-10 minutes out of a 16-hour waking day. These factors make it simple to maintain HIIT during travel or changes to my day plan.

My HIIT routine varies, but typically consists of:
- Burpees
- Squat-jumps
- Star-jumps
- Push-ups
- Back squeeze while lying on chest
- Jogging on the spot

I found HIIT to be the toughest exercise to begin, yet the easiest to complete once started. Funny that!

YouTube videos like this one are a helpful aid: [Intense 15 Minute BURPEE ONLY HIIT Workout for Serious Results!](https://www.youtube.com/watch?v=X34SBfiT7xo).

I use HIIT as a replacement for walking, aiming for 1 HIIT session every second day during periods where I can&#39;t walk.

### Walking

Yes, simply walking.

The real beauty of walking, apart from being minimal and easy to do almost anywhere on travels, is how it can be combined with other activities. With smartphone in hand, I can tune in to a fantastic array of audio material: [audiobooks](/reading), podcasts, online courses and great music.

I can also combine it with travelling to appointments, shopping, remote meetings, connecting with nature (bush-walking) and just general exploration of the world. 🙂 It&#39;s wonderful to become immersed in my environment and visiting familiar streets and parks feels similar to visiting old friends.

During walking, I try to focus on posture, keeping a tall, straight upper back. Posture issues are a growing concern these days, not just for IT/tech workers who often have to face forward to use laptops, but also now for the general public, who are often consuming content heads-down on mobile devices.

You can add novelty to walks by taking different routes, varying your pace and stride, noticing and engaging with strangers from time to time and combining various activities with your walks like picking up packages or sight-seeing.

I aim for 30 minutes to 1 hour of walking every day.

### Swimming

I like to do laps at the local pool. Maybe pool-swimming is not 100% good on the environmental scale, so I might someday switch to ocean or lake swimming. Swimming is a great all-round cardio workout and very safe and low-impact. And being in the water is fun!

I aim for one session per week.

### Standing

I&#39;ve been trying to stand for more hours of the day. Studies have shown that spending more time standing is positive for overall fitness and burns more calories. Most modern offices have standing desks.

At home it&#39;s easy to turn almost any surface into a standing desk using a sturdy cardboard box or a crate or two. Even better, you can combine the standing with moving around and taking mini-breaks from work to do small chores such as cleaning up, vacuuming, etc. So you get two-in-one: fitness _and_ a cleaner home! 

I aim for at least 4 hours of standing per day.

### Managing pain

&gt; Pull-quote: “God ... does not pet the good man: He tries him.”
&gt;
&gt; – Seneca

To be sure, there&#39;s some physical pain involved in regular exercise. Feeling fatigued, occasional muscle aches, the odd heel spur. Assuming full care is taken to avoid injury, workouts can just feel tough sometimes.

I don&#39;t have any one sure answer to &quot;solve&quot; inherent pain in exercise, but more like a set of small &quot;mind hacks&quot; that help me to manage pain and stay the course.

- **Exercise even when I don’t want to.** *Especially* when I don&#39;t want to, so as to reinforce the habit.
- **Meditation, mindful breathing.** Deep inhalations, breathing into the pain, being with my body.
- **Effort-reward cycle.** Making the effort with the knowledge that I&#39;ll feel better at the end. (And yes, 99% of the time I do feel better!)
- **Awareness of body.** Especially the effect of heat/cold, caffeine, sleep. When drowsy or lethargic, I remind myself of external factors to avoid excusing myself from putting in work.
- **Mental imagery.** I like to use my imagination to create pleasant and comforting imagery so that I feel relaxed and happy throughout the painful episode. For example, when working out in the cold, I might put on some jazz music and imagine being in an Italian restaurant. Or when it&#39;s intensely hot, I might imagine being on an island in the Mediterranean, enjoying an ocean view from a luxury hotel. Persisting through tough times with imagination can unlock &quot;coping&quot; parts of your mind that you never knew existed!

### Enjoying the weather

I&#39;ve found weather isn&#39;t usually a reason not to exercise. Actually, with the right mindset, I find the weather more of an incentive.

When it&#39;s hot and sunny, I immerse myself in the intensity of the heat and sunshine (with generous application of sunscreen, of course).

When its cold and wet, I savour the calming and relaxing feeling of the coolness and rain (under the comfort of a sturdy umbrella).

When it&#39;s humid and cloudy... well... I tell myself to toughen up! 😄 (Recalling Stoic quotes can help.)

Suitable clothing and gear really helps here.

- When it&#39;s hot, I wear minimal clothes, light materials and clothing styles that free up my body, like shorts and singlets.
- When it&#39;s cooler, I wear clothes that conserve heat while keeping my body flexible, like close-fitting long-sleeve wool shirts and tight pants.
- When it&#39;s rainy, I wear a comfortable rain jacket, pack an umbrella and wrap my backpack in a waterproof bag cover to keep my valuables dry. I also waterproof my boots with beeswax and maybe some proofing spray.
- I like to wear good quality, comfortable shoes, typically hiking boots.

With the right clothing, equipment and preparation, working out in any weather – from sunny to rainy – is no problem at all.

### Music

Music can be a great motivator during HIIT and intense strength training. I like to listen to music with a strong rhythm and high dynamic range. Some favourites include music from the [Ozora](https://www.youtube.com/results?search_query=ozora) Psytrance festival, smooth jazzy tracks of [Dimitri from Paris](https://en.wikipedia.org/wiki/Dimitri_from_Paris) and [classic 70s Brazilian samba mixes](https://www.youtube.com/results?search_query=+brazilian+samba+grooves).

## Diet

I&#39;ve settled on the [mediterranean diet](https://en.wikipedia.org/wiki/Mediterranean_diet) as my diet of choice. This diet is plant-based, mostly vegetables and whole grains, with some added fish, dairy and fruit, and plant-based fats like olive oil. It&#39;s high in nutrients, filling, low-calorie and I find it delicious!

&gt; Aside: Any diet you choose should be as enjoyable and tasty as possible. This is so you can stick with it. Unless you have the will-power of a saint, a diet that isn&#39;t enjoyable, interesting, varied and satiating will be very difficult to stick with, even if it technically meets your nutrition requirements.

Environmentally it&#39;s maybe slightly less optimal that pure veganism/vegetarianism, due to the fish and dairy content. I am investigating more sustainable options such as synthetic fish and dairy alternatives. Also there are many high quality and cheap equivalents of most animal products: legumes (including peanut butter) can replace fish, tofu and Nattō can replace yogurt and yeast flakes can replace cheese (protein) and calcium can be supplemented.

### Meals

Meals I prepare regularly:

- **Fruit.** In-season berries or citrus fruits. Combined with a cup of plain or sugar-free flavoured yogurt. This combo I find especially refreshing in hot weather and/or just after an intense workout. High in Vitamin C.
- **Sardines/Salmon/Oysters.** Occasionally I eat some seafood, to maintain adequate Vitamin B12 intake, but I prefer to limit it. I think fish from a tin is best – bones included, as they provide nutrients such as Calcium, Vitamin D and other important micronutrients. I like to fry them gently and season with lemon/lime juice or vinegar and top with ground pepper. Side of wholemeal pasta or a bread roll. Maybe complimented with tomato sauce (simply onions fried in tomato paste and vinegar) and/or a quarter of avocado.
- **Veggies.** Steamed in a pot. Broccoli, cauliflower, kale, brussels sprouts, etc. With some added carrot, capsicum, red onions, button mushrooms or whatever else I feel like. Sprinkled with vinegar, a single stick of cheddar cheese cubed or a half-cup of yeast flakes and generous herbs and spices, including hot chilli powder and a carefully measured tablespoon of olive oil. Veggies are high in vitamins and minerals, fibre and antioxidants.
- **Oatmeal.** One half-cup of oats mixed with a teaspoon of cocoa in a small bowl. Soaked in water for a few minutes - hot or cold. Cooked for a few minutes if I have a microwave. Topped with a tablespoon of peanut butter, 5 small pieces of dried fruit and some cinnamon powder. The dried fruit adds a perfect level of sweetness and chewiness with minimal calories and practically zero sugar spike. Makes a great dessert!

These meals can all be prepped in ~20-30 minutes each and I&#39;m rarely spending more than 45 minutes per day in the kitchen.

&gt; #### Aside: Toppings
&gt; I prefer to use oils/fats as toppings rather than cooking with them. This is for calorie-control reasons. Basically I can use smaller quantity while enjoying virtually the same taste and flavour. For example, I can just measure out one tablespoon of olive oil per day as a topping for the veggies, rather than spraying olive oil into a pan adding an uncontrollable amount of calories.

The ingredients are cheap, available, healthy, reasonably environmentally friendly, simple to store and cook.

- **Cost:** Mostly cheap and can be purchased in bulk or found in aisles. The fresh fruit and veggies can be purchased frozen to save cost and studies show that in frozen form they are just as nutritious as refrigerated, and possibly even more nutritious!
- **Availability:** Thanks to the wonders of modern globalised trade, I&#39;ve found most of these are available in most major cities and metro areas in much of the developed world. I do donate to food banks and other initiatives, with the hope that we will eliminate hunger and malnourishment for all people.
- **Health:** Nutritious, whole food, no added sugar, high-fibre, high in anti-oxidants, low-calorie.
- **Environment:** There&#39;s no beef or chicken and the dairy portions are modest. Even the seafood is relatively good - consuming bottom-feeders like sardines has a lower environmental impact.
- **Storage:** Most of the stuff can just be kept in a cupboard. I&#39;ll usually pick up the veggies the same day I eat them, but they keep pretty well in the fridge if I decide to do a weekly shop. Frozen veggies can, of course, be kept in the freezer indefinitely. An additional advantage of plant foods is that they tend to spoil less and don&#39;t produce harmful bacteria when not cooled (say, when the power goes out, the fridge fails or you just forget to put them in the fridge).

&gt; #### Aside: Nattō
&gt; There is one food item I didn&#39;t mention that I have once or twice a week: [Nattō](https://en.wikipedia.org/wiki/Nattō). This remarkable fermented soybean snack originates in Japan and apparently is a part of the reason Japanese people are so long-lived. It contains Vitamin K2, a surprisingly rare nutrient, which is great for bone health, given a diet with sufficient calcium and Vitamin D. It&#39;s only $3-5 for a pack of 3 and can usually be found in small Asian grocers.

&gt; #### Aside: Spicy food
&gt; Everything I&#39;ve read indicates that hot and spicy foods are good for health. Capsaicin and other chemicals found in chilli peppers and other hot foods are great for reducing bodily inflammation, which reduces risk of cancer and other diseases. Spicy foods seem to also increase my feeling of satiation after a meal.
&gt; Some of my favourite spicy foods include:
&gt; - Cayenne pepper
&gt; - Hot chilli pepper - great topping for vegetable and seafood dishes
&gt; - Chilli flakes - great for soups and stews
&gt; - Black peppers - great with seafood and tofu
&gt; - Scotch bonnet peppers - great for bean dishes. Especially Caribbean classics such as black beans and plantains.

### Drinks

I only drink water and plain coffee or tea (no sugar or milk, zero-calorie, always before 3 PM).

Drinks should always be zero-calorie, in my opinion. Liquids are the worst way to get calories - they&#39;re typically over-processed, resulting in insulin spikes. And you don&#39;t get to feel full and satisfied, because you&#39;re consuming them so fast. I&#39;ll never understand why some people are into shakes; I find them inconvenient, complicated and messy.

&gt; #### Aside: Timing coffee
&gt; Despite its many benefits, on the downside, there is some evidence that caffeine disrupts calcium absorption. For this reason, it&#39;s probably best to limit caffeine and avoid pairing it with your calcium-containing meals. Caffeine can also interfere with sleep, if taken too late in the day. To address both of these issues, I generally limit my caffeine intake to 3 cups per day and only consume it before 3 PM, during which time I&#39;m mostly fasting anyway. I consume all my calcium-rich foods later than 3 PM, usually 5 PM or later.

### Portion control

Importantly, I control and measure all the ingredients out. This gives me pretty much total control over calories.

I don&#39;t use any tricky or sophisticated equipment, just simple measuring rules, such as the following:
- Hand-full (pasta)
- Punnet (berries)
- Pot (yogurt)
- Can (fish)
- Piece (citrus fruit, bread roll, dried fruit)
- Quarter (avocado, potato)
- Measuring cup scoop (oats)
- Tablespoon (olive oil, lemon/lime juice, peanut butter)
- Stick (cheese)

When preparing any meal, I simply follow the same predictable routine, with the same quantities. For example, only 2 hand-fulls of pasta per day, or only 1 stick of cheese.

I can work out the calories fairly easily, by examining the packaging or searching online, then dividing by the quantities. For example, 2 hand-fulls of pasta are about 1/8th of a pack, which is ~436.25 calories.

Here&#39;s an example of a calorie table, based on a spreadsheet I currently use.

| Food item         | Daily portion  | Calories | Fat (grams) | 
| :-                | :-             | :-       | :-          |
| Avocado           | 1 quarter      | 80       | 5           |
| Brussels sprouts  | 1 bag          | 210      | 0.5         |
| Chickpeas         | 1 can          | 310      | 2.5         |  
| Cocoa             | 2 teaspoons    | 75       | 1           | 
| Dates             | 5 pieces       | 80       | 0.25        | 
| Hazelnuts         | 5 pieces       | 25       | 2           | 
| Honey             | 1 teaspoon     | 30       | 0           | 
| Oats              | 1 cup          | 230      | 2.5         |  
| Sardines          | 1 small can    | 145      | 2.5         |  
| Seeds             | ½ teaspoon     | 35       | 1           | 
| Strawberries      | 1 punnet       | 100      | 0.5         |  
| Tomato paste      | 2 tablespoons  | 100      | 0.25        |  
| Vinegar           | 2 tablespoons  | 30       | 0           | 

With these simple measurements, I don&#39;t have to think much about the quantities when preparing and consuming meals. I just follow the routine &quot;blindly&quot; and rely on &quot;force of habit&quot; to override and overwhelm any possible urge to cheat and add too much or too little. This consistency has helped me overcome temptation to overeat or under-eat. It took some time to build up the habit, and I&#39;ve had occasional relapses, but overall I&#39;ve maintained my diet plan more often than not.

By measuring ingredients in a standardised, repeatable, &quot;unthinking&quot; way, I can &quot;lock in&quot; a certain number of calories per day. This allows me fine-grained calorie control. This way I can create a long-term caloric deficit in a balanced, controlled way and avoid the dreaded &quot;yo-yo dieting&quot;, where extremes of under-eating and over-eating lead to stress and missing weight-loss goals.

While I think calorie counting is a very useful **measurement** tool for portion control, I would prefer not to lean too heavily on it as a **motivational** mechanism. To sustain healthy eating patterns over the long run, I think firm routines and mindfulness are more reliable.

&gt; Aside: Recommended daily caloric guidelines based can be found at websites such as [WebMd](https://www.webmd.com/diet/calories-chart), [EatForHealth](https://www.eatforhealth.gov.au/nutrition-calculators/daily-energy-requirements-calculator) and [MyPlate](https://www.myplate.gov/myplate-plan).

&gt; Aside: I think it&#39;s just as important to get *enough* calories as it is to *limit* calories. Chronic under-eating can lead to health issues and compensatory over-eating, which can throw a good routine out of order. I find it better to avoid extremes either way. To lose weight, it&#39;s better to sustain a small deficit over a long period of time. Say, 200 calories per day over several months.

With this careful diet plan in place, I only need to store the necessary ingredients in my home. So I have no unhealthy foods lying around to be accidentally snacked on. This makes it easy to stick to my diet and, to paraphrase Rico Mariani, [&quot;fall into the pit of success&quot;](https://learn.microsoft.com/en-us/archive/blogs/brada/the-pit-of-success). Even within my approved list of ingredients, I keep the higher-calorie items (such as peanut butter and dried fruit) stowed away in the fridge or drawer, out of harm&#39;s way. 🙂 This habit of minimizing stored food works great with my [minimalist lifestyle](https://en.wikipedia.org/wiki/Simple_living) and is also convenient for extended periods of travelling.

### Avoiding added sugar

&gt; Pull-quote: “Stay strong.
&gt; Get off the sugar train.
&gt; Get off the addiction.
&gt; Stop eating sugar.”
&gt; – Discipline Equals Freedom • Jocko WILLINK

Many perfectly healthy foods contain sugar, including fruits, vegetables and wholegrains.

The problem isn&#39;t sugar or carbohydrates per-se. It is the ***processed sugar*** that is added to the food that&#39;s the problem as well as alcohol in any form.

The problem is that added sugar affects the human brain in ways that cause addiction. This addiction manifests in hunger, cravings, high appetite.

The key to avoiding sugar addiction is to eliminate added sugar from your diet, relying instead only on the naturally occurring sugars in whole foods, including fruits, vegetables, nuts, beans and grains such as pasta.

Other benefits to avoiding sugar include reduced likelihood of diabetes, tooth and gum issues and more stable energy levels.

### Minimising dietary fat

&gt; Pull-quote: “Other than in the experimental situation of gross carbohydrate overfeeding, conversion of carbohydrate to stored lipid does not occur to any appreciable extent in humans.”
&gt;
&gt; – Essentials of Human Nutrition • Jim MANN, Arthur TRUSWELL

When we talk about weight loss, we usually mean ***fat loss***. We are probably not interested in losing muscle tone or bone density.

The body can easily store dietary fat as bodily fat (&quot;adipose tissue&quot;), as it is already in the form fat (&quot;lipid&quot;). By contrast, the body has more difficulty converting other kinds of macronutrients – carbohydrates and protein – into fat for storage. So consuming less fat and more carbohydrates and protein in the diet results in less fat gain overall. Yes, this is even true when calories are held constant!

The process of converting sugars into fats is a process called &quot;de novo lipogenesis&quot;. According to various studies (such as this one: [De novo lipogenesis in humans: metabolic and regulatory aspects](https://pubmed.ncbi.nlm.nih.gov/10365981)), only a relatively small portion of the energy absorbed from carbohydrates is stored as fat on the body. Most circulates in the bloodstream (&quot;glycogen&quot;) and is expended for bodily processes (including digestion), expended in normal daily activity, released as body heat (&quot;thermic effect of food&quot;) or stored in the liver.

In my personal experience, I found that I could consume a far higher caloric content while still losing weight, if I strictly limited my daily fat intake. It&#39;s not necessary or possible to completely eliminate fat from the diet – even fruits and vegetables contain small amounts. But by following a whole-food plant-based diet and avoiding or limiting fattier foods such as avocados, nuts and seeds, fat content can easily be reduced to a very small amount, which can easily be burned off during moderate intensity fasted exercise such as a morning walk.

### Enjoying food

I try to eat a bit slower and more mindfully. Famous spiritualist Thích Nhất Hạnh wrote a whole book on this topic: [How to Eat](https://www.penguinrandomhouse.com/books/545835/how-to-eat-by-thich-nhat-hanh/), which I&#39;ve started reading. Some studies show that if we take 20 minutes or more to finish a meal, we&#39;ll feel more satisfied. Using small cutlery for eating, like a smaller fork or chopsticks, can help you to slow down and appreciate each bite more.

I like to eat while involved in some relaxing, social and/or moderately stimulating activity. Typically while in an online meetup, interacting in an online chat or forum, with friends and family, and/or watching or listening to something educational such as history or nature documentary.

One thing I noticed since childhood is that the layout of the food can really make eating an absolute joy! For example, I like to add small &quot;sides&quot; to my dishes that really pack a flavour and spice punch. I can combine different parts of the plate as I eat, creating a rich, varied experience. I noticed this kind of &quot;mix-and-match&quot; mode of eating is prominent in the more traditional world cuisines, no doubt for good reason.

- South Indian cuisine - thali
- Vietnamese cuisine - spring roles
- Spanish cuisine - tapas
- Mexican cuisine - salsas

So with my regular diet, I take inspiration from this technique of having small side portions, but adapt it to my own calorie control and nutrient constraints.

### Maximising food volume

&gt; Pull-quote: “People who eat the most vegetables and fruits tend to have the healthiest body weight and gain less weight through their adult years. Eating lots of low-CD [calorie-density] vegetables and fruits instead of other foods can help you shed pounds and keep them off.”
&gt;
&gt; – Barbara ROLLS • _The Ultimate Volumetrics Diet_

Popularised by Barbara Rolls, volume eating is a tool that can be utilised to help with weight-loss. It allows you to eat more food and feel fuller without eating too many of calories. The trick is to select foods that are more bulky and filling. These are typically plant-based foods such as leafy green vegetables, fresh fruits, whole grains and beans. Many of these foods are very healthy anyway, so you also get a health benefit from choosing them.

### Fasting

I like to do most of my exercise in the morning or afternoon, when I&#39;m feeling lightest and most alert. So I generally fast most of the day (except for coffee and a small post-workout snack) and do my main eating in the early to late evening. This is known as the [&quot;warrior diet&quot;](https://en.wikipedia.org/wiki/Intermittent_fasting).

Advantages of the warrior diet:
- Simple, repeatable eating schedule, since there&#39;s only one main period of cooking/heating and one place in which to do most of the eating
- It&#39;s very satisfying and filling to consume 2,000+ calories in a 4-hour period. I&#39;m never hungry at the end of it, as long as I finished it all and drank enough water.
- I don&#39;t get hungry much during the day either, since I&#39;m pre-occupied with work, exercise and whatever else I&#39;m doing. Caffeine also helps here.
- Intense exercise while fasted (such as HIIT and strength training) burns more fat, as the body relies on fat stores to provide the calories to fuel the exercise.

### Avoiding temptation

Whenever I&#39;m feeling some random unexpected hunger pang (which is pretty rare these days, thanks to the routines described in this article) I try to run through a mental checklist and this usually sorts me out.

- **Am I feeling stressed?** Maybe I need a brief meditation or even just a few minutes of simple box-breathing. This is usually not a problem while out, at work or elsewhere. 
- **Am I uncomfortable?** Maybe I just need to put on a coat or jacket, turn on the air conditioning briefly or go to the toilet.
- **Am I hydrated?** Thirst and hunger can be easily confused. I always carry a water bottle with me so I can hydrate regularly.
- **Am I tired?** This is more tricky during the day, but in the evening I can usually go to bed earlier if I need a bit more sleep.

I&#39;ve found that 9/10 times, it&#39;s not that I&#39;m genuinely hungry, but that I&#39;m using food as a distraction to cope with some other issue. If I can quickly find the root-cause and address it, I have no need of food.

Humans need to eat, but we don&#39;t need to eat that much, and certainly not as much as is pushed on us by the capitalist/consumerist system. If we feel hungry outside of mealtimes, it&#39;s likely for some other reason, not a genuine need for food.

There are still a few simple, cheap, easy fall-backs if I really desperately need to consume something small outside my usual mealtime.

- **Small piece of fruit.** Usually 20-50 calories is pretty negligible and I eat it slowly to enjoy it. Healthy and great while on-the-go.
- **Pickled veggies.** Especially cucumber and carrot. Pretty low-calorie and healthy.
- **Mint tea.** This refreshing drink provides a pleasant freshness, with zero calories or caffeine.
- **Brushing my teeth again.** I don&#39;t go nuts with this, but if I want to freshen up during the day, this is healthy zero-calorie way.

With food, I try save the best for last. Keep earlier-in-the-day snacks as bland as possible, such as small cans of fish or beans with just a little flavouring on top. The blandness of the snack will discourage you from over-eating. But toward the end of the day, eat a very tasty, nutritious and filling dinner. This will satisfy you and help you avoid cravings later in the evening when the temptation might be stronger. It can also motivate you beforehand, helping to power you through the day in order to get to the evening meal. This taps into the &quot;effort-reward&quot; cycle, an ancient part of the human experience. Additionally, if you really enjoy dinner, you will likely eat a sufficient quantity of calories at that time, which will help you to avoid accidentally under-eating, which leads to unhealthy &quot;yo-yo dieting&quot;. In short, the tastiest meal of the day should not be the snack-foods, which you&#39;re likely to over-consume, but a large evening meal, which is likely to be filling and well timed.

Finally, some little habits that give me a motivational boost sometimes:

- Simply wait for 20 minutes, most cravings will pass
- Look forward to tonight&#39;s or tomorrow&#39;s activities, including eating

### Herbs and Supplements

Certain herbs and herbal teas can help burn fat and/or reduce appetite. For example, there is some evidence that [drinking hibiscus tea reduces body fat](https://nutritionfacts.org/video/fat-blocking-benefits-of-hibiscus-tea/). Some [moderate Flaxseed consumption has also been shown to reduce body fat](https://nutritionfacts.org/blog/are-there-any-benefits-of-flaxseed-for-weight-loss/).

I&#39;m not very big on supplements, due to the cost, complexity and dubious health benefits. I do take one vitamin D tablet per day if I&#39;m not getting out in the sun much. I take regular blood tests and if the doctor recommends supplementation to remedy any deficiency, I&#39;ll that it.

## Conclusion

I hope you found some utility and inspiration in this article!

Maintaining fitness and health is best treated as a long-term game in my opinion. The changes should be gradual, cumulative and sustainable.

In my experience, the surest way to lose unwanted fat is to maintain a calorie deficit over a long period of time by exercising vigorously on a daily basis and sticking to a healthy and enjoyable eating routine.

The toughest aspect is to *persist over long periods of time*, which is why I emphasize simplicity, convenience, health, motivation and enjoyment! But Stoicism is a great help when times do get tough.

Optimizing my exercise and diet has been a fun and fascinating (though sometimes challenging) journey. I see it as a kind of [infinite game](https://en.wikipedia.org/wiki/The_Infinite_Game), something I can always get better/smarter at and that enriches my life.

## Further viewing

- [Food and Health on Coursera](https://www.coursera.org/learn/food-and-health)
- [The Miraculous Healing Power of Food • Anthony LIM](https://www.youtube.com/watch?v=Nuts6ZE5wok&amp;t=54s)
- [Miche, PhD • Michaela](https://www.youtube.com/@MichePhD)

## Further reading

- [Eat, Drink, and Be Healthy • Walter WILLETT](https://nutritionsource.hsph.harvard.edu/2017/10/15/eat-drink-and-be-healthy-willett/)
- [NutritionFacts.org • Michael GREGER](http://nutritionfacts.org)
- [Food - What the Heck Should I Eat • Mark HYMAN](https://drhyman.com/products/food-what-the-heck-should-i-eat)
- [Losing weight mega-thread on MrMoneyMustache.com](https://forum.mrmoneymustache.com/ask-a-mustachian/help-with-diet-and-weight-loss!-way-too-chunky!)
- [Essentials of Human Nutrition • Jim MANN, Arthur TRUSWELL](https://ebook.app.hcu.edu.gh/wp-content/uploads/2024/06/Jim-Mann-Stewart-Truswell-Essentials-of-Human-Nutrition-Oxford-University-Press-2012.pdf)
- [The Ultimate Volumetrics Diet • Barbara ROLLS](https://www.harpercollins.com.au/9780062060655/the-ultimate-volumetrics-diet/)

## Tools

Some tools to help you on your diet and fitness journey.

- [Callisthenics Parks](http://calisthenics-parks.com) - free outdoor gyms, all over the world
- [Free Outdoor Fitness](https://freeoutdoorfitness.net) - free outdoor gyms in Australia and New Zealand
- [RapidTables: Kilojoules to Calories conversion](https://www.rapidtables.com/convert/energy/kj-to-cal.html)
- [EatPayLove](http://eatpaylove.surge.sh) - mobile-friendly calories and cost tracking app</content>
  </entry>
  

  <entry>
    <title>AI for developers</title>
    <link href="https://conwy.co/articles/ai-for-developers" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>ai-for-developers</id>
    <content xml:lang="en" type="html">&gt; Summary: AI, when used by developers, can assist code writing with autocomplete, provide helpful information for diagnosing error messages and technical problems, generate code such as bash scripts and unit tests, summarise technical conversations and provide helpful summaries for code reviews.

Over the last couple of years, I&#39;ve sprinkled AI usage through various typical software engineering activities.

The most common tools (and what I tend to use) have been [Copilot](https://github.com/settings/copilot) and [Copilot Chat](http://chatgpt.com), but some free tools such as [Llama Coder](https://marketplace.visualstudio.com/items?itemName=ex3ndr.llama-coder) are beginning to become more mainstream.

In this article I&#39;ll summarise the scenarios where I found AI useful.

- [Writing code faster with autocomplete](#writing-code-faster-with-autocomplete)
- [Getting help with error messages](#getting-help-with-error-messages)
- [Getting help with technical problems](#getting-help-with-technical-problems)
- [Writing bash scripts](#writing-bash-scripts)
- [Generating unit test code](#generating-unit-test-code)
- [Summarising conversations](#summarising-conversations)
- [Code reviews](#code-reviews)
- [General thoughts](#general-thoughts)

## Writing code faster with autocomplete

AI-powered autosuggest was a great help when I had to write a chunk of code that&#39;s necessarily verbose, but not unique to my problem.

A perfect example is given on Copilot extention homepage.

![Example: Copilot JS suggest for calculating days between two dates](/images/articles/ai-for-developers/copilot-js-suggest.png)

## Getting help with error messages

Pasting an error message into Copilot Chat, prefixed with `/fix`, can provide good guidance on the cause and fix for a given error.

When the responses given aren&#39;t suitable, follow-up prompts such as &quot;can you suggest some other alternatives&quot; can help.

![Example: Copilot Inline Chat Error Message example](/images/articles/ai-for-developers/inline-chat-fix-error-message-example.png)

## Getting help with technical problems

Similar to error messages, I found that expressing a technical problem in an AI-powered chat can yield some good ideas and solutions.

This worked even better when I followed up the initial question with clarifications and/or challenged the AI to think of additional ideas or alternatives.

![Example: Copilot Quick Chat feature](/images/articles/ai-for-developers/copilot-quick-chat.png)

## Writing bash scripts

Bash scripts can perform many kinds of general tasks. Once you have a script that does what you want, you can re-use it any number of times.

A specific need I had was to see all the authors who had edited a particular file in a Git repository. With the help of ChatGPT I was able to write a script that achieved what I wanted.

Here&#39;s the prompt I used:

&gt; Copyable: Please write a bash script which finds and lists all the unique authors who have edited the given file in the current Git repository. The given file will be specified as the first parameter to the bash script.

I&#39;ve published the resulting script as a Github Gist: [list_authors.sh](https://gist.github.com/jonathanconway/71d5413cce30f43d3182fdfdc46c4723).

The script takes as an argument the path to a file in that repo. It then uses `git log` on the current repository to find all the authors who have edited the file, `sort`s and `uniq`s them and outputs them to stdout.

Here&#39;s a sample of the output from running it on [a file in the NextJS repository](https://github.com/vercel/next.js/blob/fd0bc9466e42ec313ce92c58e2a5c2c157e63f54/packages/next/src/shared/lib/head.tsx):

```
$ list_authors packages/next/src/shared/lib/head.tsx
Authors who have edited &#39;packages/next/src/shared/lib/head.tsx&#39;:
Adam Stankiewicz 
Filipe Medeiros 
Gerald Monaco 
JJ Kasper 
...
```

## Generating unit test code

I sometimes use GitHub Copilot to generate unit tests for a particular code file I am working on.

This can be done by opening the file under test, pressing Cmd+I and asking Copilot to write a unit test for the current file.

I would use a prompt like: **&quot;Please write a unit test for this file&quot;**.

I use this is mainly to set up the scaffolding, such as `describe` and `it` blocks and basic assertions. Usually I need to tidy up a few things here and there, but the AI is surprisingly good at generating decent test code.

Another technique is to provide just the code for one function or code block and ask AI to generate test code for it, listing a few test cases.

Here&#39;s an example of a prompt I might use:

&gt; Copyable: Please write a Jest unit test for a Typescript function.
&gt;
&gt;
&gt; The unit test should have the following it blocks:
&gt; 1. returns a list of dates between the two dates passed
&gt; 2. returns an empty array if two identical dates are passed
&gt; 3. throws an error if null is passed
&gt;
&gt; Please write tests that satisfy the above it blocks.
&gt;
&gt; Here is the Typescript function:
&gt;
&gt; \`\`\`
&gt;
&gt; function calculateDaysBetweenDates (begin, end) \
&gt;
&gt; \`\`\`

## Summarising conversations

Some colleagues and I had a long back-and-forth about code reviews in a Github discussion.

When it came time to summarise all these in a meeting, I found that AI-powered chat was a great way to summarise the discussion and get everyone&#39;s thoughts on what we had discussed.

It looks like ChatGPT now has a quick Summarise button for this purpose.

![Example: ChatGPT summarise button](/images/articles/ai-for-developers/chat-gpt-summarise-button.png)

## Code reviews

When reviewing pull requests I&#39;ve been experimenting with various ways of asking AI help me.

One way I found useful was to have AI review and summarise the changes and overall quality.

Here are the steps I took for doing this with Copilot Chat:

1. Generate a diff between the pull request source and destination branches.
  - `git checkout ` to checkout the branch
  - `git diff  | pbcopy` to run the diff and copy the output

2. Paste the whole diff into a new empty tab in VS Code

3. Press Cmd+I and prompt Copilot: **&quot;Please review these code changes&quot;**

Here&#39;s a sample of the kinds of results I tended to get (anonymised):

&gt; The code changes introduce several new features and modifications to the healthcare application. Here are the key points:
&gt; 
&gt; 1. Localization Updates:
&gt;   - Added new localization strings for transfer confirmations in `en-AU.json`.
&gt; 
&gt; 2. Removed Mock Initialization:
&gt;   - Removed the conditional import of mock initialization in `layout.tsx`.
&gt; 
&gt; 3. New Patient Transfer Form Submission Logic:
&gt; 
&gt;   - Created a new file `submit.ts` to handle the patient transfer form submission logic.
&gt;   - This includes creating a `Ward` object, making a patient transfer request, and handling different states of the transfer (success, delay, error, no-response)
&gt; 
&gt; 4. Transfer Form Tests:
&gt;   - Updated `transfer-form.test.tsx` to reflect changes in patient name and ward number and added tests for the new patient transfer form submission logic.
&gt;
&gt; Overall, these changes enhance the patient transfer functionality by providing detailed feedback on the transfer status and improving the test coverage for various scenarios.

Not as good as a human reviewer, but not useless either.

And not bad given the tiny effort on my part!

## General thoughts

### Code is valuable

I&#39;ve heard the idea that code is no longer valuable, since AI can now write it.

I disagree. In fact, I think well written code is more valuable with the advent of AI. When working with code through an AI tool, we need the AI to be able to understand the code, reason about it, draw clear and distinct conclusions and make concise edits which we can easily review to identify mistakes. Well written, consistent code enables this.

Even better: if we can state our coding standards explicitly to the AI, using project-specific configuration (such as CLAUDE.md files in Claude Code) and AI &quot;memory&quot; features, then we can improve the effectiveness and quality of the code changes made by the AI.

### Psychological hurdle to AI adoption

From introspection (also some observation) the biggest hurdle holding back engineers from fully utilising AI tools is the emotional/psychological adaptation. The technology itself is not especially cognitively demanding. I&#39;d argue the shift to functional programming or the Cloud were as hard or harder than AI. I think the important thing is a willingness to learn and adapt. This mental flexibility can be improved over time, with technique such as making a habit of continuous learning and exploring cognitive biases.

## Conclusion

While I feel AI might have been a little over-hyped, I think there&#39;s still merit in becoming familiar with it and using it where it fits.

It seems likely that AI adoption among software engineers will grow, so it will be advantageous to be familiar and conversant with the tooling.

## Further reading and viewing

- [_Pragmatic techniques to get the most out of GitHub Copilot_](https://www.youtube.com/watch?v=CwAzIpc4AnA) • Patrick CHANEZON, Burke HOLLAND, Brigit MURTAUGH, Isidor NIKOLIC, Allison WEINS, Martin WOODWARD
- [_Notes on using LLMs for code_](https://simonwillison.net/2024/Sep/20/using-llms-for-code/) • Simon WILSON
</content>
  </entry>
  

  <entry>
    <title>Diagramming React code</title>
    <link href="https://conwy.co/articles/diagramming-react" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>diagramming-react</id>
    <content xml:lang="en" type="html">&gt; Summary: React components can be diagramming in a UML-like format, depicting Components, Component calls (with props and render props), Functions and Types or Interfaces.

After working on a [Typescript diagram format](/articles/diagramming-ts) I wanted to focus on a React equivalent.

Diagrams can be useful for various purposes:
- Designing a solution at a high-level before writing any code
- Understanding an existing code-base by diagramming it
- Quickly sketching ideas to compare different designs or work out a refactoring strategy

In this article I&#39;ll describe a UML-influenced diagramming format for React.

## Overview

The format consistent of the following elements:

- **Component** - rectangle with title and list of props
- **Component call** - caller to callee connected with solid-arrow-terminated line
- **Component call with props** - caller to props and props to callee connected with solid-arrow-terminated line
- **Component render props** - render prop rectangle connected to component with dot-terminated line
- **Function** - rectangle with title and list of parameters
- **Type or interface** - rectangle with title and list of props

## Component

A component is depicted with a depicted with a rectangle with `&lt;&gt;` descriptor and title at the top and, optionally, props underneath.

![React diagram depicting a component](/images/articles/diagramming-react/component.svg)

## Component call

A component can render another component – here this is referred to as a &quot;component call&quot;.

A component call is depicted with a line from the caller component rectangle to the callee component rectangle, terminating in a filled arrow symbol.

![React diagram depicting a component call](/images/articles/diagramming-react/component-call.svg)

## Component call with props

A component can pass props to another component – here this is referred to as a &quot;component call with props&quot;.

A component call with props is depicted with a line from the caller component rectangle to a props rectangle and another line from the props rectangle to the callee component rectangle, terminating in a filled arrow symbol.

The props are depicted in a props rectangle, in which each prop has its own rectangle. This allows any individual prop to be linked to a type, function or component rectangle.

![React diagram depicting a component call with props](/images/articles/diagramming-react/component-call-with-props.svg)

## Component render props

Render props are props for which we pass a React component, a function which renders a component or a React node.

A render prop is depicted with a line from the prop box to a Component or Function rectangle, terminating in a dot symbol.

![React diagram depicting a component call with render props](/images/articles/diagramming-react/component-call-with-render-props.svg)

## Function

Same as in the [Typescript diagram format](/articles/diagramming-ts), a function is depicted with a rectangle with `&lt;&gt;` descriptor and title at the top and, optionally, parameters underneath.

![React diagram depicting a function](/images/articles/diagramming-react/function.svg)

## Type or interface

Same as in the [Typescript diagram format](/articles/diagramming-ts), a type or interface is depicted with a rectangle with `&lt;&gt;` or `&lt;&gt;` descriptor and title at the top and, optionally, fields underneath.

![React diagram depicting a function](/images/articles/diagramming-react/type-interface.svg)

A **composition relationship** between types or an inheritance relationship between interfaces is depicted with a line from the composer/inheritor to the composed/inherited type/interface, terminating in an empty arrow symbol.

![React diagram depicting type composition and interface inheritance](/images/articles/diagramming-react/composition-inheritance.svg)

A **reference relationship** between two components, functions, types or interfaces is depicted with a line from the referencer to the referenced, terminating in an arrow symbol.

![React diagram depicting an interface reference](/images/articles/diagramming-react/interface-reference.svg)

## Example: contacts list

Here&#39;s an example of a React diagram depicting components that make up a contacts list.

- ContactsList component
- ContactsList -&gt; ContactListItem component call with render props
- ContactsListItem component
- ContactPhone component
- ContactEmail component
- Contact interface
- getContacts function

![React diagram depicting a function](/images/articles/diagramming-react/contacts-list-example.svg)

## Downloads

To make it easier to use this format, I&#39;ve implemented them in the following formats, with downloadable templates:

- Mermaid • [Download: diagramming-react.mermaid.md](/downloads/articles/diagramming-react/diagramming-react.mermaid.md)
- Draw.io • [Download: diagramming-react.drawio](/downloads/articles/diagramming-react/diagramming-react.drawio)
- Figma • [Download: diagramming-react.fig](/downloads/articles/diagramming-react/diagramming-react.fig)
</content>
  </entry>
  

  <entry>
    <title>Subformats</title>
    <link href="https://conwy.co/articles/subformats" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>subformats</id>
    <content xml:lang="en" type="html">&gt; Summary: Subformats is a technique by which I extend an established format (such as Markdown), to add my own custom features, while remaining backwards-compatible, so I can re-use the content with third-party tools.

Let&#39;s face it: even the most versatile formats can become limiting.

For example, Markdown seems to support every kind of textual element we could ever want. Yet there will always be some users (like me) who want to, say, apply special styling to [pull-quotes](https://en.wikipedia.org/wiki/Pull_quote).

In this article I present the idea of a &quot;subformat&quot;: a backwards-compatible variation of an existing format, which adds additional information to that format. That additional information can be used by a parser which understands the subformat.

## The problem

I recently encountered a problem while migrating content to [my new homepage](/projects/conwy).

The articles are in plain Markdown format (`.md`) but I had to migrate them to MDX format in
order to allow certain sections to be rendered as React components.

Example of React-rendered components enabled by using MDX format:

- **Code samples** - rendered by my `MdxCode` component, using PrismJS
- **Diagrams** - rendered by my `MdxMermaid` component, using MermaidJS

However I also wanted the ability to copy and paste the source Markdown code directly into other Markdown-based content platforms such as [Github](https://github.com/) and [DEV.to](https://dev.to/).

To do this, I would have to convert the content from MDX format back into plain Markdown format, then copy and paste it into the platform.

This wouldn&#39;t be so easy, with so many Mdx tags all over the place.

There are a couple of options to speed up the conversion:

- Use a free online converter such as [MDX Formatter](https://jsonformatter.org/mdx-formatter)
- Integrate an automated converter such as [mdx-to-md](https://www.npmjs.com/package/mdx-to-md), perhaps bootstrapped using my builder infrastructure

However both of these options would require some busywork / tedium and might bring up errors and anomalies.

I eventually settled on what seems like a better solution: **subformats**.

## What is a &quot;subformat&quot;?

I coined this term because there doesn&#39;t seem to be any pre-existing term that describes what I&#39;m trying to do.

By &quot;subformat&quot;, I basically mean a variation of an existing format, which adds additional information to that format. That additional information can be used by a parser which understands the subformat.

For example: I use the Markdown ***format***, but then add my own small backwards-compatible variations to it, creating my own Markdown ***subformat***.

In this case, I add small pieces of text to Markdown, which do not interfere with the normal rendering of the Markdown, but which can still be picked up and used by my own parser.

This keeps the content backwards-compatible (i.e., the same content can be used by normal Markdown parsers) while allowing a newer / different
parser to access the additional information.

Using this additional information, my own parser can add enhancements such as React controls or special styling.

## Markdown subformat I&#39;m using

I&#39;m using a Markdown subformat to provide additional functionality to my Markdown-based articles in a way that maintains
compatibility with regular Markdown parsers like Github and DEV.to.

Here are the variations that make up the subformat:

| Markdown element            | Variation                                   | Used for                                                     |
|-----------------------------|---------------------------------------------|--------------------------------------------------------------|
| `&gt;` (block-quote)     | Content prefixed with:`Blurb:`        | Brief summary in purple text, at the top of an article.      |
| `&gt;`(block-quote)      | Content prefixed with:`Aside:`        | Aside text in a box, in an article body.                     |
| `&gt;`(block-quote)      | Content prefixed with:`Pull-quote:`   | Pull-quote in a box, with a quotes icon, in an article body. |
| `` ``` ``(code block) | Content prefixed with:`// Lines (x) ` | Code with lines (x) highlighted.                             |

## Example: pull-quote

You can see an example implementation in my **pull-quote variation** of the Markdown `blockquote` element.

For context: I&#39;m using [MDX](https://mdxjs.com/), which allows Markdown to be rendered using React components. The mdx-components.tsx file defines a mapping between DOM nodes and React components, including `blockquote` → `MdxBlockBuote.tsx`.

```typescript
export function useMDXComponents(components: MDXComponents): MDXComponents ;
}
```

In the `MdxBlockQuote` component which renders the Markdown blockquote, I pass the props through `getBlockQuoteSubformatProps`:

```typescript
export function MdxBlockQuote(props: MdxBlockQuoteProps) 
    
  );
}
```

The `getBlockQuoteSubformatProps` function in turn passes the props through a set of chained functions, each applying a variation and returning the resulting props.

```typescript
function getBlockQuoteSubformatProps(props) 
```

&gt; Aside: Note: This chaining pattern allows multiple subformats to be applied independent of one another.

The `getPullQuoteVariationProps` function first checks if the `children` prop has the &quot;Pull-quote:&quot; prefix (this is handled by `getIsSubformatChildrenPrefixed`). If it does, then this is a pull-quote. So then it adds the `pullQuote` class (imported from CSS modules), which applies pull-quote styling to the element.

```typescript
const PULL_QUOTE_PREFIX = &quot;Pull-quote:&quot;;

export function getBlockQuotePullQuoteSubformatProps(
  props: MdxBlockQuoteProps,
) 

  // Add pull-quote class
  const className = cn(props.className ?? &quot;&quot;, moduleStyles.pullQuote);

  // Remove pull-quote prefix
  const children = removeSubformatChildrenPrefix(
    PULL_QUOTE_PREFIX,
    props.children,
  );

  return ;
}
```

Now I can write the following in my Markdown file:

```markdown

This is a paragraph.

&gt; Aside:
&gt;
&gt; This is an aside

This is another paragraph.

```

If I copy/paste it into, say, Github, it will render it like this:

![Screenshot of aside block-quote in Github](/images/articles/subformats/github-screenshot.png)

But on my own website, it will render like this:

![Screenshot of aside block-quote in conwy.co](/images/articles/subformats/conwy-screenshot.png)

## Use cases

I think the subformats concept could be useful in the following senario:

- You want to use a popular/common format or standard (such as Markdown) *and*
- You want to add certain custom features not natively supported by that format *and*
- You want to maintain compatibility with the format *and*
- You don&#39;t have good reason to believe that your custom features will make it into the popular format anytime soon

Based on these situations I can think of the following use cases for subformats:

- Embedding site-specific formatting into Markdown documents (such as the scenario above).
- Embedding type information into JSON files using structured comments.
- Demarcating insertion/interpolation points in files using comments, e.g. HTML templates using `` comments.

## Caveat

If the underlying format will support your use case in the near future, or there is a simpler alternative technique, then a subformat might be better avoided. This is a very specific tool for a very small subset of use cases.</content>
  </entry>
  

  <entry>
    <title>AI user interface patterns</title>
    <link href="https://conwy.co/articles/ai-patterns" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>ai-patterns</id>
    <content xml:lang="en" type="html">&gt; Summary: AI-enabled capabilities can be surfaced in user interfaces in a variety of ways, including inline suggestions, single and multi-agent chat, providing hints for filling in inputs and through controls that allow the user to nudge a preview until it matches what they want.

As AI capabilities become increasingly available to everyday development
teams, it might be useful to explore way to surface these capabilities to
end-users.

This article describes some user interface patterns for surfacing AI.

Using ***&quot;treat it like a person&quot;*** as a core principle, I provide patterns,
examples (including in-the-wild cases) and how they mimic humans.

## Principles

As the definition of &quot;AI&quot; is still somewhat in flux, I want to assume a
definition for the purposes of this article:

***The capability of software/machines to do things that are normally thought of a human, in a rational way.***

The fact AI mimics human thinking/behaviour suggests that we user interfaces should expose AI capabilities in a human way.

As Ethan Mollick puts it in the book _Co-Intelligence_ (bold mine):

&gt; AI doesn’t act like software, but it does act like a human being. I’m not suggesting that AI systems are sentient like humans,
&gt; or that they will ever be. Instead, I’m proposing a pragmatic approach: ***treat AI as if it were human*** because, in many ways,
&gt; it behaves like one. This mindset, which echoes my “treat it like a person” principle of AI, can significantly improve your
&gt; understanding of how and when to use AI in a practical, if not technical, sense.

The patterns I&#39;ve encountered are:

- Inline suggestion
- Single-agent chat
- Multi-agent chat
- Prompting and nudging controls

Let&#39;s look at them in detail...

## Pattern: Inline suggestion

While performing a task, relevant ideas are displayed nearby in text or even imagery.

The user might be invited to provide input, such as selecting between variants or filling in a blank. (See [Fill-in-the-blanks pattern](#pattern-fill-in-the-blanks))

**Example:** As a product owner enters a story into a task tracking system, the AI suggests edge cases they didn&#39;t yet consider.

![Example: inline suggestion for a product owner entering a task](/images/articles/ai-patterns/ai-ui-patterns-inline-suggestion.svg)

**In the wild:** Code assistance plug-ins in IDEs (such as [Genie AI](https://www.genieai.co/), [Amazon Q](https://aws.amazon.com/q/), [CodeGPT](https://codegpt.co/), [Codeium](https://codeium.com/) and [Llama Coder](https://github.com/ex3ndr/llama-coder)) and dedicated IDEs (such as [Cursor](http://cursor.com)). Email and text message completion, as seen in [Gmail](https://mail.google.com/), [LinkedIn messaging](http://linkedin.com/) and [Apple Messages](https://en.wikipedia.org/wiki/Messages_(Apple)).

![In the wild: reply suggestion on LinkedIn](/images/articles/ai-patterns/ai-ui-patterns-inline-suggestion-linkedin.png).

**Mimics:** 🧍 Colleague, mentor, friend, etc. sitting nearby verbally offering a suggestion and/or physically pointing to a part of the screen.

## Pattern: Single-agent chat

A specialised chat bot is available for back-and-forth discussion.

**Example:**: Customer on an e-commerce website starts entering a question about a product. A specialised chat-bot replies with a detailed response. An input box allows the customer to respond with a follow-up question.

![Example: specialised single-agent chat bot on an e-commerce website](/images/articles/ai-patterns/ai-ui-patterns-single-agent-chat.svg)

**In the wild:** &quot;Have a question?&quot; feature on [Hotels](http://hotels.com/), &quot;QnaBot&quot; on [Amazon](http://amazon.com/).

![In the wild: &quot;Have a question?&quot; feature on Hotels](/images/articles/ai-patterns/ai-ui-patterns-single-agent-chat-hotels.png)

![In the wild: &quot;QnaBot&quot; on Amazon](/images/articles/ai-patterns/ai-ui-patterns-single-agent-chat-qna.png)

**Mimics:** 💬 Colleague, mentor, customer service, etc. communicating with the user via chat.

## Pattern: Multi-agent chat

Multiple chat bots appear in the same chat window. Each bot has a different persona and perspective, and only contributes where applicable.

By splitting AI responses among multiple bots, rather than just one, it&#39;s easier for the user to mentally divide the AI output into different &quot;buckets&quot;.

Also, because this is analagous to real human-human team-work, it&#39;s intuitive for people.

Users can address individual bots by name, to ask for further assistance on a specific topic or aspect covered by just that bot.

**Example:** Financial advisor tool for recommending products to customers. Agents representing analysts and compliance each offer a perspective. The advisor uses these insights to prepare for a meeting with the client.

![Example: specialised multi-agent chat bots embedded in a financial advisor tool](/images/articles/ai-patterns/ai-ui-patterns-multi-agent-chat.svg)

**In the wild:** Slack automation bots such as [Trello for Slack](https://trello.com/platforms/slack), [ThreadReaderApp](http://threadreaderapp.com) on Twitter and dedicated chat platforms such as [Symphony](http://threadreaderapp.com).

![In the wild: Trello for Slack automation bot](/images/articles/ai-patterns/ai-ui-patterns-multi-agent-chat-slack.png)

![In the wild: ThreadReaderApp on Twitter](/images/articles/ai-patterns/ai-ui-patterns-multi-agent-chat-thread-reader.png)

![In the wild: Symphony dedicated multi-agent chat platform](/images/articles/ai-patterns/ai-ui-patterns-multi-agent-chat-symphony.png)

**Mimics:** 👭 Group of people working together, such as a team meeting.

## Pattern: Fill-in-the-blanks

A stencil is displayed, with some areas for user input and some ares for AI generated content.

As the user fills in the inputs, the AI uses contextual information to generate more of the content. User and AI both work together until the full output has been generated.

**Example:** Writing a CV for a job. You start to fill in work history items. The AI suggests additional bullet points, which you accept or refuse. The AI suggests shorter more focussed descriptions and word removal, which you accept or refuse.

![Example: fill-in-the-blanks AI for CV editing tool](/images/articles/ai-patterns/ai-ui-patterns-fill-in-the-blanks.svg)

**Mimics:** 📈 Collaborative white-boarding with colleagues (virtually or physically), collaborative card sorting exercises with a team.

## Pattern: Nudging controls

A &quot;work in progress&quot; is displayed in the center while command-buttons for &quot;nudging&quot; are displayed around the edges or off to the side. By clicking the buttons, you can ask the AI to change the work along some dimension.

**Example:** 3D image manipulation. We ask the AI to make the shape more or less rounded, more or less flat, etc.

![Example: nudging controls for AI-assisted logo editing tool](/images/articles/ai-patterns/ai-ui-patterns-nudging.svg)

**In the wild:** Dall-E image generator.

![In the wild: Dall-E image generator](/images/articles/ai-patterns/ai-ui-patterns-nudging-dalle.png)

**Mimics:** 💺 Pairing with a designer, where the designer is tweaking this or that based on your input.

## Further reading

- [_Exploring Generative AI_](https://martinfowler.com/articles/exploring-gen-ai.html) • Birgitta BÖCKELER
- [_Artificial Intelligence: A Modern Approach_](https://aima.cs.berkeley.edu/) • Stuart RUSSELL, Peter NORVIG
- [_Co-Intelligence_](https://www.penguin.com.au/books/co-intelligence-9780753560778) • Ethan MOLLICK
- [_Living with AI Discombobulation_](https://youtu.be/lxpASbe5Uys) • Clay SHIRKY</content>
  </entry>
  

  <entry>
    <title>Manual testing</title>
    <link href="https://conwy.co/articles/manual-testing" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>manual-testing</id>
    <content xml:lang="en" type="html">&gt; Summary: Manual testing offers distinct and powerful benefits such as understanding system behaviour with minimal documentation, verifying changes rapidly in multiple environments and empathising with end-users. Structuring your manual test efforts compounds these benefits.

While automated testing methods have been established for a long time in the software development process (e.g. unit, integration and end-to-end tests), relatively less attention has been paid to manual testing.

However manual testing is far from &quot;dead&quot;. Software developers still routinely verify their work by using products manually. Further, developers are usually required to take responsibility for the end-to-end functioning of their software, not just writing quality code and passing unit tests. They are usually encouraged not lean too heavily on QA.

In this article, I will:

- Review the distinct benefits of manual testing.
- Present a real-life scenario where manual testing adds value.
- Provide guidance for structuring your manual testing, so you can get maximum benefit from it.

## Benefits of manual testing

Manual testing allows you to achieve certain specific goals which may not be available through automated testing:

- Discover ***actual behaviour*** – how the system ***currently*** to behaves at runtime. (This information is not always readily available by other means.)
- Determine ***intended behaviour*** – how the system is ***expected*** to behave. (Also not always readily available.)
- Perform testing ***immediately*** – without setting up test frameworks, etc.
- Perform testing in ***any environment*** you can access – not just local or QA environments.
- Put yourself ***in the end-user&#39;s shoes*** – letting you experience the system as an end-user would.
- Verify ***complex, lengthy workflows*** – which might be too difficult to automate. For example, complex interactions between an end-user and the system or complex data processing activities on the backend.

As with any activity, manual testing can offer maximal benefit when performed in a structured manner.

In my experience this involves:

* Writing clear, structured test cases - e.g. heading, description, numbered steps with actions and expected results
* Organising test cases for rapid retrieval, by using consistent naming and tags
* Sharing test cases within the team/organisation, so others can leverage them

## Example of a test case

Here&#39;s a simple example of a test case involving a user logging in:

```
user_can_login.md:

# User can login

Users who have an account should be able to log in.

## Steps

1. Go to the homepage
2. Click the login button
3. Expect that the login screen is shown
4. Enter username
5. Enter password
6. Click login screen submit button
7. Expect that you are shown logged in, in the header section
```

Notice we have a brief heading and description, followed by neatly numbered steps.

Steps can be:
* ***Actions*** (e.g. &quot;click the login button&quot;) or
* ***Expectations*** (e.g. &quot;expect that the login screen is shown&quot;)

This format allows us to quickly follow the steps of the test case (actions) and know what to look at to determine whether the test passed or failed (expectations).

## Scenario: critical fixes for a startup

A realistic scenario might make it easier for you to see how manual testing can help.

Imagine you begin work as a software engineer at a rapidly growing startup, building a complex product with many user flows.

You are assigned to work on the sign up experience. Users provide various personal details such as their country of residence. Based on these, the system provides various prompts then accepts payment.

You are given your first development task:

&gt; &quot;Please fix the flow for Japanese customers. They are getting stuck at the point where they submit their personal details, but before they have paid for the product.&quot;

This is based on direct customer contact. No one in the company can tell you exactly what &quot;stuck&quot; means or in exactly which part of the flow this is occurring.

There is also minimal unit test code, code quality is not good and there&#39;s little documentation. Remember, it&#39;s a fast-growth startup – they don&#39;t have the same time and resources as a more mature company.

How would you go about solving this? Your approach might look like this:

1. You go through the flow manually, simulating a Japanese customer (perhaps setting your browser location to Japan).
2. As you go, you write down the steps you are taking, such as which details you entered, which buttons you clicked, etc. (This makes it easier to keep track of what you&#39;re doing, in case you need to restart the process). 
3. You find the exact point where the system is stuck - the submit button on screen 5 doesn&#39;t do anything.
4. Examining the requests/responses, you discover that the system skipped the collection of the user&#39;s driver licence details, which are required for customers in certain countries, including Japan, causing an underlying API call to fail if not provided.
5. Your verify this requirement with Backend engineers and the Product owner. Now you know what the fix is: you need to enable drivers licence details collection for Japanese customers.
6. You make the fix in the relevant part of the code-base.
7. Testing your work manually, you realise this data can be collected  earlier in the sign-up flow, with a skip option given for customers who don&#39;t have the details on hand. This will be a nicer user experience and increase the number of potential customers in the sales funnel.
8. You complete all your changes, cover them with a unit test, save your manual testing steps in a markdown document (linked to from the pull-request) and push your changes.
9. Once in Prod, you do a quick verification and see that everything works as expected. 
10. You can now report to the team that your task is completed with (hopefully) zero bugs!

Notice how documented manual testing helped you to solve this problem:

- You found the actual error by manually going through the flow (step 1).
- You kept track of your testing by writing down the steps, allowing you to quickly and efficiently repeat your test efforts whenever needed (steps 2, 7, 9).
- You easily verified your work in Prod (step 9).
- You empathised with the end-user and even found an opportunity to improve their experience as well as the onboarding rate (step 7).
- You added value to the team by documenting your manual testing steps (step 8).

As we&#39;ll soon see, this is only the beginning of the benefits! 

## Tagging your test cases

Tagging can be a powerful way of making your whole test case collection searchable.

Suppose every time you refer to the login screen in your Markdown files, you use the exact phrase: &quot;login screen&quot;. Perhaps wrap it in brackets: &quot;(login scren)&quot;.

Now this exact phrase is searchable, via a simple find-in-files in your text editor. By searching for the string &quot;(login screen)&quot; you can find every test case involving that screen.

For example, your search might yield the following results:

* `user_can_login.md`
* `user_can_recover_forgotten_password.md`
* `user_cannot_login_with_wrong_credentials.md`
* `user_can_login_from_another_country.md`
* `user_can_login_with_a_linked_google_account.md`

This gives you powerful new capabilities such as:

* **Regression-testing** - checking various test cases, in case your change might have broken something.
* **Exploratory-testing** - observing how the application behaves in various scenarios, generating ideas for improvement or uncovering hidden bugs.
* **Determining which unit tests to write** - to boost test coverage in a critical area of the application.

## Test data 

Suppose a feature you want to test relies on certain data existing in the system beforehand.

For example, you might need a certain kind of user account, such as a user who has their country set to Japan.

You could create a test user in your testing environment - `hiroshi@yompail` – and save it in your test case under a &quot;Test data&quot; heading.

```
user_can_login.md:

# User can login

## Steps

1. Go to the homepage
...

## Test data

- User: hiroshi@yopmail.com / P@ssw0rd
```

## Results and artifacts

It can be very useful to know the full list of dates/times when you ran your test and what the result was on each run.

These can be added to a &quot;runs&quot; section of the test case file.

```
user_can_login.md:

# User can login

## Steps

1. Go to the homepage
...

## Runs

| Date/time               | Result    |
| ----------------------- | --------- |
| 2024-10-01 9:00 AM      | Succeeded |
| 2024-09-04 10:00 AM     | Failed    |
```
 
How might this be useful?

* **Spotting a pattern in failures** can indicate a systemic problem, such as insufficient compute resources or code quality issues with a particular part of the code base.
* **Correlating failures with code changes** can narrow your version control system search. For example, if you know the failure happened within the last week, you can limit your search changes made within that timeframe.

When with manual testing, it is common for engineers to capture artifacts of their work, such as screenshots, screen recordings and copies of log output. These serve to demonstrate work done, prove that things worked correctly at a certain date/time and capture additional information that could help identify additional problems or improvement opportunities.

Artifacts from manual tests can be organised alongside test cases, using a structured folder naming system.

I have found it best to keep artifacts in folders named after the test cases and test run dates from which they were generated.

Here&#39;s an example:

- `/test_cases`
  - `user_can_login.md`
  - `user_can_recover_forgotten_password.md`
  - ... etc
- `/test_artifacts`
  - `/user_can_login`
    - `/2024_10_01_9_00_AM`
      - `Screen Recording 2024-10-01 at 9.01.55 am.mov`
      - `Untitled2.png`
  - `/user_can_recover_forgotten_password`
  - ... etc

## Manual testing workflow

You can make manual testing a regular, consistent part of your workflow. As you strengthen this habit, your work quality and overall knowledge of the system should improve.

Here are some ideas:

- Write a test case at the beginning of working on a major feature.
- Include or link to the test case in the task tracking system.
- Perform a test case of every major feature you deliver, writing a test case if one doesn&#39;t already exist.
- Include or link to your test case from every pull request you submit.
- Keep all your test cases in a shared knowledge system, such as your project&#39;s wiki.
- Copy relevant parts of a test cases in chat conversations about a feature or bug.

## Manual testing tools

There are a range of software tools to help you write and manage test cases.

- [Testmatic](/projects/testmatic). Shamless plug – I built this! It includes a web-based UI and CLI and saves everything to Markdown.
- [Azure Test Plans](https://azure.microsoft.com/en-us/products/devops/test-plans). This one has a nice web-based UI and integrates with the Azure suite.
- [DoesQA](https://does.qa/test-automation/codeless-vs-code). An interesting product that apparently allows you to write &quot;codeless&quot; but runnable tests.

## Conclusion

Manual testing offers distinct and powerful benefits, not offered by automated testing, such as understanding and representing current and desired system behaviour, making fast progress in challenging environments with limited documentation and test coverage, verifying changes in multiple environments, verifying complex workflows and empathising with end-users.

Structuring your manual test efforts compounds these benefits: you can quickly locate related tests (enabling regression and exploratory testing), ease your test efforts (using test data) and keep track of test results (helping you identify patterns in failures or find the root cause of an issue).

## Further reading

These resources inspired this article:

- [_Software Testing - A Craftsman&#39;s Approach_](https://www.routledge.com/Software-Testing-A-Craftsmans-Approach-Fifth-Edition/Jorgensen-DeVries/p/book/9780367767624) by Paul JORGENSEN</content>
  </entry>
  

  <entry>
    <title>Mindfulness</title>
    <link href="https://conwy.co/articles/mindfulness" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>mindfulness</id>
    <content xml:lang="en" type="html">&gt; Summary: Recently I started the habit of practicing mindfulness-meditation daily. This resulted in some unique experiences and personal transformation including positive orientation, enhanced awareness and reduced stress.

&gt; “Let all those beings which exist --
&gt; without enemies, without obstacles, overcoming their grief
&gt; and attaining happiness, be able to move freely,
&gt; each in the path destined for them.”
&gt; – BUDDHAGHOSA • Visuddhimagga

&gt; “We are what we repeatedly do.”
&gt; – ARISTOTLE

&gt; “Mindfulness is not merely a concept or a good idea. It is a way of being.”
&gt; – John KABAT-ZINN

&gt; “You don’t make any decisions. You don’t judge anything. You just accept
&gt; everything. If I do that for ten or fifteen minutes while walking around,
&gt; I end up in a very peaceful, grateful state.”
&gt; – Naval RAVIKANT

During my most recent sabbatical I experimented with mindfulness-meditation.

Starting with 10 minutes then moving up to 20 minutes per day, I sat in an small spot outdoors, observing my surroundings and well as my body and mental activities.

I&#39;m glad to report that, with a little persistence, this has now become a firm daily habit and something that I quite look forward to!

During this period I was reading a number of books that seemed relevant, including:
- _Full Catastrophe Living_ by John Kabbat Zinn
- _Zen Mind, Beginner&#39;s Mind_ by Shunryo Suzuki
- _The Tao Te Ching_ by Lao Tzu (various translations)

I had some interesting experiences and thoughts, which I thought I&#39;d share.

**Transformed experiences.** When I experienced sounds and sights, I observed my (rather overactive) mind reacting to them. I observed a tendency to distinguish and label objects, animals, people, etc. Over time I gently nudged myself away from labels, focussing more on the wordless experience of these phenomena. I also found my experience broadening to encompass the _overall atmosphere_ of the spot – the &quot;total combination&quot; (if you will) of all these phenomena. I found this practice began to subtly transform my experience of the environment, especially over time and repetition. I began to feel a greater sense of unity with the world. I don&#39;t think this was necessarily due to to any intellectual realisation, but more from developing a habit of ***not distinguishing*** myself from my surroundings. 

**Enhanced memory.** I noticed an ability to recall things more easily – from facts and figures I&#39;ve been learning in various studies to even imagery from dreams. I&#39;m not sure whether this is attributable to my meditation practice, but at least it seems to have coincided with it.

**Beauty.** I catch myself more often being struck by beauty. Not only sunsets but also the beauty of peoples&#39; dress, of language, of various animals (magpies, various insects) and plants, and also landscape features like hills. I don&#39;t experience the beauty of these separately (though it probably seems that way because of how I write about them), but more often together as part of the same scene. It&#39;s a great joy!

**Observing non-critically, withholding judgement.** I&#39;ve been practicing a more mindful approach generally. For example, when reading code or someone&#39;s writing, I try to practice a small hesitation. I hold back from assuming that my initial understanding is correct and re-read the material to check if I really understood it. I&#39;m hopeful that this will help me to avoid mistakes in future and also make the reading experience more engaging (both for code and writing).

**Seeing obstacles as opportunities.** Initially I had to somewhat coax myself into mindfulness. I have been mindful many times throughout my life, but carving out a specific time in my day just for this practice took a bit of persistence. There is a saying that no meditation is &quot;bad&quot; – what matters most is that you simply do it. In this spirit, I tried to look at my effort (and the resistance to it) as an obstacle leading to an opportunity – the opportunity to increase awareness and inner peace.

**Moving quickly without rushing.** In the _Catastrophe_ book, Zinn refers to: &quot;being aware even when moving quickly&quot; and suggests: &quot;shift your awareness ... to a sense of your body as a whole moving through space&quot;. I practiced this awareness during busy moments, such as shopping and commuting. It really took the stress out of these and at times made them quite enjoyable.

I hope you found these insights interesting and that perhaps I&#39;ve whetted your appetite for practicing mindfulness – in whichever way works best for you.

Namaste!</content>
  </entry>
  

  <entry>
    <title>What I learned studying Calculus</title>
    <link href="https://conwy.co/articles/studying-calculus" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>studying-calculus</id>
    <content xml:lang="en" type="html">&gt; Summary: Completing an Introduction to Calculus taught me a range of interesting lessons including lessons about learning, such as the importance of understanding fundamentals, visualisation, geometric analogies, parts vs. whole, focussing on correcting mistakes and thinking deeply about small things.

&gt; “I never regretted the time I spent on history and on math. Math sharpens
&gt; your mind, history gives you some idea of your limitations and what’s going
&gt; on in the world.”
&gt;
&gt; – Bjarne STROUSTRUP ([Video](https://www.youtube.com/watch?v=-QxI-RP6-HM))

&gt; “Curiosity is recognizing a gap in our knowledge about something that
&gt; interests us, and becoming emotionally and cognitively invested in closing
&gt; that gap through exploration and learning.”
&gt;
&gt; – Brené BROWN • _Atlas of the Heart_

Recently I completed [*Introduction to Calculus*](https://www.coursera.org/learn/introduction-to-calculus) on Coursera.

My motivations were:

* To improve my foundational math skills, enabling a better understanding of computing foundations and machine learning.
* To test and improve my learning skills by studying a less familiar field outside comfort zone.
* Ok... the real reason... to gain entry to the Sydney University B. Adv. Comp. program! 😄

The course has been fascinating and engaging. It&#39;s not only introduced me to Calculus but also helped me to brush up on basic arithmetic and algebra where I discovered I had serious gaps. [Prof David Easdown&#39;s](https://www.sydney.edu.au/science/about/our-people/academic-staff/david-easdown.html) regular participation in the forums was valuable gift to us students!

Some reflections in no particular order:

## Understanding fundamentals

The hard part often isn&#39;t the highest level concepts, but the foundations you need in order to (properly) understand and use them. I had to understand concepts such as *completing the square*, *long division of polynomials* and *derivatives*, not only theoretically, but well enough to apply them correctly to solve an unexpected problem. I&#39;ve [commented](https://news.ycombinator.com/item?id=40083488) about this on HackerNews.

## Benefits of drawing, visualising

Using a high quality notebook and pen helped with enjoyment and motivation to study! Fleshing out problems on paper, down to the fine details, helped me to see how the pieces of a problem fit together, which was quite fascinating. 

## Geometric analogies

I found it incredibly helpful when David presented an idea *geometrically*. Simple shapes such as triangles are intuitive to many learners. And the [Theorem of Pythagoras](https://en.wikipedia.org/wiki/Pythagorean_theorem) is now widely understood. The curve sketching exercises and Riemann sum rectangles were memorable examples but there were so many other cases where David made the idea clearer by some kind of geometric metaphor.

## Parts vs. whole

I found that solving a non-trivial math problem typically requires also understanding all the parts of the problem. (This is in contrast to my usual profession, software development, where many problems can be solved using &quot;black-box&quot; solutions such as libraries, without understanding their internals.) This experience of the parts/whole adds a dimension to my understanding of problem solving generally.

## Focussing on mistakes

Trying out the examples and practice tests and observing what I got wrong helped me narrow down specifically where my knowledge gaps lay and then actively correct them, which also helped improve my long-term memory of the concepts. (This way of thinking is also helping me in other areas of life beyond math.)

## Different learning methods at different stages

I found different learning techniques useful at different stages of the course. Early in the course, I found repeated practice and deep thinking most useful. Midway through, I found sketching and visualisation more productive. Late in the course, I found all the above useful, plus reading various additional sources such as books.

## Thinking deeply about small things

Prof David mentioned this in one of the videos - such a powerful insight! Sometimes on a walk or another repetitive activity I turned over an idea in my head to try and understand it in its essentials (e.g. I did this a lot with Leibniz notation, trying to understand it at some deeper level than words).

## Temporarily suspending understanding

Introspectively, I found that getting stuck (what people call &quot;writers block&quot;, &quot;analysis paralysis&quot;, etc) often happens when I&#39;m trying to understand an interconnected complex of ideas and am uncertain how to break them down. Here the usual approach of &quot;divide and conquer&quot; or breaking down the problem into smaller pieces doesn&#39;t work because I don&#39;t know how or according to what criteria to break them down. One way to proceed is to temporarily suspend trying to understand some parts so that I can focus on others. I&#39;ll treat them as small &quot;black boxes&quot; so that I can skip learning them. This enables me to move on to other problems and not be blocked.

## Concepts vs. application

Abstract conceptual knowledge is not the same thing as knowledge that can be applied. I could read a book on Calculus without really understanding it, but doing the practice tests in this course was better. After this course it&#39;s more likely that I&#39;ll be able to see a problem, see where Calculus might help, identify/name the components and then try to solve it using appropriate methods.

## The power of good notation

Prof David mentioned this in one of the videos on Leibniz notation. Amazing, rich insight. This immediately inspired ideas that I&#39;ve been translating into my software development practices. Representing a problem differently can open the way to unexpected solutions. This inspired my [code selectors](/projects/codeselectors) project.

## Mathematics as a language

Sometimes thinking of a mathematical idea as language or &quot;description&quot; helped me understand it. Rather than trying to understand a concept&#39;s full meaning immediately, I try to think of it as a just label – in object-oriented programmer-speak, a &quot;class&quot;. Then I gradually add &quot;properties&quot; or &quot;attributes&quot; to that label as my understanding increases. For example, I found this method useful for understanding [Euler&#39;s number](https://en.wikipedia.org/wiki/E_(mathematical_constant)). Rather than thinking of it as a particular number (which stumped me for a while) I found it better to think of it as the *criteria* for some number which I don&#39;t yet know. In SQL programming terms: a `SELECT` statement, with multiple `WHERE`/`AND` clauses, which yields a single scalar result which is _e_. In these terms, *e* is &quot;the number which yields has a slope (rise over run) of 1 at 1&quot;, etc. Thinking this way helped me reason about the use of *e* in graphs.

## Directions for further study

I greatly appreciated David&#39;s frequent references and pointers to areas for further study. Explaining the *proofs* of a method, rather than just the method itself, is one example – I could use this knowledge for [formal verification](https://en.wikipedia.org/wiki/Formal_verification). Referencing more advanced concepts such as series expansions is another example. This makes me curious and motivates me to study the field further.

I started this course with some trepidation and had many challenges along the way, but I feel a great sense of satisfaction after completing it.

Now I can&#39;t wait to jump into my next learning challenge: [Linear Algebra](https://www.coursera.org/learn/introduction-to-linear-algebra)!

## Further reading

- [_Precalculus: Mathematics for Calculus, Seventh Edition_](https://www.amazon.com.au/Precalculus-Mathematics-Calculus-James-Stewart/dp/1305071751) • James STEWART, Lothar REDLIN, Saleem WATSON
- [_How to Solve It_](https://en.wikipedia.org/wiki/How_to_Solve_It) • George POLYA

</content>
  </entry>
  

  <entry>
    <title>Streamlining code reviews</title>
    <link href="https://conwy.co/articles/code-reviews" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>code-reviews</id>
    <content xml:lang="en" type="html">&gt; Summary: Code reviews can be made easier and more efficient by following a repeatable process. The process I found useful is: 1. context: gain a high level understanding of the context of the change, 2. scan: read all the code and mark out any immediate issues and questions and follow them up, 3. checklist: rigorously review the code against a code review checklist and leave prioritised comments.

For myself and others, I&#39;ve found that code reviews can be a challenging part of being a software developer.

There may be many code changes to go through, many possible mistakes to be found and limited time to find and communicate them. Even before considering mistakes, the sheer amount and complexity of the code and changes can feel overwhelming – you don&#39;t know where to begin. It often feels like code review is chaotic and random, and it&#39;s down to luck whether or not it will be constructive.

In this article I want to share my code review process, which I&#39;ve evolved over time, in response to the pressures mentioned above.

These are not necessarily based on hard evidence such as data and statistics, but more of a grab-bag of potentially useful ideas sampled from a range of different work environments, development stacks and teams, over many years.

Broadly, there are three practices I follow, in order, for each code review:

1. **_Context_** – gain a high level understanding of the context surrounding the change, by checking the description, commit messages, task and any other documentation, and/or by asking the author
2. **_Scan_** – scan all of the code in the change, observe any questions or issues that come to mind, try to answer them on my own, otherwise leave a comment
3. **_Checklist_** – make a final pass of all the code, this time against a checklist, and call out minor and major issues

Let me go into a bit more detail on how I perform each of these.

## Context

It&#39;s difficult to meaningfully assess a code change without understanding its **_context_**.

Context includes: what problem or requirement the code change intends to solve and how it fits into the broader context of the system.

Without context, the code may either look superficially correct, leading you to approve it too quickly, or it may look very odd, generating innumerable questions to the author. Conversely, when you **_do_** understand the intention and context, a code change becomes much easier to understand and more intelligible.

So I&#39;ve found it useful to learn more about the context if I&#39;m unclear.

Here are some methods I use to learn more about the context:

- Read descriptive notes and commit messages for the change, if any.
- Look up the task associated with the code change and read description and comments there.
- Look up code files related to the change and examine the code there.
- Look up the **_history_** of the files associated with the change, look up the tasks associated with that history, read the descriptions and comments.
- Search internal information sources (chat channels, wiki, etc.) using keywords found in the code.
- Ask the author of the change directly for context.
- Look up the authors of the files associated with the change in version control history and ask them directly for context.

While the above might seem time-consuming, I&#39;ve found it possible to fairly quickly improve my knowledge, even within minutes, by just picking a few of the relevant methods and applying them.

For example, if I already work closely with the author involved, a simple message asking for context often gets a quick reply. Or if the code changes are attached to tasks, e.g. via task codes, it&#39;s usually possible to access the task with just a couple of clicks, and then read it within a few minutes.

I believe this &quot;context hunting&quot; is usually worth the effort. It&#39;s not only about understanding the code change you&#39;re looking at. The benefits of contextual knowledge compound over time. Initially you might spend, say, 10 minutes reading and digesting contextual information, but eventually the time spend can approach 0, as you develop a systematic understanding of the whole system. That systematic understanding is highly valuable in all kinds of ways, not only for code review. It can help you to succeed in your own projects within the organisation and even help you to make the case for new projects and initiatives.

## Scan

After gaining context, the next step is to scan the code, getting a &quot;big picture&quot; view of how it hangs together.

I&#39;ll often check out the change locally, open some of the files in my IDE, and use the navigation tools in the IDE to figure out what sequence of calls are being made, what data are being passed, etc. If it&#39;s a complex network of calls, I might spend a few minutes sketching an [execution flowchart](/articles/visualising-execution-flows).

I also survey the content of new code added, looking at key variables, control-flow structures (conditionals, switches, loops, etc), and getting an overall grasp of what the code does.

At this point I may already have questions or issues for the author, and if so, I won&#39;t hesistate to leave a few comments.

My comments will usually be in the following form:

```
[Priority]: (Message)
```

This helps the author to understand my intent and prioritise which comments to reply to.

For example, if it&#39;s a minor issue, which shouldn&#39;t necessarily block merging, I&#39;ll write something like this:

```
[Minor]: `.forEach(expandSection)` might be more concise here.
```

But if it&#39;s a question, I&#39;ll write:

```
[Question]: Should this section be hidden for users without permissions?
```

And if it&#39;s a major issue, I&#39;ll write:

```
[Major]: Should include an authorization check here.
```

## Checklist

&gt; Pull-quote: “Substantial parts of what software designers, financial managers, firefighters, police officers, lawyers, and most certainly clinicians do are now too complex for them to carry out reliably from memory alone.”
&gt;
&gt; – Atul GAWANDE • _[The Checklist Manifesto](https://en.wikipedia.org/wiki/The_Checklist_Manifesto)_

By this point I&#39;ll have a pretty solid understanding of the change.

Now it&#39;s a good time to run through a code review checklist and see if I missed anything significant.

Because I broadly understand the change as a whole, even with a large checklist of 50 items, it&#39;s possible to quickly scan the checklist and pick out only the items that apply to the code.

For example, suppose one of the items in my checklist is:

- Query keys should be appropriately unique

After scanning the change, I will already know whether or not the change includes any query keys at all. If it does not, then I can immediately skip this step.

On the other hand, if the change **_does_** contain enums, then I will know to check the following item in my checklist:

- Enum values should match keys

Where does this checklist come from?

I usually build a unique checklist for each project I work on. As initial inputs to the checklist, I analyse the codebase I&#39;m working on and read any technical documentation, such as coding standards.

Subsequently I will add new items to the checklist, based on comments others leave on my change submissions, technical discussions with team members and general observations.

Additionally, I&#39;ve built up a pool of coding standards and best practices over my time as a developer. Some of these you can find documented in my article, [Towards zero bugs](/articles/towards-zero-bugs). I plan to publish a comprehensive list of them in a future blog post.

This checklist isn&#39;t only useful for reviewing others&#39; work – I use it on my own changes as well. By anticipating feedback and addressing it earlier, my code will already be of higher quality by the time it reaches the screens of others. This reduces the review workload on other engineers and improves my reputation within the team.

## Conclusion

Code reviews are an integral part of modern software engineering.

At a team level, they&#39;re a great way to maximise code quality and ensure a shared understanding and knowledge of the code and systems.

At an individual level, they&#39;re useful for understanding as much of the code as possible, both at a high level and a detailed level. This improves the quality of my own work and increases the likelihood of success in my current work and new initiatives within the organisation.

Having a normalised process for performing code reviews helps make them easier and more fun. It also improves the quality of the feedback and, long-term, the code base.

## Further reading

These books inspired this article:

- [_Software Engineering at Google_](https://www.kobo.com/au/en/ebook/software-engineering-at-google) by Titus WINTERS, Tom MANSHRECK, Hyrum WRIGHT
</content>
  </entry>
  

  <entry>
    <title>Visualising execution flows</title>
    <link href="https://conwy.co/articles/visualising-execution-flows" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>visualising-execution-flows</id>
    <content xml:lang="en" type="html">&gt; Summary: To understand how a code-base is connected and functions at runtime, we can use execution flows. These map the paths through the code as it executes the code in real life. A rigorous format can map directly to the code-base, enabling an accurate depiction. An appropriate format can be fed into a tool such as Mermaid, to generate a visual flowchart.

Anyone who has spent some time developing software knows writing new code is but a small part of the job. At least as big, perhaps bigger, is **understanding the existing code**. And that includes understanding the **runtime behaviour** of that code!

I often found myself having to understand a complex cluster of code modules, entailing many function calls being made and many data types being passed and returned.

To properly understand the behaviour of the code, I needed to see a whole flow together at once so I could reason about it. I needed to somehow visualise it, e.g. by listing out the function calls in a text editor or maybe drawing a diagram on a piece of paper or in a diagramming application.

After doing this quite a few times, I have started to evolve a more consistent and powerful format, one which is text-based (and so, easy to work on in a standard text editor) but can also be converted to a visual flowchart using a tool called Mermaid.

In this article I want to describe this format and the reasoning behind it.

Execution flow notations can be useful in understanding an existing code-base, troubleshooting bugs, communicating with other team members and for solution design.

But first some background...

## What is an execution flow?

It&#39;s helpful to define the concept of &quot;execution flow&quot;.

I&#39;m referring to the path that the runtime will take through the code as it executes the code during a real-life use case.

You should not confuse this with a more specific term: **_call stack_**. Since a flow can include multiple function calls in sequence, each producing its own distinct call stack, a flow can include multiple call stacks. Much of the complexity of an execution flow is precisely that calling of multiple functions and the passing of data to them and returning of data from them. So &quot;call stack&quot; is too narrow a term to cover what I&#39;m trying to describe.

On the other hand, you should also not confuse this with a more general term such as **_abstract syntax tree_** or &quot;code structure&quot;. We are not describing the code as a whole, but just one path of possible execution of the code. Any piece of code that has one or more conditionals (e.g. `if` or `switch` statement, etc.) will execute differently depending on how those conditionals evaluate. For the same code, different lines might execute depending on the situation (e.g. depending on external state of some kind such as a database, web-service, system clock, etc.). Thus one code base can support multiple execution flows.

## Example of an execution flow

Let&#39;s use a hypothetical example – handling a user login on a Java backend.

```java
class LoginResource  else 
  }
}
```

Can you spot the two execution flows in this code?

### Flow 1 - Logging in successfully

First, we have flow when the user&#39;s credentials are valid.

Here&#39;s that code example again, with the relevant lines highlighted:
 

   else 
  }
}
`}
  


1. Inside `login()`, the `if` condition calls `UserAuthProvider::checkUserCredentials`, passing user credentials.
2. `UserAuthProvider::checkUserCredentials` returns `true`.
3. Execution proceeds into the `then` block.
4. We call `SessionProvider::setCurrentUser`, passing user credentials.
5. We return `Response`, passing success parameters.

Notice that this isn&#39;t just a single call-stack, as there are actually two method calls in this flow, each of which will generate its own call stack.

1. `UserAuthProvider::checkUserCredentials`
2. `SessionProvider::setCurrentUser`

### Flow 2 - Failure to log in

What if the user credentials are _not_ valid and `isValidUser` returns `false`?

That would be a separate execution flow.

Here&#39;s the code example once more, with the relevant lines highlighted:


   else 
  }
}
`}
  


1. Inside `login()`, the `if` condition calls `UserAuthProvider::checkUserCredentials`, passing user credentials.
2. `UserAuthProvider::checkUserCredentials` returns `false`.
3. Execution proceeds into the `else` block.
4. We return `Response`, passing failure parameters.

## Tools for finding execution flow

So how to we figure out how our code flows in the first place?

We can, of course, just read the code, open various files as needed, and try to follow along in our head.

Thankfully we also have automated tools to help reduce some of the tedium. You&#39;ll likely be familiar with these:

- **_Go to definition_** - we can select a reference (function, class, variable, etc) and be taken to its original definition
- **_Find references_** - we can select a definition (function, class, variable, etc) and pull up a list of all points in the codebase which reference the definition

Different IDEs name these differently, but most mainstream IDEs have them in one form or another, including IntelliJ IDEA, VSCode, Visual Studio and xCode.

![Screencast of a developer using Go to definition tool in IDEA](/images/articles/visualising-execution-flows/visualising-execution-flows-demo-1.gif)

For example, in the code sample given previously, we might use _Go to definition_ to locate the class whose `login` method is being called.

1. Go to the `LoginResource` class and its `login` method.
2. Right-click the `isValidUser` call and select &quot;Go to definition&quot;.
3. Observe that it is defined in the `UserAuthProvider` class and its `isValidUser` method.
4. Go back the `LoginResource` class and its `login` method.
5. Right-click the `setCurrentUser` call and select &quot;Go to definition&quot;.
6. Observe that it is defined in the `SessionProvider` class and its `setCurrentUser` method.
7. Go back the `LoginResource` class and its `login` method.
8. Observe that a new `Response` object is constructed.



We might want to find out where else the `UserAuthProvider::isValidUser` method is called.

Supposing there was a `RegisterResource` class having a `register` method, as shown below:



   else 
  }
}
`}
  


Then we might locate this piece of code by using the _Find references_ tool:

1. Go to the `UserAuthProvider` class and its `isValidUser` method.
2. Right-click the `login` method and select &quot;Find usages&quot;.
3. Observe that it is called in the `LoginResource` class, in its `login` method.
4. Observe that it is also called in the `LoginResource` class, in its `register` method.
5. Observe that a new `Response` object is constructed.

## Describing with text

Suppose we wanted to make some notes of the execution flows we discovered. Maybe there are too many for us to easily memorise. Perhaps we want to see them all in one view rather than scattered among many files.

Let&#39;s start with the first flow – successful login:

```mermaid
LoginResource::login
  ---&gt;|userName,password| UserAuthProvider::isValidUser
  ---|true| LoginResource::login

  ---&gt;|userName,password| SessionProvider::setCurrentUser
  --- LoginResource::login

  ---&gt;|200,&#39;Login succeeded.&#39;| Response::constructor
```

Then the second flow – successful login:

```mermaid
LoginResource::login

  ---&gt;|userName,password| UserAuthProvider::isValidUser
  ---|false| LoginResource::login

  ---&gt;|401,&#39;Login failed. Invalid credentials.&#39;| Response::constructor
```

And the final flow – register:

```mermaid
LoginResource::register
  ---&gt;|userName,password| UserAuthProvider::isValidUser
  ---|true| LoginResource::register

  ---&gt;|200,&#39;Login succeeded.&#39;| Response::constructor
```

Now we can step back and look at all these flows together and see the bigger picture, e.g. how login and register both check user validity using `UserAuthProvider`, and how both instantiate the Response class with various constructor parameters.

&gt; ### Aside: Sketching execution flows
&gt; 
&gt; Observe that we don&#39;t have to cover the flows exhaustively, nor do we have to limit our coverage. We can cover just the parts of code that we are concerned with, based on our current goal, e.g. to solve the current bug or to learn more about a specific part of the code-base. We can make a kind of &quot;partial sketch&quot; of the parts of the execution flows that interest us.
&gt; For example, we don&#39;t cover how login and register are called, and we don&#39;t cover which further calls are made by UserAuthProvider, SessionProvider or Response, if those parts of the code don&#39;t interest us.
&gt; And if we are dealing with a bug in which isValidUser incorrectly returns false, we can focus more on isValidUser and which methods it calls.

## Notation

Did you notice the textual format used in the previous section to notate the execution flows?

Let&#39;s deep-dive into that.

```mermaid
Class::methodCalling
  ---&gt;|parameters| Class::methodBeingCalled
  ---|return values| Class::methodCalling
```

- `Class::methodCalling` - the caller
- `---&gt;|parameters|` - execution flowing from caller to callee, with the parameters being passed in the call
- `Class::methodBeingCalled` - the callee
- `---|return values|` - execution flowing from callee back to caller, the value returned from the callee
- `Class::methodCalling` - the caller (again)

We can chain these together to notate a sequence of consecutive calls.

For example:

```mermaid
Class1::method
  ---&gt;|parameters| Class2::method
  ---&gt;|parameters| Class3::method
  ---|return values| Class2::method
  ---|return values| Class1::method
```

## Closures and indirection

Thusfar we&#39;ve use the `Class::method` format to reference the callers and callees. This should work reasonably well for classical OO code-bases written in Java, C#, Swift etc.

But what if we want to reference code in other ways, such as named closures, for languages written in Javascript, Typescript, etc.?

Here are some notations that could allow such structures to be referenced:

### Nested closure

foo/bar - Reference a closure witin another closure.



### Indirect call

-.-&gt; - References an indirect method call - a call which our code doesn&#39;t make directly, but causes to be made, such as calling `setTimeout` on a function in Javascript. It looks like a dotted line.

### Example in Javascript

Let&#39;s use an example – a recursive Javascript function – to put all these ideas together.

```javascript
function retry(action, times, count = 1) 
  }, timeout);
}
```

`retry` is a recursive function, which calls `setTimeout`, passing a closure. That closure executes. Depending on the number of times `retry` has called itself already (`time`), it may call `retry` again or simply do nothing, halting the recursion.

We can notate this execution flow, including the closure, using the nested closure, multiple calls, row/column and indirect call notations given above, in the following manner:

```mermaid
flowchart
  retry
    -.-&gt;|action, times=3| retry/handleTimeout
    ---&gt; action
    ---|false| retry/handleTimeout
    ---&gt;|action, times=3, 2| retry
    -.-&gt;|action, times=3, count=2| retry/handleTimeout
    ---&gt; action
    ---|true| retry/handleTimeout
    ---retry
```

## Visualising with Mermaid

Now the juicy part – lets look at how this format can be instantly converted into a visual flowchat using Mermaid!

[Mermaid](https://mermaid.js.org/) is a free, open-source tool, which takes code written in a specific syntax and converts it into a diagram.

You can run Mermaid in the browser using [Mermaid Live](https://mermaid.live/), or if you prefer, you can download and run it locally using the instructions on the [mermaid-live-editor](https://github.com/mermaid-js/mermaid-live-editor) GitHub profile.

We&#39;ll need to add the keyword graph to the top of the text.

Also, in these examples, we add numbered circular nodes (e.g. ---n1((1))) to indicate the order of execution.

The following is how our two earlier Java examples – login success and login failure – render in Mermaid:





And here&#39;s the Javascript example:



Notice that we&#39;ve added small numbered circles, indicating the order in which the calls occur. This makes the flow a bit easier to navigate.

Imagine this appearing in a Slack conversation:

It could potentially be easier to read and follow an execution flow diagram than to read paragraphs of text trying to describe in plain language the complex sequence of calls.


&gt; ### Aside: Asynchronicity and concurrency
&gt;
&gt; Though we touched on async in the Javascript example with the setTimeout call, we haven&#39;t fully addressed the issue of describing asynchronicity or concurrency in execution flows.
&gt; This is probably a fairly deep topic that deserves a dedicated article. However I have no doubt it can be represented diagrammatically, as long as a strict convention is adhered to.

## Isn&#39;t this just a flowchart?

Yes, but it&#39;s a **_specialised_** form of flowchart, focussed on representing execution flow.

The flowchart directly maps to the code it represents, so it accurately and unambiguously conveys information about that code. At the same time, because it&#39;s not actually code, but a diagram, it allows us to more easily view and reason about the code in terms of execution flows specifically. We don&#39;t have to jump around between files, scroll up and down, etc. but can see a whole execution flow in one screen.

Also by establishing and adhering to a convention in how we represent callers, callees, parameters and return values, etc. this flowchart technique is re-usable across programming languages, codebases, business domains, etc. A similar versatility is found in UML, sequence diagrams and other kinds of specialised diagram formats.

## Sequence diagrams

You might have seen diagrams similar to those described here, but laid out as sequence diagrams. Execution flows can certainly be visualised as sequence diagrams. A sequence diagram is arranged as a set of vertical columns connected by arrows, where each column represents a method and each arrow represents a call.



There are weaknesses of sequence diagrams, however.

- They present each method in a column, so we may soon run out of horizontal space, whereas flowcharts can flow **_down and across_**. Also, even for lengthy flowcharts, scrolling up and down is easier on most devices than scrolling side-ways.
- They may position the caller and the callee very far apart, so that the eye has to scan back and forth over a large distance to see the call, whereas flowcharts can more position the caller and callee closer together, making scanning easier.

For these reasons, I find the flowchart format more appealing.

## Automatic generation

Surprisingly, not really.

For dependency visualisation, I found a [few](https://marketplace.visualstudio.com/items?itemName=sz-p.dependencygraph) [interesting](https://marketplace.visualstudio.com/items?itemName=lilinhao.vscode-pylonn) [plugins](https://marketplace.visualstudio.com/items?itemName=CodeLogic.vscodecape) for VSCode, and also experimented with [IDEA&#39;s dependencies analysis](https://www.jetbrains.com/help/idea/dependencies-analysis.html) tool.

However, all of these tools are focused on reporting **_compile-time dependencies_**, which are a different kind of thing to **_execution flows_**.

Dependency graphs of course help us to understand how code is structured, but they don&#39;t give us the full picture of which parts of that code execute in which order at runtime. For that, we really need execution flows.

Theoretically any tool that could automatically report execution flows would need to be able to analyse the code in terms of its expected execution at runtime. The tool might, like a debugger, execute the code, in order to determine the flow of control, e.g. where the flow of control depends on some state which can only be discovered at runtime. Or it could statically analyse the code to determine all possible flows and generate a report of all of them.

It&#39;s beyond the scope of this article to look into how such a tool could be developed, but it&#39;s something I&#39;m interested in looking into and perhaps even undertaking myself.

&gt; ### Aside: Use of ChatGPT
&gt;
&gt; My experimentation with ChatGPT yielded promising results.
&gt; The LLM (Large Language Model) tool was able to generate a flowchart with labels in plain-English in both ASCII and Mermaid formats.
&gt; The flowchart did accurately follow the flow of the code. However, it did not use the format I described above, which is intended to directly map to elements in the code (function names, variable names, etc).
&gt; With some more training of ChatGPT, more detailed prompts or a more customised LLM tool than ChatGPT, perhaps it will be possible in the near future for a chat-bot to generate execution flows automatically. That would be cool!

## Conclusion

This article has outlined a format for describing execution flow, which can be used to visualise and understand how parts of a codebase execute at runtime (and generate diagrams).

This understanding can help to diagnose bugs/errors, determine the best points at which to change the code, estimate how long changes might take, and no doubt many other use cases.

I hope you find it useful!

## Further reading

These books inspired this article:

- [_The Pocket Guide to Debugging_](https://jvns.ca/blog/2022/12/21/new-zine--the-pocket-guide-to-debugging/) • Julia EVANS
- [_UML Distilled_](https://www.martinfowler.com/books/uml.html) • Martin FOWLER

</content>
  </entry>
  

  <entry>
    <title>Front end observability</title>
    <link href="https://conwy.co/articles/front-end-observability" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>front-end-observability</id>
    <content xml:lang="en" type="html">&gt; Summary: Observability can be applied to front end code, specifically: user events, HTTP events and browser events. Tracing can reveal all the events in a particular user-system interaction, while querying across events can identify patterns and anomalies or just learn more about how the system functions. Observability can be surfaced in documentation, empowering all members of a multi-disciplinary team.

I&#39;ve been reading the book [_Observability Engineering_](https://info.honeycomb.io/observability-engineering-oreilly-book-2022) by Charity Majors and thinking about how to apply the ideas to front end development.

She describes the concept of a **_structured event_** - an event &quot;which captures everything that occurred while one particular request interacted with your service&quot; (Chapter 5).

On the front end, a structured event might capture everything that happened during, say, a user interaction or receipt of an HTTP response. This might be done by placing logging calls at key points in the code, similar to how we might place `console.log` statements for local debugging.

In this article I&#39;ll give an overview of front-end observability with some examples using [Sentry](https://sentry.io/).

## Observability on the front end

A key benefit of structured events (compared to unstructured logs) is that they can contain ***rich contextual data points***:

- **User events**, such as what value was entered into an input
- **HTTP events**, such as responses received from a backend
- **Browser events**, such as location data

![Observability points for typical front end applications: HTTP, user and browser events](/images/articles/front-end-observability/observability-points.svg)

These data points are ***queryable*** and we can filter for them using the powerful querying facilities of a monitoring platform such as [Sentry](https://sentry.io/), [DynaTrace](http://dynatrace.com), [AWS CloudWatch RUM](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-RUM-custom-events.html) or [Azure Monitor](https://learn.microsoft.com/en-us/azure/azure-monitor/logs/log-query-overview).

![Querying structured logs in Sentry](/images/articles/front-end-observability/example-stake-error-sentry-query.png)

With structured logs in place, developers can &quot;ask&quot; arbitrary questions about how the application is behaving in production.

We can pro-actively search for unanticipated bugs or diagnose difficult errors involving complex front end logic.

&gt; ### Aside: Capabilities of observable systems
&gt;
&gt; In defining &quot;observability&quot; (Chapter 1), Majors lists the following capabilities:
&gt;
&gt; - Understand the inner workings of your application
&gt; - Understand any system state your application may have gotten itself into, even new ones you have never seen before and couldn’t have predicted
&gt; - Understand the inner workings and system state solely by observing and interrogating with external tools
&gt; - Understand the internal state without shipping any new custom code to handle it (because that implies you needed prior knowledge to explain it)

Let&#39;s look at some examples.

## Example 1 - User event

![Observability point: user interaction](/images/articles/front-end-observability/observability-points-user-event.svg)

Suppose our front end app validates a change to a numeric field:

When the user edits the stake of a shareholder, we want to validate that the total of all shareholder stakes is never more than 100%. But this only applies to _active_ shareholders – we want to skip shareholders which have been turned off.

We want to make the state of our component observable.

Let&#39;s log two structured events:

1. ***changeStakeValid*** - stake was valid; we&#39;ll submit a PATCH
2. ***changeStakeSumError*** - stakes sum was too high; we&#39;ll show an error




  ,
    });

    await patchShareholderStake();

    refreshShareholders();
  } else ,
    });

    showShareholderStakeError();
  }
}
`}
  



Suppose we subsequently receive a bug report:

&gt; The user attempted to enter a 20% stake for one node, but got an error, despite the enabled nodes having a total &lt;= 80%.

We might ask ourselves a bunch of questions:

- Why didn&#39;t our &quot;enabled&quot; logic work in this case?
- Was there a bug in the front end logic?
- If so, how should we fix it?

Instead of having to guess or consult various sources, wouldn&#39;t it be nice if we could more directly observe what happened?

Let&#39;s query Sentry for:

- Events generated by this component - `message:&quot;useShareholderStakeEditor*&quot;`
- For this user - `user.id:1234`
- And this company - `companyId:5678`

![Querying Sentry for structured events by message, user id and company id](/images/articles/front-end-observability/example-stake-error-sentry-query.png)

We find our error event - `changeStakeSumError`:

![Sentry query results indicating an error was logged](/images/articles/front-end-observability/example-stake-sentry-query-results.png)

Clicking on the row reveals some interesting details:

![Sentry error details, showing an item with the tags shareholderId: 113 and stake: 30](/images/articles/front-end-observability/example-stake-sentry-query-result-detail-tags.png)

![Sentry error details, showing an item (id: 112) with the word &quot;[Deleted]&quot; in its name](/images/articles/front-end-observability/example-stake-sentry-query-result-detail.png)

We see that the user was trying to set one shareholder (id: 113) to have a stake of 30%.

However, another shareholder (id: 112), which was `enabled: true`, had the word &quot;Deleted&quot; in its name. The presence of the word &quot;Deleted&quot; likely confused the user into thinking that its 40% stake would not included in the total.

Now we have enough information to propose further actions:

1. Solution: We could add logic that removes words like &quot;Deleted&quot; from names of shareholders, to avoid confusing the user like this in future
2. Solution: We could ask the user to disregard words like &quot;Deleted&quot; and share that knowledge with other users publicly (e.g. via Slack)
3. Investigation: We could find out why users were using the word &quot;Deleted&quot; in shareholder names; is the delete function broken?

Notice that we don&#39;t have to ask the user questions and wait for their response, nor run the application and attempt to reproduce the error, nor query the database, nor puzzle over server-side logs.

Rather, **_we can to go directly to the root of the problem_**, observing logs generated by the specific part of the code which the user was interacting with at the time of the event.

Even better, by naming each logging statement uniquely and using a strict hierarchical naming convention (e.g. `$/$`), we can query more broadly by component, then narrow in on the event, to locate the exact line of code which generated the event!

When you think about it, observability is not all that different from the standard practice of adding `console.log` statements at appropriate points and debugging locally – only it&#39;s more rigorous and queryable and **_we can observe production_**.

## Example 2 - HTTP event

![Observability point: HTTP event](/images/articles/front-end-observability/observability-points-http-event.svg)

On saving a shareholder&#39;s stake, the front end app should refresh the list of all shareholders&#39; stakes.

But suppose we receive another bug report:

&gt; A user reports that the stakes did not refresh after they saved a stake.

So we ask some questions:

- Why did the refresh not work?
- Was there a problem with the PATCH request?
- Did the front end code handling of the PATCH request fail?
- Was there some other kind of issue?

If we log an event on refresh, it should be easier to find out.



  ) );

        captureEvent(,
          },
        });

        const refetchShareholdersResult = await refetchShareholders();

        captureEvent(,
          },
        });
      } else 
    }
    ...
  }
`}
  


As in the previous example, let&#39;s query Sentry for:

- Events generated by this component - `message:&quot;useShareholderStakeEditor*&quot;`
- For this user - `user.id:1234`
- And this company - `companyId:5678`

We find our two events - `changeStakePatchCompleted` and `changeStakeRefreshCompleted` - were both logged:

![Sentry query results, indicating that both the patch and refresh completed successfully](/images/articles/front-end-observability/example-stake-sentry-update-results.png)

However, examining the refresh event, we see that the new stake value was not provided.

![Sentry refresh details, showing stale value for stake of id: 113](/images/articles/front-end-observability/example-stake-sentry-update-result-detail-refetch.png)

Now we know why the stake did not refresh properly – the back end is returning stale data! We&#39;ll need to discuss cache-busting with the back end developers.


## Example 3 - Browser event

![Observability point: browser events](/images/articles/front-end-observability/observability-points-browser-event.svg)

For our final example, suppose the front end app should refresh the list of all shareholders&#39; stakes periodically, e.g. every 30 seconds.

We receive the following bug report:

&gt; A user reports after one user had modified the stakes of certain shareholders, the other users didn&#39;t see the updates until the following day.

We might ask:

- Why did the auto refresh not work?
- Was there a problem with the GET request or code handling the response?
- Was there a Backend issue, such as a cache becoming stale?

Let&#39;s query Sentry for observability on the auto-refresh hook:

- Events generated by the hook - `message:&quot;useShareholdersAutoRefresh*&quot;`
- For this company - `companyId:5678`

We find our autorefresh event - `useShareholdersAutoRefresh` - was logged:

![Sentry query results, indicating that the auto refresh completed successfully](/images/articles/front-end-observability/example-stake-sentry-auto-refresh-results.png)

And hovering over the events column, it looks like it has been running at regular intervals:

![Sentry query results, indicating that the auto refresh ran many times over the last 24 hours](/images/articles/front-end-observability/example-stake-sentry-auto-refresh-results-period.png)

What could have gone wrong? Inspecting the details, we see that different values were returned for one user than for another:

![Sentry event details, indicating a discrepancy between data received for two different users](/images/articles/front-end-observability/example-stake-sentry-auto-refresh-details-compare.png)

This indicates that the back end may be serving stale updates for some users, rather than propagating changes to all users at once.

## Tracing with breadcrumbs

From the previous examples, you may have noticed continuity between events. For example, the user action of editing a shareholder stake generates a sequence of related events: `changeStakeValid`, `changeStakePatchCompleted`, `changeStakeRefreshCompleted`.

Wouldn&#39;t it be nice if we could see a sequence or &quot;flow&quot; of events together in a list?

Thanks to Sentry&#39;s [breadcrumbs feature](https://docs.sentry.io/product/issues/issue-details/breadcrumbs/), we can. Simply open the details of one of the events, scroll down to the Breadcrumbs section, then filter by &quot;Tranaction&quot;.

![Sentry event details, breadcrumbs section, listing a sequence of antecedent events](/images/articles/front-end-observability/example-breadcrumbs-transactions.png)

## Querying across events

With detailed structured events in place, we can form more interesting queries, proactively searching for anomalies or just simply learning more about how our system functions in production.

For example, as we included `companyId` in the events concerned with shareholders, we could more generally query all events associated with that `companyId`. More powerfully, we could query all events associated with **_any_** `companyId`, that is, all company-related events. This could be useful if company was an important entity in our system and we wanted to prioritise fixing of errors related to that entity.

Or take another example – querying by date and time. We could query for events with `message:&quot;*error*&quot;`, within a time of day in which users are experiencing a lot of issues. This would allow us to diagnose the cause of those issues separately from more time-independent issues.

## Observability and documentation

Documentation can be an excellent place to surface observability.

Links to queries in a monitoring system can be placed in wiki pages, where they can be discovered by our team members or others in the organisation as needed.

For example, from our previous example, wouldn&#39;t it be great if a new team member could not only read a textual description of Shareholder stakes, but also be linked to actual production data around this feature?

We could achieve this by querying Sentry for all events with `message:&quot;*shareholderStake*&quot;`, grabbing a link to that query and pasting it into a &quot;Shareholder stakes&quot; wiki page, perhaps under a heading titled &quot;Observability&quot; with a link titled &quot;shareholderStake events&quot;.

![Example: Shareholder stake feature documentation with Observability section and link to `shareholderStake` event query](/images/articles/front-end-observability/docs-observability-section.svg)

Imagine if all feature documentation was augmented with links to observability queries. This could give newcomers and experienced team members alike a boost in understanding how each of those features functions in production.

## Managing observability code

In the interests of keeping code clean and readable, we might want to reduce the quantity and complexity of logging code.

Some ideas:

* Abstraction
* Removal
* Aspects

### Abstraction

We can hide logging behind a more abstract function, to reduce its complexity and surface area.

For example, in a React codebase, rather than directly calling `captureEvent` from `@sentry/react`, we could create and consume our own custom hook, named something like `useLogEvent` returning a function like `logEvent`. The hook and function could encapsulate concerns such as caching re-used data and following a hierarchical naming convention.

### Removal

Similar to feature flag controls, logging code could be scheduled for removal after a period of time, if the software has been working well and is considered not in need of monitoring.

Alternately, we could comment-out logging calls or add a special flag to disable them. Developers could quickly determine that the code is not in use and skip over it.

### Aspects

Aspect-oriented programming involves augmenting the behaviour of existing code without modifying it, typically using a declarative pattern such as [decorator](https://www.w3schools.blog/java-decorator-design-pattern). Frameworks such as [AspectJ](https://github.com/eclipse-aspectj/aspectj) are already used for logging in back end systems.

In front end, [Typescript Decorators](https://devblogs.microsoft.com/typescript/announcing-typescript-5-0/#decorators) may in the near future allow logging to be added in a similar, unobtrusive style.

## Security and privacy

A word about security – sensitive data (such as [personal data](https://en.wikipedia.org/wiki/Personal_data)) should probably be omitted from structured events, to avoid data leakage and comply with regulations.

The chance of sensitive data being accidentally leaked grows with increased use of logging in production (as with any other use of data production). So if your system deals with sensitive data, it&#39;s crucial to have processes in place to ensure that this data is not leaked in logs. This could be part of a code review process as well as an ongoing independent review process, likely involving examination of both code and logs.

## Conclusion

Observability in software engineering is about observing the internal state of a software system during regular usage in production, typically by capturing and monitoring detailed and structured log outputs.

While more commonly applied to distributed systems on the back end, observability can also be applied to the front end, using front end compatible tools such as Sentry to observe states generated by user, HTTP or browser events.

Distinct from typical logging, structured events capture detailed contextual information surrounding the events and make the events queryable (e.g. with tags in Sentry) and traceable (e.g. with Breadcrumbs in Sentry).

Using structured data generated by production logging, we can diagnose an issue or answer an unanticipated question about the behaviour of the system. Additionally, we can proactively search for issues or anomalies by querying across events. And those queries can be integrated into documentation, where they can be discovered and accessed by engineers or other interested parties.

Observability is a newly emerging field within software engineering, and we can&#39;t know for sure what it will look like in the future. Increasing the observability of a front end could potentially be a very worthwhile pursuit, in terms of time and cost saved, where an application is already running in production and complex issues need to be diagnosed and resolved quickly.

## Code example

The source code for the examples mentioned in this article can be found here:

[https://github.com/jonathanconway/observability-example-react](https://github.com/jonathanconway/observability-example-react)

## Further reading

These resources inspired this article:

- [_Observability Engineering_](https://info.honeycomb.io/observability-engineering-oreilly-book-2022) by Charity Majors
- [_Sentry Browser JavaScript Docs_](https://docs.sentry.io/platforms/javascript) by Sentry
</content>
  </entry>
  

  <entry>
    <title>Refactoring vs documentation</title>
    <link href="https://conwy.co/articles/refactoring-documentation" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>refactoring-documentation</id>
    <content xml:lang="en" type="html">&gt; Summary: Understanding and documenting existing systems and code can be a better use of time than large-scale refactoring. This is particular the case in fast-growth businesses, where time is limited and pragmatic concerns outweigh code aesthetics.

Most of the software projects I&#39;ve worked on involved complex and poorly structured code. This can happen for various reasons, even with the most dedicated and experienced developers. The problem space is complex, difficult to navigate and/or highly dynamic, time is limited, there is a high turn-over of developers, language and frameworks have limitations.

Refactoring is an oft-touted solution, aiming to bring order to a chaotic code-base by cleaning and improving the code without changing its functionality. Regression testing, via unit tests and end-to-end tests, allow us to verify that the code still performs its intended function.

The problem with refactoring is that almost no team (that I&#39;ve worked on) ever has time for it. There always seem to be other activities that would generate more business value, and faster, and those activities tend to be prioritised. In the professional world, at least, code only exists to achieve an outcome, not as a work of art for its own sake.

&gt; Pull-quote: In some situations, such as a rapidly growing or changing business environment, understanding and documenting existing code might be a better use of time than a lengthy refactoring.

Given the above, I&#39;ve come to think that, at least in some situations, such as a rapidly growing or changing business environment, understanding and documenting existing code might be a better use of time than a lengthy refactoring. Bad code can stay bad, but can be worked with effectively, if it is well understood by the development team so that they can work with it efficiently.

If software engineering is the art of managing complexity, software documentation is the art of managing the complexity of software.

Let me dive deeper to explain this perspective.

## Why refactoring takes so long

Code-changes themselves are easier than ever. IDEs provide powerful tools for bulk renaming, find-and-replace, structural search, regular expression search, etc. Unit and integration tests can verify correctness of individual components and groups of components. And practices like inversion-of-control, object-oriented programming and functional programming can support decoupled, flexible code bases that are easy to modify.

The time-consuming part of refactoring is not necessarily the code changes. It can be:

1. Working out what changes need to be made and
2. Ensuring that those changes don&#39;t cause system behaviour errors

During a refactoring (at least, in in any non-trivial code-base) we are likely to learn a lot more about the code, frameworks, business domain than we knew beforehand. As we learn more, our refactoring moves change. This means that what started out as, for example, a simple extraction of a function, can quickly turn into a major alteration, impacting many parts of the codebase.

Additionally, as the scope of the refactoring changes, so too does the scope of the regression testing that will need to be done, to ensure that the changes do not cause breakage. Even with 100% unit test coverage, any code change may open up gaps in coverage, requiring tests to be changed or new tests to be written. The application also needs to be end-to-end tested, whether in an automated or manual manner, and the scope of the end-to-end testing is also impacted.

These factors compound, causing a seemingly small refactoring to turn into a major undertaking, with questionable justification for time spent in proportion to business value.

## Understanding the code

For any significant refactoring to be successful, the Developer likely needs to first have a solid grasp of the code being refactored. This means understanding the structure of the code as well as the expected behaviour of the code and the business problem it is intended to solve. Gaining this understanding takes a significant amount of time, as does making the actual changes. [1](#note-1)

I would argue that such understanding is necessary anyway, not only for refactoring, but for making any changes to the code at all, such as implementing new features, making modifications or fixing bugs.

If we have to spend time understanding code, whether or not we actively perform refactoring, then that understanding itself is of value. So we might as well invest more time into understanding the code, rather than trying to refactor it, given the greater payoff of understanding.

That understanding can be converted into documentation, for future reference and to transfer the knowledge to the rest of the team.

## Documentation structure

A powerful feature of documentation is that can be organised in ways that best facilitate understanding and knowledge transfer.

This is much harder to do in code itself. Code usually has to deal with a mixture of concerns at once, such as the programming language itself, software frameworks, interfacing with other modules and systems (such as databases), security, performance, etc.

![Code usually has to deal with a mixture of concerns](/images/articles/refactoring-documentation/code-mixture-concerns.svg)

For this reason, the way a code base is structured usually does not mirror the structure of the problem it is solving or the feature it is implementing. And even if some of the code could be refactored into a perfect, pure representation of the problem space, the problem space itself may be complex and multi-faceted, making it difficult to represent clearly in code.

Documentation, on the other hand, can be structured in any way or multiple ways at once. So documentation can be divided, grouped and organised in whichever way will best facilitate understanding and communication. For example, documentation can pull together information about each feature in the application into a set of &quot;feature&quot; pages.

![Documentation can describe code while being structured differently, for example, by feature.](/images/articles/refactoring-documentation/documentation-vs-code.svg)

## Documentation as a reference tool

Documentation can serve as a handy reference to consult when a certain question needs to be answered around a particular topic.

For example, suppose a Product Owner asks a Developer about some recent problems encountered with the a &quot;Minimum order free shipping notification&quot; feature. The Developer could consult a feature document which contains links to various resources such as web server logs. The Developer could then follow the link to the web server logs to check if any errors were logged.

So documentation can act as a central repository in which to find pointers to various resources, such as parts of the code and other systems.

![Example: Gathering relevant code, logs, databases into a single feature doc.](/images/articles/refactoring-documentation/documentation-reference.svg)

This referenceability, if used correctly, can make it much easier for a Developer to navigate a complex mass of code modules, databases, services, etc. in order to achieve some goal such as answering a question or diagnosing a bug.

## Flavours of documentation

Let&#39;s look at a few documentation &quot;flavours&quot; that could be applied in various scenarios, depending on the situation.

### Feature documentation

This flavour of documentation focuses on a feature of a software product or system used by customers or other actors.

It may give a brief summary of the feature and also provide some background information such as the business case.

It might then have sub-sections detailing the parts that make up the feature. It might also list the components or systems involved in implementing the feature, including links to code repositories and/or individual code files. It might also contain diagrams depicting user flows, execution flows and/or communication between systems. And it might link to various other flavours of documentation described in this article, such as User interface documentation for the User interface components that make up the feature.

![Example: Outline of minimum order value notification feature documentation](/images/articles/refactoring-documentation/feature-doc-example.svg)

#### How it helps to work with difficult code

- Clarifies how the system behaves, or at least, is intended to behave
- Specifies which code or systems implement the behaviour

### Project documentation

This flavour of documentation is similar to feature documentation, only it focuses on a project (which is time-bound), rather than a feature (which may exist indefinitely).

![Example: Outline of time-limited &quot;Easter discount&quot; project documentation](/images/articles/refactoring-documentation/project-doc-example.svg)

#### How it helps to work with difficult code

- Clarifies why certain code or systems are changing

### User interface documentation

This flavour of documentation describes the various parts of a user interface. A Developer can create this kind of documentation to communicate how the user interface currently works, is intended to work and/or should work in the future.

These docs could be organised as a hierarchy, aligned with the navigation structure of the application&#39;s user interface. Each leaf in the hierarchy has a dedicated page, and that page includes screenshots of that part of the UI, along with descriptive text broken into headings.

![Example: UI documentation hierarchy for a shopping cart](/images/articles/refactoring-documentation/ui-hierarchy-example.svg)

![Example: UI screen documentation](/images/articles/refactoring-documentation/ui-doc-example.svg)

#### How it helps to work with difficult code

- Conceptually maps user interface elements to the code that implements them, when that mapping isn&#39;t made obvious by the code itself
- Clarifies how the user interface currently functions, or at least, is intended to function

### API documentation

This flavour of documentation describes a programming interface of an application, such as the REST API of a web backend.

![Example: API documentation for a PUT Order HTTP endpoint](/images/articles/refactoring-documentation/api-doc-example.svg)

#### How it helps to work with difficult code

- Conceptually maps APIs to the code that consumes them, when that mapping isn&#39;t made obvious by the code itself.
- Clarifies how the APIs currently function, or at least, are intended to function.

### Topic documentation

For material which fits none of the above categories, specific &quot;topic&quot; documents can be created.

Suppose we are trying to describe something which isn&#39;t clearly a feature, a project, a part of the user interface or an API. For example, behaviours of an application which only apply in one particular country, for example, Australia. A topic document titled &quot;Australia&quot; could be created, and grouped under a heading such as &quot;Country-specific behaviours&quot;.

![Example: Topic hierarchy](/images/articles/refactoring-documentation/topic-hierarchy-example.svg)

![Example: Topic documentation](/images/articles/refactoring-documentation/topic-doc-example.svg)

#### How it helps to work with difficult code

- Communicates knowledge on specific topics associated with the code base, which are not clearly expressed by the code itself and don&#39;t fit into other categories of documentation.

## Conclusion

Suitable documentation can facilitate understanding of complex and poorly structured code, enabling developers to work with it more efficiently.

Unlike refactoring, documentation can be added without a full build-deploy cycle, without risking breakage and without having to follow the structure of the code.

Creating documentation may be a better use of time than complex refactoring, if you are dealing with a complex code base, have tight time constraints and need to minimise risk.

## Notes

1 According to research, almost 60% of programmers’ time is spent understanding rather than writing code. See “Measuring Program Comprehension: A Large-Scale Field Study with Professionals” by Xin Xia et al. (2017), [https://ieeexplore.ieee.org/abstract/document/7997917](https://ieeexplore.ieee.org/abstract/document/7997917). From the book [_The Programmer&#39;s Brain_](https://www.oreilly.com/library/view/the-programmers-brain/9781617298677/) by Felienne Hermans.

## Further reading

These books inspired this article:

- [_Software Engineering at Google_](https://www.kobo.com/au/en/ebook/software-engineering-at-google) by Titus Winters, Tom Manshreck, Hyrum Wright
- [_The Programmer&#39;s Brain_](https://www.oreilly.com/library/view/the-programmers-brain/9781617298677/) by Felienne Hermans
</content>
  </entry>
  

  <entry>
    <title>Three tests for accessibility</title>
    <link href="https://conwy.co/articles/three-tests-accessibility" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>three-tests-accessibility</id>
    <content xml:lang="en" type="html">There are many good reasons to make our software applications accessible. But to achieve this goal, we must undertake rigorous accessibility testing. 

This presents what may look like an overwhelming challenge: given that there are so many criteria for good accessibility, and that the application itself may be complex in many ways, **how do we verify that all parts of the application are accessible?**

As accessibility is a developing and evolving field, we cannot pretend that there is one silver bullet or one definitive answer. However, I think it&#39;s worthwhile for us to put in a **best effort**.

If we can come up with a small number of tests that cover the most basic and crucial bases of accessibility, then run those tests on all the screens and components of our application, then we can at least say that we have made a significant effort and at most say that we have removed all the most obvious and important impediments to the accessibility of our product.

## Testing on principle

The [WCAG Guidelines](https://www.w3.org/TR/WCAG20/), from which much accessibility advice is derived, are based on [four principles](https://en.wikipedia.org/wiki/Web_Content_Accessibility_Guidelines#WCAG_2.0):

* **Perceivable** - Information and user interface components must be presentable to users in ways they can perceive.

* **Operable** - User interface components and navigation must be operable.

* **Understandable** - Information and the operation of user interface must be understandable.

* **Robust** - Content must be robust enough that it can be interpreted reliably by a wide variety of user agents, including assistive technologies.

I asked one fundamental question of each principle: **what kind of test would verify that this principle had been followed?**

Here are the answers what I came up with:

* **Screen-reader-only**. If I can fully use the application purely by listening to it through a screen-reader, then the application is at least basically &quot;presentable to users in ways they can perceive&quot; and &quot;understandable&quot; through those ways.

* **Keyboard-only**. If I can fully use the application with only a keyboard, then the application is at least basically &quot;operable&quot; by a range of assistive technologies, which operate through the same inputs as the keyboard.

* **Automated test**. If the application passes automated tests, using an appropriate WCAG-compliance testing tool, then it is likely &quot;robust&quot; enough to be be interpreted by various user agents, and meets certain basic technical criteria for being &quot;perceivable&quot; and &quot;operable&quot;.

## Three tests

The three answers lead to three basic tests:

### Test 1: Screen-reader-only

Try to use the application, relying only on **hearing the spoken word**. Turn on a screen-reader and turn off or look away from the screen. You can use the keyboard to provide input as needed.

This tests whether the application is structured in such a way that it can be effectively &quot;presented&quot; to me through one other non-visual assistive technology (a screen-reader). If it can, then it is likely to work almost as well on other non-visual assistive technologies, which rely on the same information that a screen-reader relies on.

Tools:
* [VoiceOver](https://help.apple.com/voiceover/mac/10.14/) (built-in to MacOS and iOS)
* [TalkBack](https://support.google.com/accessibility/android/answer/6283677?hl=en-GB) (built-in to Android)
* [Narrator](https://support.microsoft.com/en-us/help/22798/windows-10-complete-guide-to-narrator) (built-in to Windows 10+)
* [NVDA](https://www.nvaccess.org/) (other versions of Windows)
* [ChromeVox](https://www.chromevox.com/) (Chrome browser on all operating systems)

### Test 2: Keyboard-only

Try to use the application, relying only on **keyboard input**. Put the mouse away or disconnect it, or disable your trackpad.

This tests whether the application is &quot;operable&quot; by a range of assistive technologies, which operate similarly to a keyboard. For example, speech recognition facilities or braille keyboards, which interpret signals analogously to how a keyboard interprets certain keystrokes.

Tools:
* Just your keyboard!

### Test 3: Automated test

Run an automated testing tool on your application, analyse the output and address all major errors detected.

For everything that cannot be captured by tests 1 and 2, automated testing tools can provide some coverage. Of course, an automated tool is just a piece of software and cannot replace aware, focussed human attention. However, it can catch obvious errors that a human may miss, due to human error. It can also thoroughly cover many areas in a short space of time, where a human would take much longer.

Tools:
* [WAVE](https://wave.webaim.org/) by WebAIM (all major operating systems). This tool analyses any web page and provides a detailed report, covering the entire WCAG specification, and highlighting errors.

## Benefits of manual testing

You&#39;ll notice that two out of the three tests are entirely manual and don&#39;t rely on automated tools. While manual testing is harder than just running an automated tool, I think it offers two key advantages:

### 1. It uncovers errors that no automated tool can capture

By actually trying to use our interface, we get a rich, qualitative answer to the question: &quot;how usable is this?&quot;. We can directly observe when the interface is difficult, cumbersome, unclear, or otherwise unusable. We can also directly observe when the interface works smoothly and is easy to use.

A web page might have perfectly structured content, proper usage of semantic HTML and alternative text on all non-textual content. **But what if a user has to listen through 3 minutes of audio, just to sign up for an email alert?**

This is just one example of errors in the interaction design and/or code, which are generally not picked up by automated testing tools.

By actually using an application the way a user would, we can directly identify issues that aren&#39;t clear-cut enough for an automated tool to detect.

Of course, manual testing the application ourselves won&#39;t give us as much information as observing other people try to use it. However, it will probably reveal the biggest and most obvious accessibility issues, giving us an opportunity to resolve them sooner.

### 2. It puts us in the shoes our users

Manual testing encourages us to empathise with our users. This mindset of empathy is a crucial component of good usability, as it affects how we build, what we build and what we prioritise.

## Play well with assistive technologies

One lesson I learned from observing a wide range of users during usability testing was that **users rely a lot on assistive technology, independent of particular applications**.

Many accessibility affordances, from navigating a form to interacting with navigation, are already built in to screen readers and input devices, which are constantly improving and innovating.

* Screen-readers get better at interpreting interfaces and text.
* Input devices are improved to offer more precise and easy-to-use affordances; new input devices come on the market.
* Browsers and operating systems are improve the integration of accessibility features into the user experience.

Rather than trying to anticipate and implement every conceivable accessibility feature directly into our applications, we should instead **focus on making sure our application plays well with assistive technologies**.

We should simply expose the right structures and data and let assistive technologies take it from there. For example, in a rich web application, this means using properly marked-up form elements to label fields and capture form inputs.

![Photo of a person putting their finger on a braille reading device](https://upload.wikimedia.org/wikipedia/commons/4/4a/Plage-braille.jpg)

![Photo of a person using a mouth-held stylus to operate a screen](https://i.pinimg.com/originals/8f/11/23/8f11237b7a530bdfca68f34c5c051952.jpg)

## Conclusion

Rather than getting overwhelmed and giving up on accessibility, might we serve our users better by spending some time on basic testing and letting assistive technologies do most of the heavy lifting? I think the answer is yes!

By means of simple but thorough testing, and making fixes as needed, we will be well our way to making accessible products that work for all of our users.

## Further reading

Boooks that inspired me:

- [_Engineering for Accessibility_](https://www.microsoft.com/en-au/download/details.aspx?id=19262) • Jason GRIEVES, Masahiko KANEKO
</content>
  </entry>
  

  <entry>
    <title>Combinatorial testing</title>
    <link href="https://conwy.co/articles/combinatorial-testing" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>combinatorial-testing</id>
    <content xml:lang="en" type="html">&gt; Summary: Combinators (from functional programming) can be used to generate data-driven tests that cover many combinations of inputs, without having to spell out every possible combination in code.
</content>
  </entry>
  

  <entry>
    <title>Testing Steps</title>
    <link href="https://conwy.co/articles/testing-steps" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>testing-steps</id>
    <content xml:lang="en" type="html">&gt; Summary: The BDD-style &quot;Given/When/Then&quot; syntax adds an additional learning curve and can be cumbersome for long flows. I suggest an alternative: numbered lists of steps and expectations marked out with an &quot;Observe&quot; prefix.

## Introduction

Over the years several [acceptance testing frameworks](https://en.wikipedia.org/wiki/Acceptance_testing#List_of_acceptance-testing_frameworks) have risen and fallen in popularity.

We have seen [Behavior Driven Development (BDD)](https://en.wikipedia.org/wiki/Behavior-driven_development), implemented in formats such as [Cucumber](https://en.wikipedia.org/wiki/Cucumber_(software)) and [RSpec](https://en.wikipedia.org/wiki/RSpec), aiming to provide a human-readable and machine-parsable syntax for defining requirements. Developers and business people collaborate to produce specs in a &quot;Given/When/Then&quot; structure. Developers then implement an executable test for each spec using a more standard programming language test framework, such as JUnit, XUnit, Jasmine, etc.

Though it has grown in popularity, the BDD style has two disadvantages:

1. The &quot;Given/When/Then&quot; syntax adds an additional learning curve for people not familiar with the language.
2. The &quot;Given/When/Then&quot; structure (if adhered to) constrains the tests, forcing all assertions to take place after all actions, rather than allowing a sequence of interleaved actions and assertions.

Instead of BDD, we could use a much simpler and more familiar syntax:

**An ordered list of testing steps**

In this _testing steps_ approach, we remove the Given/When/Then structure altogether and simply list our sequence of steps and assertions. As with BDD tests, we then write code that implements each of the steps, using templating and parameterization where appropriate for reusability.

Instead of:

```
GIVEN x
WHEN y
THEN z
```

We write this:

```
1. x
2. y
3. z
```

## An example

Suppose we wish to write a spec for the following requirement:

&gt; Display an error if a currency conversion is over the limit for that currency, along with a Max button which resets the payment amount to the maximum amount, and then allows the user to proceed with the payment at that amount.

This requirement might be captured in two BDD specs such as the following:

&gt; ### TITLE: Validate currency limit with max button
&gt;
&gt; ### SCENARIO 1: Validate currency limit
&gt;
&gt; - **GIVEN** I am a registered user
&gt; - **AND** I have a bank balance of 100,000 GBP
&gt; - **AND** The maximum conversion from GBP to CAD is 50,000
&gt; - **WHEN** I go to the Make a Payment screen
&gt; - **AND** I set the Destination currency to CAD
&gt; - **AND** I set the Payment amount to 51,000 GBP
&gt; - **THEN** I will see a Currency conversion over daily payment limit error
&gt; - **AND** I will see a Fill max currency button
&gt;
&gt; ### SCENARIO 2: Provide Max button, which resets currency to limit value
&gt;
&gt; - **GIVEN** I am a registered user
&gt; - **AND** I have a bank balance of 100,000 GBP
&gt; - **AND** The maximum conversion from GBP to CAD is 50,000
&gt; - **WHEN** I go to the Make a Payment screen
&gt; - **AND** I set the Destination currency to CAD
&gt; - **AND** I set the Payment amount to 51,000 GBP
&gt; - **AND** I click the Fill max currency button
&gt; - **AND** I click the Submit payment button
&gt; - **THEN** I will see a Payment successful screen
&gt; - **AND** I will see the amount paid as 50,000 GBP

Notice how cumbersome and repetitive this is.

Using a ***testing steps*** format, we could replace it with a single, neatly condensed sequence of steps:

&gt; ### SCENARIO: Validate currency limit with max button
&gt;
&gt; 1. Log in as a registered user
&gt; 2. Assume a bank balance of 100,000 GBP
&gt; 3. Assume a maximum conversion from GBP to CAD of 50,000
&gt; 4. Go to the Make a Payment screen
&gt; 5. Set the Destination currency to CAD
&gt; 6. Set the Payment amount to 51,000 GBP
&gt; 7. Observe the following error is visible: Currency conversion over daily payment limit
&gt; 8. Observe the following button is visible: Fill max currency button
&gt; 9. Click the Fill max currency button
&gt; 10. Click the Submit payment button
&gt; 11. Observe the following success message: Payment successful screen
&gt; 12. Observe the following field | value: Amount paid | 50,000 GBP

Notice how this latter form conveys the same information as the BDD spec, but without the Given/When/Then structure, and as a sequence of actions/events in a single flow.

Also notice that this is closer to how most human beings would manually test this kind of behavior. They wouldn&#39;t separate their testing into two sets of three distinct phases, starting over again after the first set. Rather, they would more likely perform just one sequence of steps, verifying the correctness as they go, all the way until the last step.

It&#39;s true that the testing steps don&#39;t explicitly tell us which of the steps are arrangements/pre-conditions, which are actions and which are assertions/post-conditions. For example, step 8 doesn&#39;t explicitly tell us that it is an assertion. However, I would argue that this fact is implicit in the language anyway and the average reader should have no problem interpreting a statement like &quot;I will see a Fill max currency button&quot; as an expectation rather than an action for the reader to perform.

From the developer&#39;s point of view, it doesn&#39;t matter either; any of these steps can have its own code block, associated via string/template matching. We don&#39;t need to specify whether a step is a Given, a When or a Then, in order to match the step to the correct code block. (If we want to make that attribute explicit in code, we can always do so with a comment, decorator, method naming convention, etc.)

## Conclusion

It seems to me that the &quot;Given/When/Then&quot; way of structuring spec tests is a relic of design by contract and intended to help the code more than the user. It is unnecessary to structure tests in this way. Instead we can use a simple sequential list of steps. This is simpler, more user-friendly and more suitable to typical testing in which actions and assertions are intermingled throughout a sequence.

Users don&#39;t normally think in terms of pre-conditions/post-conditions, but are much more likely to think in terms of sequence of actions they perform and responses they get from the system.

## Library

During writing of this article I developed a new testing framework which applies the concept of testing steps.

You can check it out here: `testing-steps`.

This framework is a Javascript/Typescript library which can be consumed by unit tests targeting the Jest test runner.

If there is enough interest, I will look at getting it ported to other languages/frameworks.

## Further reading

Books that inspired me:

- [_The Cucumber Book_](https://pragprog.com/titles/hwcuc2/the-cucumber-book-second-edition/) • Matt WYNNE
</content>
  </entry>
  

  <entry>
    <title>Diagramming Typescript</title>
    <link href="https://conwy.co/articles/diagramming-ts" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>diagramming-ts</id>
    <content xml:lang="en" type="html">&gt; Summary: Typescript structures can be diagramming in a UML-like format, depicting Interfaces and Types (including inheritance and composition), Enums and Functions (including parameters and return types) as rectangles, with suitable connecting lines.

As the practice of front-end development grows and evolves, front-end developers find themselves working with increasingly complex problem domains, requirements and code-bases. This necessitates increasing usage of solution design and planning tools, such as [wireframes](https://en.wikipedia.org/wiki/Website_wireframe), [component diagrams](https://reactjs.org/docs/thinking-in-react.html#step-1-break-the-ui-into-a-component-hierarchy), [user stories](https://www.martinfowler.com/bliki/UserStory.html), etc.

In recent work on large, complex Typescript code-bases I&#39;ve found myself doing a significant amount of upfront solution design, planning modifications or additions to the code by way of high-level diagrams.

In this article I want to share a &#39;tweaked&#39; form of UML that I&#39;ve been using in solution designs on Typescript code-bases.

But let&#39;s first review the utility of diagrams and UML.

## Why diagrams?

To motivate this article, I want to review uses and benefits of diagrams.

Diagrams have the following features, distinct from either code or documentation:

- ***Partial.*** Diagrams can &quot;sketch&quot; some parts of code while omitting others
- ***High-level.*** Diagrams can depict high-level components while omitting low-level implementation details
- ***Spatial.*** Diagrams are in 2D space, enabling us to better visualise the parts and how they connect to eachother

By virtue of these features, diagrams offer certain unique uses and benefits at different stages of the software lifecycle.

- Solution design
- Planning complex changes
- Documentation

### Solution design

Solution design helps us to conceive our solutions before implementing them. We can begin to assemble the pieces of the solution and envisage how they will interact with eachother in advance of writing any code. This helps us to clarify our work, avoid costly mistakes and rework and come up with better time estimates. The benefits are multiplied when solution design is shared between multiple team members and improved based on their feedback.

Diagramming is an excellent way to both develop and communicate a solution design. Diagrams, which don&#39;t need to be compiled, can be built partially, creating a kind of &quot;code sketch&quot; that communicates software design at a high level while omitting details. Diagrams are laid out spatially, allowing us to organise our thinking outside the constraints of the file system or compiler.

&gt; ### Aside: Multi-stakeholder solution design
&gt;
&gt; In some organisations multiple stakeholders may need to approve a solution – from product owners to designers to security specialists. In these cases it&#39;s even more beneficial to develop solution designs and share them with the stakeholders. The stakeholders can then have an opportunity to identify issues and risks before implementation commences. They can co-design the solution with developers, shaping it in beneficial ways before implementation begins.

&gt; ### Aside: Agile solution design
&gt; 
&gt; There is a culture in some development teams of avoiding solution design, thinking it is unnecessary and even to be avoided, since it is part of undesirable &quot;big upfront planning&quot; or &quot;waterfall&quot; methodology. The idea is that &quot;agile&quot; is a new and better way of working and, as such, developers should begin coding as soon as possible with minimal planning and preparation (&quot;MVP&quot;).
&gt;   
&gt; My thinking goes against this, but addressing it in-depth is beyond the scope of this article. But to summarise: if you carefully review the agile literature, it is very rare for it to discourage planning, big picture thinking, solution design or architecture.
&gt;   
&gt; In fact, some of the most popular agile practitioners, such as Bob Martin and Martin Fowler, have written lengthy books on both architecture and UML. Thus it is apparent that agile is broadly compatible with solution design and planning.

### Planning complex changes

As our software grows in multiple directions (code size and complexity, users, features, etc.) the complexity of making changes increases. Any change, from renaming a field to adding cross-cutting functionality such as monitoring, can involve changes to many components across the code-base. We may need to envisage the impacts of these changes and carefully plan them out, paying regard to constraints such as time, system resources, performance, etc.

This is where diagramming can come in handy. As we analyse the code directly, we can also begin to sketch out a partial model of the code, focussing on just the components that will need to be changed. We can then add our changes to this model and use annotations, dashed rectangles or whitespace to mark our which parts are changing.

### Documentation

Diagrams can form a useful part of documentation. They can be added to wiki pages, task trackers and pull requests, to help developers and other team members understand the structure of the code.

We can create a diagram only depicts once slice of the code-base, and omit implementation detail. This helps when documenting a cross-cutting aspect of the code-base.

For example, we might have one page in the wiki dedicated to the topic of &#39;SMS verification&#39;. That page could detail the systems and processes involved in sending an SMS verification message. It could include a diagram depicting only the parts of our code involved in SMS verification and how they connect to eachother, omitting parts that aren&#39;t directly involved in SMS verification.

## Background on UML

UML is a widely used diagramming language for depicting object-oriented code structures. Normally used with strongly-typed, class-based programming languages, such as Java and C#, it focuses on representing the public interfaces of classes, interfaces and other structures, inheritance relationships between classes (generalisation, realisation, etc.) and relationships between objects generated by classes (association, aggregation, composition).

The UML standard covers a range of diagrams, most of which can be readily applied to Typescript and/or front-end projects with practically no tweaking.

Notice, however, that UML &quot;class diagrams&quot; (as the name suggests) are focussed on depicting classes and objects. Most Typescript code-bases (especially front-end) are much more focussed on functions and types. This is in good part due to the functional style of programming that predominates in front-end languages (Javascript), frameworks (React), libraries (Redux) and tooling.

This presents a challenge: there is a dissonance between the class focussed world of UML and the function and type focussed world of Typescript. It seems like we need to tweak UML in order to use it effectively in a Typescript context.

Happily, as we will see, this is all quite doable. In fact, &quot;Typescript UML&quot; can be realised as a subset of UML without significantly altering the language.

## Applying UML to Typescript

The first thing to note is that with Typescript we need to model functions and types – structures which aren&#39;t traditionally supported by UML.

UML already allows for extensibility, via the &quot;stereotype&quot; pattern, annotations and on connector lines. We can carefully apply use these features to depict important Typescript structures such as types and functions, while preserving the overall idioms of UML, to keep the diagrams clean, consistent and (if needed) broadly accessible to non-Typescript developers.

## Interfaces, types and enums

Interfaces and enums, which are also present in class-based languages, translate immediately over to UML.



  class BaseUser 
  BaseUser ..&gt; UserType
*/}

![UML diagram depicting an interface, a type and an enum](/images/articles/diagramming-ts/interfaces-types-enums.svg)

```typescript
enum UserType 

interface BaseUser 
```

Types can get a little more tricky. A type might simply be declared equivalent to another structure – such as an interface or another type. Or it might also be a composition of other structures, such as a conditional type or mapped type.

How can we accurately represent our types diagrammatically without overburdening our diagrams with code-like detail?

My approach here is to simply lay out all the types involved and depict their relationships to eachother without necessarily including logical constraints or finer-grained details such as mapped properties. Where such details are crucial, they can be placed in a nearby &#39;note&#39; element (already a feature of standard UML) and/or, as in the case of mapped properties, simply included in the type&#39;s first compartment.



  class BaseUser 
  BaseUser ..&gt; UserType

  class Pilot 
  Pilot --|&gt; BaseUser

  class Crew 
  Crew --|&gt; BaseUser

  class User 
  User --|&gt; Pilot
  User --|&gt; Crew

  class UserAccountInfo 
  UserAccountInfo --|&gt; BaseUser: (pick)
*/}

![UML diagram depicting a group of related types](/images/articles/diagramming-ts/interfaces-types-enums.svg)

```typescript
type PilotLicenceNumber = string;

type Pilot = BaseUser &amp; ;

type Crew = BaseUser &amp; ;

type User = Pilot | Crew;

type UserAccountInfo = Pick;
```

I&#39;m not sure if this is ideal, but it seems a reasonably pragmatic approach. Note that UML allows us to depict the code partially, not necessarily exhaustively.

We can also depict ***associations*** between different interfaces/types in the same way as regular UML class diagrams. In this example, we depict a `Flight` interface which aggregates `Crew` and `Pilot` members, along with the cardinality of the relationship.



  class Crew 

  class Flight 
  Flight &quot;0&quot; o--&gt; &quot;n&quot; Crew : crews
  Flight &quot;0&quot; o--&gt; &quot;n&quot; Pilot : pilots
*/}

![UML diagram depicting types with their associations](/images/articles/diagramming-ts/interfaces-types-associations.svg)

```typescript
interface Flight 
```



## Functions

As the name suggests, UML &quot;class diagrams&quot; are normally oriented toward depicting classes, which are treated as the main building blocks of class-based programs.

Typescript programs however, especially on the front-end, tend to more heavily emphasise functions. Functions are treated as &quot;first class citizens&quot;, meaning that they make up important structural elements of the program, and are not merely an implementation detail.

Nevertheless, we can take UML&#39;s &quot;box with two compartments and a title bar&quot; and re-purpose it for diagramming Typescript functions.

The public interface of a Typescript function primarily consists of its parameters and return type. We can repurpose the first compartment of our box to depict the parameters passed in to the function. Since a function has no publicly accessible &quot;instance&quot; members, there&#39;s no need to represent them at all. The lower compartment can contain private variables held in scope of the function, which, as with private members of a class, aren&#39;t accessible from outside.


  isValidUser ..&gt; User : user
  isValidUser ..&gt; isValidPilotLicenceNumber : (calls)

  class isValidPilotLicenceNumber 
  isValidPilotLicenceNumber ..&gt; PilotLicenceNumber : licenceNumber
*/}

![UML diagram depicting functions](/images/articles/diagramming-ts/functions.svg)

```typescript
function isValidUser(user: User): boolean 

function isValidPilotLicenceNumber(licenceNumber: PilotLicenceNumber): boolean 
```

This leaves one important problem – how do we represent the return type of a function?

## Return types of functions

Since a Typescript function only has one return type, we might want to represent it as one structure. That type could have one or more members (if it is an inline type, interface or class). It could also have relationships to other types (e.g. an interface that realises another interface). It could even be another function.

We could designate an additional, third, compartment in which to place information about the return type. There are two downsides to this, however. Firstly, introducing a third compartment increases the learning curve for someone who is more accustomed to seeing only two compartments in a UML box diagram. They must figure out what the third compartment signifies and then remember that it signifies the return type and that they should look there for the return type. Secondly, there is the awkward problem of representing a return type which isn&#39;t simply a collection of members. How do we represent a return type that itself has a relationship with another type? Or a return type that is itself a function? If we simply list a single name in the third compartment as though it is a member, this creates confusion as to whether we are naming the return type itself or a member of the return type. For the above reasons it seems inconvenient to house our return type in the third compartment – or any compartment – of a Function box.

A better way is to put the return type in a separate box altogether. We can actually do this, in much the same way as we would represent a type of a function parameter. The relationship can easily be clarified with a connector, which points from the function box to the return type box with a &#39;returns&#39; label.


  fetchFlightDetails ..&gt; Flight : (returns)


  class Flight 
*/}

![UML diagram depicting a function and its return type](/images/articles/diagramming-ts/function-return-type.svg)

```typescript
async function fetchFlightDetails(id: string): Flight 
```



## Framework-specific functions

We can do a similar re-purposing to support framework-specific building blocks which are functions – for example, React **components** and custom **hooks**.

UML includes a &quot;stereotype&quot; pattern – a double-angle-bracketed name that sits above the title. This can be used to label our functions – e.g. `&lt;&gt;`, `&lt;&gt;` for React-specific functions. These, along with the aforementioned ways of depicting functions and types, can be used to diagram the components of a React application.


  useFlightDetails ..&gt; Flight : (returns)
  useFlightDetails ..&gt; fetchFlightDetails : (calls)

  class FlightDetails 
  FlightDetails ..&gt; useFlightDetails : (calls)
  FlightDetails &quot;1&quot; *--&gt; &quot;1..m&quot; PilotDetails : (renders)
  FlightDetails &quot;1&quot; *--&gt; &quot;1..m&quot; CrewDetails : (renders)

  class PilotDetails 
  PilotDetails ..&gt; Pilot

  class CrewDetails 
  CrewDetails ..&gt; Crew
*/}

![UML diagram depicting React components and hooks](/images/articles/diagramming-ts/react-components-hooks.svg)

```typescript
function useFlightDetails(: ):  

function FlightDetails(: ): React.Node 

function PilotDetails(: ): React.Node 

function CrewDetails(: ): React.Node 
```

Note: As React components typically take a single &#39;props&#39; object as a parameter, I opted to just inline that object&#39;s members in the first compartment of the `&lt;&gt;` box. This very small inconsistency probably won&#39;t be too confusing to anyone who has a basic understanding of React.



## Putting it all together

For your reference, here is one big UML diagram comprising all the pieces discussed in this article:



  class BaseUser 
  BaseUser ..&gt; UserType


  class string 

  class PilotLicenceNumber 
  PilotLicenceNumber --|&gt; string

  class Pilot 
  Pilot --|&gt; BaseUser
  Pilot ..&gt; PilotLicenceNumber : licenceNumber
  Pilot ..&gt; UserType : type

  class Crew 
  Crew --|&gt; BaseUser
  Crew ..&gt; UserType : type

  class User 
  User --|&gt; Pilot
  User --|&gt; Crew

  class Flight 
  Flight &quot;0&quot; o--&gt; &quot;n&quot; Crew : crews
  Flight &quot;0&quot; o--&gt; &quot;n&quot; Pilot : pilots


  class isValidUser 
  isValidUser ..&gt; User
  isValidUser ..&gt; isValidPilotLicenceNumber : (calls)

  class isValidPilotLicenceNumber 
  isValidPilotLicenceNumber ..&gt; PilotLicenceNumber : licenceNumber



  class fetchFlightDetails 
  fetchFlightDetails ..&gt; Flight : (returns)




  class useFlightDetails 
  useFlightDetails ..&gt; Flight : (returns)
  useFlightDetails ..&gt; fetchFlightDetails : (calls)

  class FlightDetails 
  FlightDetails ..&gt; useFlightDetails : (calls)
  FlightDetails &quot;1&quot; *--&gt; &quot;1..m&quot; PilotDetails : (renders)
  FlightDetails &quot;1&quot; *--&gt; &quot;1..m&quot; CrewDetails : (renders)

  class PilotDetails 
  PilotDetails ..&gt; Pilot

  class CrewDetails 
  CrewDetails ..&gt; Crew
*/}

![UML diagram depicting all the ideas discussed in this article](/images/articles/diagramming-ts/all-together.svg)

With all these parts in one diagram, including connective lines, we can perhaps see more clearly one of the main benefits of diagramming: being able to zoom out and see how all the parts connect together to form the whole.

We can, for example, easily see which components depend on the core types `Pilot` and `Crew`. During initial solution design, this diagram might help us to estimate and prioritise the work. Or during a complex change, it might help to visualise the impact, were we to modify one or both of these types.

This kind of &quot;birds-eye view&quot; wouldn&#39;t be possible with just code alone, which appears in a hierarchy of folders and files. Even if we expanded every folder, we still wouldn&#39;t see all the connections between the structures contained in the files. Diagrams give us a more powerful visualisation of our code.

## Future directions

Many UML-code and code-UML converters already exist, supporting class-based programming languages such as Java and C#. It would be great to see such tools implemented for Typescript. [tplant](https://github.com/bafolts/tplant) looks like a promising start, though it appears to only support the code-UML direction.

It would be interesting to see if subsets of UML emerge, focussed on representing functional and/or Javascript/Typescript structures.

State-charts have already been recommended for diagramming Redux state machines. Perhaps it would be better for developers to standardise on UML state diagram notation.

## Further reading

These books may serve as a handy guide and reference on UML:

- [_UML Distilled_](https://www.martinfowler.com/books/uml.html) • Martin FOWLER
- [_The Unified Modelling Language User Guide_](https://www.amazon.com/Unified-Modeling-Language-User-Guide/dp/0321267974) • Grady BOOCH
- [_Modelling with UML - Language, Concepts, Methods_](https://www.abbeys.com.au/book/modeling-with-uml-language-concepts-methods-book-9783319816357.do) • Bernhard RUMPE
</content>
  </entry>
  

  <entry>
    <title>Uses of mock data</title>
    <link href="https://conwy.co/articles/mock-data" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>mock-data</id>
    <content xml:lang="en" type="html">&gt; Summary: Rigorous use of mock data can benefit complex, long-term software projects by thinking about examples during modelling, providing unit test inputs, quickly simulate any desired application state and decouple immediate inter-team dependencies. The costs including the need to structure the application in a suitable manner and the time/effort to add mock data.

Mock data, dummy data, fake data, test data, sample data.

These terms all express the same thing:

**Data that a developer hard-codes in place of real data.**

In my observation, mock data has tended to be used in a rather loose, slipshod, careless manner. Unlike documentation, it is treated as the garbage of software material. (Sometimes even referred to as &quot;garbage data&quot;). People will try to avoid writing it by using elaborate &quot;generators&quot; such as [jFairy](https://github.com/Devskiller/jfairy) or [zed](https://github.com/brimdata/zed).

My argument in this article is that mock data, when treated with respect, turns out to be a supremely useful, versatile and valuable tool.

I find four special uses for mock data:

1. [Designing and documenting](#designing-documenting)
2. [Unit testing](#unit-testing)
3. [Manually testing](#manually-testing)
4. [Decoupling teams](#decoupling-teams)

I will elaborate on each of these.

## Designing &amp; documenting

Let&#39;s begin with an example that should be reasonably familiar to most developers:

**Validating a username in a sign-up form.**

Suppose we want to capture and validate one of three kinds of username:

- an email address -or-
- a 9-character alpha string -or-
- a numeric employee number

We might begin by modelling the `username` field as a `string | number` data-type that covers all three kinds of username.

```typescript
type Username = string | number;
```

The above type expresses a part of our requirements but not all of them. Specifically, it doesn&#39;t express such facts as:

- the username might be an email
- the username might be a 9-character string
- the username might be a string longer than 9 characters, but that would be invalid

How might we express these requirements in code prior to writing a validation routine?

One way might be to write descriptive comments next to the field. Another way might be to bring in a hefty and cumbersome &quot;validation framework&quot; such as `zed` and try to twist and wrangle it to the shape of our specific requirements.

Or... we could simply create a few mock values:

```typescript
const UsernameMocks = ;
```

We have now enumerated the variants of the username field that we expect to deal with.

And we&#39;ve given them descriptive names. Naming them this way helps us to think clearly about the requirement and allows us to document the requirement in code.

Looking at these mock values, we might also begin to ask questions. For example: does a numeric username have a lower and upper bound? Safe assumptions might be `0` and `Number.MAX_SAFE_INTEGER`, but we might want to check with a domain expert.

The point is, by laying out all the expected values of this field together in one view, we give ourselves an opportunity to think more deeply about the range of possible cases and how we will deal with these cases. In this way, mock data becomes a kind of tool for concretising requirements.

We can now begin to think about how we might design and test the validation routine.

## Unit testing

As we begin to write a username validation function, the `Username` type definition combined with `UsernameMocks` given above lead directly to four unit tests:

```typescript
describe(&quot;validateUsername&quot;, () =&gt; );

  it(&quot;validates text 9 chars long as true&quot;, () =&gt; );

  it(&quot;validates text more than 9 chars long as false&quot;, () =&gt; );

  it(&quot;validates number as true&quot;, () =&gt; );
});
```

This isn&#39;t a coincidence – the whole point of mock data is to represent kinds of values we expect to deal with. Our unit tests need to do the same thing, to verify that the system under test behaves as we expect.

We can now begin to implement the requirement, writing each of the unit tests one by one, and writing enough code to make it pass.

Alternately / additionally, we could use this information about expected inputs to scaffold the function with comments:

```typescript
function validateUsername(username: Username): boolean 
```

This is just scratching the surface!

As we write the tests, we notice that we can reference the mock constants directly inside the test code, to avoid repeating ourselves.

For example:

```typescript
describe(&quot;validate username&quot;, () =&gt; );
});
```

Notice how clean and readable this test is!

The naming of the mock constant reveals the intent of the test beautifully. Rather than pollute our test code with concrete values, we can extract them to well-named constants and have the test code focus on the _relationships_ between the values.

The re-use can go even further. Suppose, in a different part of the code, we want to display a user profile which includes the user&#39;s username. We want to style the text differently depending on what kind of username the user has.

We might extract the username type and mocks to its own module, say, `username.ts`. Then we can re-use the mock usernames in our tests, like so:

```typescript
describe(&quot;user profile&quot;, () =&gt; );

  it(&quot;renders email username in sans-serif&quot;, () =&gt; );

  it(&quot;renders alpha username in sans-serif&quot;, () =&gt; );
});
```

In future we might need to maintain username code – e.g. support additional kinds of username, remove support for a kind of username, fix a mistake in one of the mock values, etc.

It will be much easier to find the code that needs to change across the whole codebase if we use consistent mock constants than it will be if we use inconsistent mock literals.




    class UsernameMocks 
    UsernameMocks ..|&gt; Username

    class UsernameTests 
    UsernameTests ..&gt; Username
    UsernameTests ..&gt; UsernameMocks

    class UserProfileTests 
    UserProfileTests ..&gt; Username
    UserProfileTests ..&gt; UsernameMocks
`}

The end result is that any test code that deals with mock values will be:

- faster to write
- easier to read
- more maintainable

**Bonus:** And we&#39;re talking about more than just unit-tests here! Mock values can also be used to fill in live component demos (e.g. Storybook stories), dynamic documentation (e.g. Docusaurus pages) and snapshot tests (e.g. PhantomJS screenshots).

## Manually testing

Imagine if our application was augmented with mock data in such a way that all of its features could be used while running purely off the mock data, without ever having to connect to any real data-source. (By &#39;data-source&#39;, I&#39;m referring to things like databases, APIs, etc.)

This capability would offer some unique advantages:

- We could simulate any behavior we desired in our application (by mocking states that could trigger that behavior)
- We could test how the application would respond to an unexpected state (by mocking that state)
- We could run and develop the application entirely on mocks while the external data-source was down, e.g. during an outage or planned maintenance
- We could develop new features in advance of the data-source supporting them (adding mock data as needed and only substituting real data as it becomes available)
- We could demo features of an application to stakeholders prior to having an external data-source to support that feature
- We could mock data to model changes to an external data-source, to clarify our own thinking and/or to communicate requirements to the data-source maintainers

Mocking all of an application&#39;s data-sources might seem like a daunting task. However, in my experience, it&#39;s easier than it might seem, especially if done in the early stages of a project.

But there are a few pre-requisites.

Firstly, the application needs an interchangeable data-source, so we can switch between real data and mock data. We need to write all our application code against that data-source abstraction, without concern for where the data actually comes from.


    B --&gt;|Yes| C[Use mock data]
    B --&gt;|No| D[Use real data]
`}

Secondly, we need to be able to switch the Application state between the real data-source and a mock data-source.

- Some Single Page Application (SPA) projects use a state container such as Redux. In that case, we might dispatch a `SetMockStateAction` which sets an `isMockMode` flag in the store. When this flag is `true`, all data-retrieval actions use mock data rather than making a real HTTP call.

- In other cases (typically a SPA or a micro-service), an HTTP API client sits between the Application state and the HTTP API and calls the HTTP API to fetch data. We could add a `setMockState` method here, which sets a private `isMockMode` field which, when `true`, uses mock data rather than making a real HTTP call. Or we could set up a Dependency Injection (DI) system, in which an abstract `APIClient` interface is implemented by `HttpAPIClient` and `MockAPIClient`, which can be substituted at runtime.

The &quot;switch&quot; could be activated by clicking a UI element, e.g. a small checkbox in the footer area of a web page, which is only visible to Admin users. The click handler toggles the Application state between real data-source vs. mocks.

![Screenshot of a mock data checkbox](/images/articles/mock-data/mock-data-checkbox.svg)

Thirdly, we need all of our application state to be mocked in a set of mock constants. This is easiest if the application state is modelled in some more abstract way, e.g. using classes, interfaces, types, etc. That way, we can easily construct our mock data as a realisation of those abstractions.



    class MockAccount 
    MockAccount ..|&gt; Account
    
    class Invoice 

    class MockInvoice 
    MockInvoice ..|&gt; Invoice
`}

It would take significant effort to completely mock the data-sources of a pre-existing application. But that effort could be broken down into smaller pieces and pursued incrementally, similar to adding unit tests.

Once our application is completely augmented with mock data, maintaining the mock data going forward would only add a small overhead (and might even boost development speed, as described in sections 1 and 2).

---

How about switching between _multiple_ mock states? One way would be via a collection of mock controls, presented to Admin users in the UI, allowing the mocks to be adjusted at whatever level of detail is needed. These could be presented in a pop-up modal or panel activated by clicking a Mock Settings button located somewhere out-of-the-way and only accessible to Admin users.

The following screenshot depicts mock controls for a hypothetical online banking application, allowing the user&#39;s home country, preferred currency and business / personal accounts to be adjusted.

![Screenshot of controls for more complex customization of mock data](/images/articles/mock-data/mock-data-controls.svg)

## Decoupling teams

Once our entire Application is able to run off mocked data, not only can we _operate_ the application while a data-source is unavailable, but we can also _operate and develop_ application features prior to the data-source even supporting them.

**Mocking our data-sources decouples our team&#39;s development efforts from other teams.**

For example, imagine we are working in an _Invoicing_ team in an online banking system. We want to build a &quot;Foreign Accounts&quot; feature. Suppose this feature depends on data from an _Accounts_ team. Without mock data, the Invoicing team might have had to await until the Accounts team had built certain APIs, which it would then consume.

But with mock data, the Invoicing team no longer needs to wait for the Accounts team to support a Foreign Accounts feature, but rather, it can immediately begin developing the Foreign Accounts feature. We merely need to model Foreign Accounts interface in a way that makes sense for Invoicing purposes, and from those models, derive mocks.



We can develop and test all the Invoicing logic against those mocks. When the Accounts team does finally support Foreign Accounts we can connect our Invoices system to theirs. Any dissonance between their models and ours can be solved by adding a mapping layer, e.g. an `AccountsAPIDataSource` which implements `AccountsDataSource` methods by calling AccountsAPI methods.


    InvoicingApplication ..&gt; ForeignAccountsDataSource

    class ForeignAccountsDataSource 

    class ForeignAccountsAPIDataSource 

    ForeignAccountsAPIDataSource ..|&gt; ForeignAccountsDataSource
    ForeignAccountsAPIDataSource ..&gt; AccountsAPI
    
    class AccountsAPI 
`}

Notice how we are building our Foreign Accounts feature against a `ForeignAccountsDataSource`, which functions as a kind of contract between the `InvoicingApplication` (which we control) and the `AccountsAPI` (which the other team controls).

This contract helps us to think more clearly about what we need from the Accounts team - the inputs and outputs and behaviors. So we can communicate more clearly with the teams who we depend on about the data we depend on them for.

### Sharing mocked states with team members

With mocked data in place, we can share various configurations of our application with team members such as QA engineers / testers, product owners, usability and accessibility professionals and others.

One technique applicable to web applications (which I used on a recent real-life project) is to configure the mock states via queryString parameters in the URL. The URL can then be shared with anyone who needs to see the web application in the mocked state. Rather than having the team member go through complicated sequences of steps to simulate a given state, all they need to do is to open the link.

For example, if we want to simulate the state in which the user entered a credit card into a payment page, but the card has expired, we might share a URL like this: http://myapp.com/payment-details?mockCreditCardExpired=true. This URL could be used to test the error message that is displayed for expired cards.

## Other uses of mock data

We&#39;re talking about more than just simulating expected (or unexpected) application states! We can also simulate large data-sets (e.g. to test scalability), error conditions (to test error handling logic), delays (to test performance under various network conditions) and... well... anything else it&#39;s possible and useful to simulate. The ability to simulate specific application states is kind of a super power.

## Summary

We&#39;ve looked at four interrelated benefits of treating mock data with respect and rigour, with examples / pseudo-code for each.

1. It helps us to clarify our software design by thinking about examples during modelling, before diving in to implementation.
2. It boosts our unit testing efforts by providing a ready-made set of test inputs and making test code more readable and maintainable.
3. It gives us the powerful capability to run our application independent of external data-sources and, as such, to simulate any application behavior we desire.
4. Finally, it decouples us from immediate dependency on other teams while clarifying the relationships between teams by encouraging us to model them as contracts.

These benefits come at a cost. Using mock data in this way requires application code to be structured in a certain way (isolation of Application state). And it takes significant effort to augment a pre-existing application with mock data, especially if that application has complex logic.

Given all of the above, mock data seems best suited to long-term software projects of moderate complexity, where the advantages of using mock data outweigh the costs.

## Related tools

- [Mock Service Worker](https://mswjs.io/), targeted at web/typescript projects, provides some infrastructure for mocking web endpoints. The application can make requests as usual, but MSW can handle the requests and provide mock responses as if the Backend was mocked. The requests will appear in the Network Tab of Developer Tools, just like a regular request.

## Further reading

Books that inspired me:

- [_Domain Modelling Made Functional_](https://pragprog.com/titles/swdddf/domain-modeling-made-functional/) • Scott WLASCHIN
- [_The Art of Unit Testing_](https://www.artofunittesting.com/) • Roy OSHEROV
</content>
  </entry>
  

  <entry>
    <title>Parallel loading in React</title>
    <link href="https://conwy.co/articles/parallel-loading-react" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>parallel-loading-react</id>
    <content xml:lang="en" type="html">&gt; Summary: The problem was: how to load a list of items, then load details of each item, then combine all of this information and render it to the user, all within one component. This could be done more easily by splitting details into a separate component, rendered in a `map` loop, and having each instance of that component make its own request.

Recently I had to build a React component that would merge the results of several independent requests into one set of data and render it as a single list.

The requests would look like this:

- GET to load initial list of items
- GET to load item 1 details
- GET to load item 2 details
- ... etc for each item in the list

I wanted the list to ultimately render like this:

- Item 1 + details
- Item 2 + details
- ... etc for each item in the list

The problem was: how to load a list of items, then load details of each item, making a separate request per item, then combine all of this information and render it to the user, all within one component.

&gt; ### Aside: Caveat: Ideal simpler implementation
&gt;
&gt; This could be done more simply by splitting details into a separate component, rendered in a `map` loop, and having each instance of that component make its own request.
&gt;
&gt; However, for various reasons, this might not always be possible. For example, when working in a complex pre-existing code-base, there might not be time to refactor everything to the simpler implementation.

## Synchronously combining results

The simplest way would be to await all the requests and then render them together at once.


    D --&gt;|Yes| C
    D --&gt;|No| E(Combine items list with details)
        E --&gt; F(Render items list with details)
        F --&gt; G[Done]
*/}

![Flowchart depicting synchronous loading of items](/images/articles/parallel-loading-react/sync-loading.svg)

Here is an implementation which uses `Promise.all`.

[Codepen Link](https://codepen.io/jonathanconway/pen/dyRQGam)

```jsx
function UsersAndStatuses(props) ));

    setUsers(usersWithStatus);
  }, []);

  return (
    
      
       
        
      ))}
    
  );
}
```

The problem with the above is:

**It could take a long time for all the requests to complete.**

We don&#39;t want to keep the user waiting for the whole list to load before they can see any results.

It would be better if we could

1. Load and quickly render the list of items without the details, then
2. Load and render the detail for each item as soon as each response is received


    F --&gt;|Yes| D
    F --&gt;|No| G[Finish]  
*/}

![Flowchart depicting parallel loading of items](/images/articles/parallel-loading-react/async-loading.svg)

## Asynchronously combining results

Implementing this improved solution raised a challenge:

**How to merge the details from all the requests together into one state variable without triggering a React refresh cycle?**

If the React refresh cycle triggered, it would have caused the state variable to contain incomplete data, as one partial value would override another.

It turns out the solution is rather simple: we just have to re-use the latest copy of our state variable each time we set it.

So instead of the typical `setState` call:

```js
setUsers();
```

We [pass a state setter](https://twitter.com/dan_abramov/status/816394376817635329) whose parameter (`currentUsers`) will always have the last updated value:

```js
setUsers((currentUsers) =&gt; ());
```

So... here&#39;s the parallel loading solution.

[Codepen Link](https://codepen.io/jonathanconway/pen/dyRQMQL)

```jsx
function UsersAndStatuses(props) );
  const users = React.useMemo(() =&gt; Object.values(usersById), [usersById]);

  React.useEffect(async () =&gt; ),
        
      )
    );

    const userIds = usersList.map((user) =&gt; user.id);

    userIds.forEach(async (userId) =&gt; ,
      }));
    });
  }, []);

  return (
    
      
       
        
      ))}
    
  );
}
```


</content>
  </entry>
  

  <entry>
    <title>Wireframing techniques</title>
    <link href="https://conwy.co/articles/interaction-wireframes" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>interaction-wireframes</id>
    <content xml:lang="en" type="html">&gt; Summary: Interaction wireframes depict a user interface at low fidelity including additional information on each component and interactions – how the interface responds to user activity.

It’s nearly 2021, so I thought I’d share a small achievement of 2020:

**A way of depicting interactions in UI wireframes!**

Background: I&#39;ve been doing a lot of complex UI work lately. In the process I&#39;ve been finding it useful to diagram out these interfaces. I like to do this both before and during the actual development work. It really helps to understand and reason about the UI. These are very interactive UIs - lots of clicking, dragging, dropping, etc. So the question arises: can the interactions also be expressed in visual form?

From experimenting with a number of projects and techniques, I&#39;ve settled on a consistent style, which I now use in all wireframes:

1. Elements □ - Shapes and enclosed text
2. Markers ○ - Numbered circles (with a legend)
3. Interactions → - Connecting arrow lines (with labels)

Let&#39;s do a quick dive into each.

## 1. Elements

The actual elements that make up the interface are marked out with shapes such as rectangles, rounded rectangles, circles, etc., similar to how they would appear in the final application.

Here&#39;s a convention to follow for shapes:

- Straight rectangles for panels, modals, headers, etc.
- Rounded rectangles for buttons, input boxes, checkboxes, etc.

And here&#39;s an example:

![Wireframe showing only interface elements drawn with simple shapes](/images/articles/interaction-wireframes/wireframes-elements.svg)

## 2. Markers

We might want to &quot;mark&quot; or &quot;tag&quot; a particular part of the UI with additional info.

For example, to indicate that a specific component should be used, when it isn&#39;t obvious just by looking at the diagram, we might want to mark that part of the wireframe with the name of that component.

For this purpose, we can drop in numbered circles, and along with a legend item for each indicating the name of the component.

Here&#39;s how it looks:

![Wireframe showing interface elements numbered with legends](/images/articles/interaction-wireframes/wireframes-markers.svg)

## 3. Interactions

Finally we get to the exciting part: _interactions_.

The user might generate events (click, drag, drop, keypress, etc) which cause the UI to change in some way (e.g. open a drop-down, move an element, hide a modal, etc).

You might have assumed that depicting interactivity would require the use of a prototyping tool, but actually it can be done in a static wireframe too.

We can simply add a connecting arrow lines made up of the following parts:

1. Source of the connector - the element from which the event originates
2. Label on the connector - name of the event
3. End of the connector - arrow-head pointing at a component (or group of components) which depict the state of the UI when the event is handled

For example, suppose we want to depict that when the user clicks a button, a modal box appears. We draw an arrow from the button to the modal, with ‘(click)’ in rounded brackets on the connector.

![Event connector depicting a button click event](/images/articles/interaction-wireframes/wireframes-interactions.svg)

Notice that we don&#39;t necessarily have to depict the whole UI in the &#39;after&#39; part of the wireframe. We only have to depict the part that changed - in this case, the modal. This habit of only depicting the change really speeds up the wireframing activity. We only have to depict _changes_ in our UI, not the whole UI in every possible state.

There might be some logic to these interactions. For example, if the user enters a correct username and password to log in, we display a success notification. But if they get the password wrong, we show an error message underneath the password field. This kind of logic can be depicted by augmenting our diagram with a flowchart shape.

## Putting it all together

Here&#39;s the whole UI - elements, numbered labels and event connectors (with logic).

![Wireframe showing interface elements, component labels and event connectors](/images/articles/interaction-wireframes/wireframes-alltogether.svg)

Notice how you can read and comprehend this quite quickly, just like we&#39;d read a paragraph out of a book. Wireframes can communicate a information that is better represented visually and spatially rather than in paragraphs of plain text.

Notice also that this wireframe can manipulated - split apart, combined with other elements, used to form a new wireframe. This can be an excellent tool for experimenting with alternative designs. It can also be great for communicating - you can easily slice of any part of the design, paste it into a Slack discussion, and gather some feedback from your colleagues.

## Conclusion

I&#39;ve found simple, low-fidelity wireframes that highlight **interactions** to be highly useful when developing highly interactive or logic-intense user interfaces.

- They help me to understand how the software will actually work.
- They give me a feeling of control over my work environment - I can change the design at any time and in any way.
- They can help me to think clearly and form a good mental model of the requirements.
- They provide a visual aid for communicating requirements to team members and getting their feedback.
- They serve as a guide and reference point while I&#39;m actually writing the code.

## Further reading

Books that inspired me:

- [_Designing for the Digital Age_](https://www.wiley.com/en-us/Designing+for+the+Digital+Age%3A+How+to+Create+Human+Centered+Products+and+Services-p-9780470229101) • Kim GOODWIN
- [_Macintosh Human Interface Guidelines_](https://developer.apple.com/design/human-interface-guidelines/) • Apple Computer
</content>
  </entry>
  

  <entry>
    <title>Towards zero bugs</title>
    <link href="https://conwy.co/articles/towards-zero-bugs" />
    <updated>2025-02-12T00:00:00.000Z</updated>
    <id>towards-zero-bugs</id>
    <content xml:lang="en" type="html">&gt; Summary: Using a checklist, and a mindset of expecting and seeking out bugs, we can eliminate bugs from our code before going to production.

Software with zero bugs may seem like an ambitious goal. Over time, defects in software have increased and have become so normalised that some developers and users even expect them.

But while it&#39;s difficult to get to zero bugs, I think it&#39;s worth trying for. We shouldn&#39;t concede defeat and assume ahead-of-time that our products will be defective. Rather, we should do everything in our power to avoid inadvertently creating bugs in our software, where they could be avoided. The closer we get to zero , the better!

Over time, I have been building up a mental checklist of things to look out for, both in the code I write and in the running application that it generates, to identify potential bugs. I now run through this checklist whenever I am about to complete work on a change or a new feature. I have also been working on building a mindset that encourages discipline, rigour and attention to detail.

By running these checks and building this mindset, I aim to identify and fix bugs early, rather than having them show up in a testing environment, or worse still, in front of an end-user.

I would love to share this with other developers. Please have a read and let me know your thoughts in the comments!

## The checklist

Without further ado, here&#39;s my list:

**Typos, accidental keystrokes, debugging statements.** Every time you&#39;re about to commit, hold back for a moment and review the diff of changes going in. Make sure you&#39;re only committing what you fully intend to commit. Check for typos, accidental keystrokes, inadvertent capitalisation, etc. A compiler or linter can usually pick these up, but there are often cases that are missed, so it&#39;s still worth taking a few seconds to run your eyes over the diff. Also check for development-only code, such as logging or debugging statements, which pass compilation but shouldn&#39;t be checked in.

**Subtle logic errors.** Look for all those mistakes that _look_ like reasonable code, to both the first glance and the compiler, but are actually the wrong way round or otherwise incorrect.
For example:

- False-positives. For example: `if (!hidden)  else `. Observe that `!hidden` is actually equivalent to being visible. So this code would actually execute `show()` when already visible and `hide()` when invisible! To correct this, we would want to remove the `!` and have something like this: `if (hidden)  else `. It&#39;s important to keep an eye out for these kinds of subtle logic errors.
- Expressions being coerced to incorrect boolean values. For example, in Javascript, an `indexOf(x)` call without being compared to anything, when it should be compared it to a numeric value. A correct (and clearer) way to achieve this intent might be to call `includes(x)`, which _does_ return a boolean.
- Off-by-one errors. For example: `for (let i = 0; i &lt;= 10; i++) `. This loop runs 11 iterations, where it was probably expected to run 10. It would be clearer to rewrite it as: `for (let i = 0; i &lt; 10; i++) `.
- Filtering operations. You may perform a filtering function, but accidentally extract items from a list and return only those items, when your intent was to return the full list _including_ those items. Or your code might return everything except certain items, when the intent was to return nothing at all if those items exist. There are many other variations on this. In summary, carefully review complex filtering operations.

**Edge cases.** To find these, try to break your app.

- Click a lot of different parts of the UI in very quick succession.
- Test long sequences of actions and make sure the result at the end is exactly as expected. For example, test undo/redo thoroughly by performing an action, then undoing it, then redoing it, many times, then verifying the end result.
- Input values in unexpectedly large quantities, in an unexpected format or null/empty values.
- Test with correctly formatted but illogical values (e.g. a date that is the 32nd of the month).
- Add a larger than normal number of items to a list.
- Run multiple instances of the application at once and verify that it still works properly.

Basically do everything you can to break your application and ensure that it recovers gracefully in all circumstances. If you have a large number of possible combinations of inputs to test, unit tests can definitely be your friend!

**Values vs. references.** Do you expect a value to be set in one place and updated in many others? Or do you want to hold independent copies of that value in multiple places? Review your usages of references vs values and make sure they&#39;re correct for your use case.

**Memory leaks.** These can dramatically slow down an application and even cause it to crash, due to incorrect and unconstrained allocation of memory. These can manifest themselves in a variety of ways, depending on the language and environment you&#39;re developing for.
For example:

- In C# or Java, it may be an unmanaged resource that&#39;s not being cleaned up.
- In multithreaded applications, dead threads.
- In Javascript, Maps that reference DOM nodes that no longer exist.
- In RXJS, subscriptions to observables that you forgot to unsubscribe.

In addition to manually checking the code, practically every environment also has its own set of tools for diagnosing memory leaks. For example, for .NET, there is a memory profiler and for Javascript, Developer Tools in most browsers have a Memory tab or similar.

**Code executing too often.** Do you perform unnecessary operations within a for loop, a game loop, a template, a rendering cycle, or any other part of the code base that gets executed many times in succession? This could cause a slowdown to your app, which if it gets too bad, could be considered buggy behaviour. Code that might not need to run includes code that generates the same result on every iteration (in which case, some form of caching is your friend) or code that&#39;s only needed in certain states (where a simple `if` statement around that state could skip the code when it&#39;s not needed).

**Same same but different.** Be extra careful in situations where you have two things that look and behave very similarly, but are qualitatively different. An example of such a situation, which I encountered recently, was in building two tree views which depicted essentially the same data, but with subtly different visual markers on each. These visual markers highlighted opposite aspects of the same data. But, by mistake, I also coded one of the trees so that it reversed the order of its elements! This bug should have been obvious, but it escaped my notice. I was so focussed on getting the markers right (the difference) that I forgot to ensure that the ordering was right (the sameness). In retrospect, if I had pulled back and double-checked that the end-result had the _right_ difference and not the _wrong_ difference, I could have caught this early and fixed it.

**Null-checks.** Whenever two values are being compared, have you null-checked and undefined-checked both sides of the comparison if needed, and handle what to do if either/both are null? Add checks as needed. (Some languages offer conveniences / syntactical sugar for this. E.g. Javascript has the [optional-chaining operator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Optional_chaining): `?.`.)

**Async data dependencies.** Does your app depend on multiple sets of data, which may load at different times? What happens when not all of the data has loaded? Does the application crash and burn? Or does it handle the situation gracefully, perhaps waiting until all the data has loaded, and showing a &#39;loading&#39; indicator in the meantime? You might simulate this state by temporarily adding a lag to one of your data sources, using your language&#39;s &#39;delay&#39; mechanism. For example, calling Javascript&#39;s `setTimeout` method, RX&#39;s [Delay operator](http://reactivex.io/documentation/operators/delay.html) or .NET&#39;s `Thread.Sleep()`. Of course, take care to revert any testing code prior to check-in!

**Browser/OS upgrades.** Depending on the environment you&#39;re developing for, be aware of the potential for breaking changes to that environment, when a new version comes out. Upgrade whenever a new version ships and test your application in the new version, looking for bugs. I experienced the importance of this recently, with the [changes to Flexbox in Chrome 72](https://bugs.chromium.org/p/chromium/issues/detail?id=927066), which necessitated several CSS changes.

**Devices, screen sizes and zoom factors.** Test your app with multiple devices if needed – mobile, tablet and/or desktop. You may also need to check with multiple browsers on those devices as well as multiple versions and form-factors of the devices. Also, try increasing/decreasing the zoom level and ensure that the layouts, sizing, etc, are still proportional.

**Accessibility.** Bugginess or even absence of accessibility features is a major problem in the software application landscape. If your app will be used by a broad segment of the population, you probably should be ensuring that it is accessible. Ideally accessibility is &quot;baked-in&quot; from the beginning, but this doesn&#39;t nullify the need to regularly and rigorously test that accessibility features work. In my own accessibility auditing, I focus on three main areas: A) keyboard-only operation, B) non-visual operation, C) adherence to WCAG. A basic test of these three areas can be performed on any web page, by A) pushing the mouse away and attempting to use the application keyboard-free, B) looking away from the screen and attempting to use the application by means of only a screen-reader, C) running the [Wave](https://wave.webaim.org/extension/) automated testing tool and reviewing its output. Similar tests can be run on non-Web/native applications. I plan to write an entire article dedicated to this topic, as it is a large one. In the meantime, you can check out some excellent resources, such as [WAI](https://www.w3.org/WAI)&#39;s [Easy Checks](https://www.w3.org/WAI/test-evaluate/preliminary/) page.

**Date and time handling and formatting.** Be extra careful to test code that does anything with dates or times. If the code is performing some kind of calculation on a date/time value, try to test it with a variety of inputs and ensure that it always produces a correct result date/time. Also, test that it works in a different time-zone. To do this locally, you can temporarily change your system time-zone, re-load your application and re-test the date/time feature.

**Numeric values, such as currency.** As with dates/times, thoroughly test any aspect of your application that operates on numbers, and especially locale-specific numbers such as currency values. Also check if you might receive a numeric value as a string and need to convert it to an appropriate numeric type before using it.

**Load testing.** Does the system break down when large number of items are passed through it? Substitute a fake data-source with thousands or even millions of records and see if the application can handle that load.

**Requirements vs solution.** Double-check the original requirements and see if you actually addressed them. There might have been a subtle indication in the language that you overlooked or some ambiguities that you didn&#39;t yet clear up. If you need to go back to the business to clarify these issues, do this as soon and early as possible, so that you have a better chance of fixing any bugs in the code before releasing it.

**Hit refresh.** Sometimes, for reasons that I don&#39;t entirely understand (and perhaps don&#39;t wish to) a running application will get out-of-sync with the code that generated it. Yes, this can happen even when automatic compilation tools are in use. In the case of web apps, caching of assets can play a role. For native apps, processes may remain open. I have sometimes spent half an hour or more trying to figure out why something wasn&#39;t working or why I couldn&#39;t reproduce a bug, only to find that the version I was using was stale. Long story short: when in doubt, hit restart and refresh.

**Multiple environments.** Most organisations have multiple environments into which software is deployed in a staged manner. There&#39;s the local developer machine, then a Development server, then Staging and/or QA, then Production/Release/Live. It&#39;s a good idea to run some tests on your application in every environment. This is especially important if your feature or change depends on environment-specific factors, such as configuration values, database schemas, data and other systems, services or resources. Anything might go wrong in a new environment, from a typo in a configuration value to a missing authorisation on a resource. You don&#39;t have to test everything in every environment, but it&#39;s probably a good idea to at least test the happy path.

**Find similar bugs and fix them (and generalise the fix!).** This came up recently, where a colleague discovered a bug in which the wrong property was being used to retrieve the error message from an HTTP response. Rather than merely fixing it for that one response, I tested all places in the codebase where an error message was being retrieved from an HTTP response and fixed them all where necessary. I then went a step further and generalised the fix, by extracting HTTP error handling to a common function. So not only were additional bugs eliminated, but similar bugs in the future were prevented, by improving the overall framework.

**Errors of addition.** When adding new code, be careful that it doesn&#39;t cause an error. For example, adding a field to a class, adding a value to an enum, etc might cause unexpected behaviour. This is especially important if you have code somewhere that dynamically reads the structure you&#39;re modifying, e.g. code that loops over the fields in a class using reflection. (Such &quot;dynamic access&quot; is usually not best practice, but unfortunately some code-bases use it, so we might need to check the code-base we&#39;re working on.)

**Errors of ommission.** When adding new code, be careful that we didn&#39;t *forget* to include something, which might cause an error. Say we create a new subtype of an inheritable class, we might need to include some field or value. This might not necessarily be indicated by the compiler if, e.g., our code-base has some dynamic code that loops over the fields in all subtypes of the class and expects certain fields to exist.

**Consuming a data source in a context where it is not available.** When we call a method or function from a component, we might verify that our code works by using that component and seeing that it works correctly. But will that call work in every possible context in which the component is used? What if there is a different way to access the same component, in which that call breaks? This could be very subtle and easy to miss, if we are not aware of the different contexts in which our component is used. For example, this happened to me once when working on a popup modal in React. The modal consumed a hook which depended on certain data being in the browser URL. But I was not aware that the modal could be accessed from a different page with a different URL which did not have that data. The different URL broke the hook and thus my modal component.

**Re-testing after merge.** After completing a change and pushing, you might need to resolve a merge conflict or rebase your change. Be careful to re-test your work following the merge! Even a successfully automated merge might still result in a subtle logic error that you missed. The same applies to any changes you make in response to pull-request comments, build errors, etc.

**Remote API calls.** Ensure all remote API calls your code depends on are fully working. E.g. HTTP requests, web-sockets connections, etc.

## The mindset

This checklist may seem daunting, especially when working under time constraints. However, you don&#39;t have to action all of these items for every change you make. I typically give this list a quick scan and pick out only the items that are relevant to the change I&#39;m making. For example, a change to the logic for calculating a numeric value probably doesn&#39;t necessitate checking &#39;Devices, screen-sizes and zoom factors&#39;. Likewise, for a change to the layout of a dialog box, I can probably skip &#39;Async data dependencies&#39;.

The &quot;old&quot; mindset (that I have sometimes seen in the industry) is:

- I assume my code has no bugs by default.
- Good developers never write buggy code, so I shouldn&#39;t bother too much checking my code for bugs, otherwise I might discover that I&#39;m a terrible developer!
- There&#39;s never enough time to check for bugs, so I have no choice but to ship buggy code.
- My code will naturally get more and more reliable as I gain experience.
- Testing and bug-fixing is boring, tedious and not fun.
- There&#39;s no reward to being thorough about testing for and fixing bugs.
- Software development is unimportant, menial &quot;grunt work&quot;, so it doesn&#39;t matter if we get it wrong.

The &quot;new&quot; mindset that I aim to spread, which I think is more productive, is:

- My code is buggy unless proven otherwise.
- Part of being a good developer is having the discipline and patience to go through code that I wrote, which looks fine - even spectacular - and find and fix all the bugs that I know are probably lurking within it.
- There&#39;s almost always a little extra time to put in some honest effort to finding and fixing bugs.
- Putting in a regular, consistent effort to write reliable code will make my code more reliable.
- Testing and bug-fixing can be made fun, with a positive mindset and a little &#39;gamification&#39;. I can enjoy the endorphin-rush of fixing a bug and knowing that I left the code better than I found it.
- The reward to testing for and fixing bugs is building the mental muscles (discipline, rigour, attention to detail, etc) that will result in more reliable software. Those muscles will move me forward in all aspects of problem-solving, not only bug-fixing. Also, I can build a reputation as someone who builds reliable software, which will probably be good for my career.
- Software development is a profession and a craft, and we should take pride in our work.

## Let a thousand checklists bloom!

Do you keep a checklist like this, either in written or mental form? Are there any other items you would add to such a checklist? And do you have anything to add about the mindset needed to write reliable, bug-free code?

Feel free to comment about your checklists and experiences or link to them in the comments. It would be great to share any ideas that we developers can use, in order to get closer to writing bug-free code.

Thanks for reading!

## Further reading

Boooks that inspired me:

- [_The Checklist Manifesto_](https://atulgawande.com/book/the-checklist-manifesto/) • Atul GAWANDE
- [_Code Complete_](https://archive.org/details/code-complete-2nd-edition/page/428/mode/2up) • Steve MCCONNELL
- [_The Pragmatic Programmer_](https://pragprog.com/titles/tpp20/the-pragmatic-programmer-20th-anniversary-edition/) • Andrew HUNT, David THOMAS
- [_Clean Code_](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882) • Bob MARTIN
</content>
  </entry>
  
  </feed>